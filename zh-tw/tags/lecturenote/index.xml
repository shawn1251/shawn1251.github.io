<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>LectureNote on Shawn&#39;s Note</title>
        <link>http://shawn1251.github.io/zh-tw/tags/lecturenote/</link>
        <description>Recent content in LectureNote on Shawn&#39;s Note</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>zh-tw</language>
        <lastBuildDate>Tue, 06 Aug 2024 00:00:00 +0800</lastBuildDate><atom:link href="http://shawn1251.github.io/zh-tw/tags/lecturenote/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>2024 李弘毅 生成式AI導論筆記</title>
        <link>http://shawn1251.github.io/zh-tw/post/generativeai-2024-youtube-summery/</link>
        <pubDate>Tue, 06 Aug 2024 00:00:00 +0800</pubDate>
        
        <guid>http://shawn1251.github.io/zh-tw/post/generativeai-2024-youtube-summery/</guid>
        <description>&lt;p&gt;課程講得淺顯易懂，雖然目前還沒有時間做LAB，但內容對於了解生成式AI的概念有很大的幫助。&lt;br&gt;
課程連結: &lt;a class=&#34;link&#34; href=&#34;https://www.youtube.com/playlist?list=PLJV_el3uVTsPz6CTopeRp2L2t4aL_KgiI&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://www.youtube.com/playlist?list=PLJV_el3uVTsPz6CTopeRp2L2t4aL_KgiI&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;lec0&#34;&gt;lec0&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;本課程適合已經接觸過AI，想了解背後原理&lt;/li&gt;
&lt;li&gt;arXiv 可以用來找尋最新技術文章&lt;/li&gt;
&lt;li&gt;會學到訓練7B參數的模型&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;lec1&#34;&gt;lec1&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;生成式人工智慧: 機器產生複雜有結構的物件
&lt;ul&gt;
&lt;li&gt;複雜: 近乎無法窮舉&lt;/li&gt;
&lt;li&gt;不是分類，分類是從有限選項作選擇&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;機器學習: 機器自動從&lt;strong&gt;資料&lt;/strong&gt;找出一個函數
&lt;ul&gt;
&lt;li&gt;函數會需要很多參數&lt;/li&gt;
&lt;li&gt;模型: 有上萬個參數的函數&lt;/li&gt;
&lt;li&gt;學習/訓練: 把參數找出來的過程&lt;/li&gt;
&lt;li&gt;對於當今有大量參數的模型，我們可以表示會類神經網路。而訓練過程也就是深度學習&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;ChatGPT 也是個函數，當中有上億個參數，使用的模型為transformer&lt;/li&gt;
&lt;li&gt;語言模型: 文字接龍
&lt;ul&gt;
&lt;li&gt;原本無窮的問題，因為文字接龍而變得有限&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;生成策略
&lt;ul&gt;
&lt;li&gt;Autoregressive Generation
&lt;ul&gt;
&lt;li&gt;將複雜物件拆成較小單位，依照某種順序依序生成
&lt;ul&gt;
&lt;li&gt;文章 &amp;gt; 文字&lt;/li&gt;
&lt;li&gt;圖片 &amp;gt; 像素&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;lec2&#34;&gt;lec2&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;如今生成式人工智慧，厲害的是在於沒有特定功能&lt;/li&gt;
&lt;li&gt;生成式人工智慧很難評估模型&lt;/li&gt;
&lt;li&gt;如今工具這麼厲害，我能做什麼?
&lt;ul&gt;
&lt;li&gt;思路1: 改變不了模型，那我改變自己
&lt;ul&gt;
&lt;li&gt;prompt engineering&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;思路2: 訓練自己的模型&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;lec3&#34;&gt;lec3&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;在不訓練模型的狀況下提升模型&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;請模型思考 Chain of Thought
&lt;ul&gt;
&lt;li&gt;
&lt;blockquote&gt;
&lt;p&gt;Let&amp;rsquo;s think step by step&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;請模型解釋自己答案
&lt;ul&gt;
&lt;li&gt;
&lt;blockquote&gt;
&lt;p&gt;answer by starting with &amp;ldquo;Analysis:&amp;rdquo;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;對模型情緒勒索
&lt;ul&gt;
&lt;li&gt;
&lt;blockquote&gt;
&lt;p&gt;This is very important to my career&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;更多prompt技巧&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;from &amp;ldquo;Principled Instructions Are All You Need For Questioning LLaMA-1/2, GPT-3.5/4&amp;rdquo;&lt;/li&gt;
&lt;li&gt;無須對模型有禮貌&lt;/li&gt;
&lt;li&gt;請告訴模型做甚麼(do)，不要告訴模型不做什麼 (don&amp;rsquo;t)&lt;/li&gt;
&lt;li&gt;告訴模型回答好有獎勵 &amp;ldquo;I&amp;rsquo;m going to tip $X for a better solution&amp;rdquo;&lt;/li&gt;
&lt;li&gt;告訴模型做不好有處罰 &amp;ldquo;you will be penalized&amp;rdquo;&lt;/li&gt;
&lt;li&gt;&amp;ldquo;Ensure that your answer is unbiased and avoids relying on stereotypes&amp;rdquo;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;用AI來找尋改進AI的prompt&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;增強式學習&lt;/li&gt;
&lt;li&gt;
&lt;blockquote&gt;
&lt;p&gt;&amp;ldquo;Let&amp;rsquo;s work this out in a step by step way to be sure we have the right answer&amp;rdquo;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;blockquote&gt;
&lt;p&gt;&amp;ldquo;Take a deep breath and work on this problem step by step&amp;rdquo;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;blockquote&gt;
&lt;p&gt;&amp;ldquo;Let&amp;rsquo;s combine our numerical command and clear thinking to quickly and accurately decipher the answer&amp;rdquo;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;並不是對所有模型都有效&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;提供範例&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;in-context learning&lt;/li&gt;
&lt;li&gt;不一定有效，根據研究，目前對較新的模型更加有效&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;lec4&#34;&gt;lec4&lt;/h2&gt;
&lt;p&gt;承接上&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;拆解任務&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;將複雜的任務拆成小任務&lt;/li&gt;
&lt;li&gt;也解釋了Chain of Though, CoT，請模型解釋步驟會有用的原因&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;請語言模型檢查自己的錯誤&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;令語言模型可以自我反省&lt;/li&gt;
&lt;li&gt;很多問題得到答案很難，驗證卻相對簡單&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;問問題為甚麼每次答案不同&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;語言模型輸出的是下一個使用的字的機率，在輸出的過程中會根據機率隨機選取&lt;/li&gt;
&lt;li&gt;可以重複多次，選擇出現最多次的結果&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;組合上述所有技巧&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Tree of Thoughts(ToT)
&lt;ol&gt;
&lt;li&gt;將一個任務拆成多個步驟&lt;/li&gt;
&lt;li&gt;每個步驟執行多次&lt;/li&gt;
&lt;li&gt;每次結果，請模型進行檢查，自我驗證&lt;/li&gt;
&lt;li&gt;通過者在進行到下個步驟&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;加強模型&#34;&gt;加強模型&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;使用工具
&lt;ul&gt;
&lt;li&gt;搜尋引擎
&lt;ul&gt;
&lt;li&gt;Retrieval Augmented Generation (RAG)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;寫程式
&lt;ul&gt;
&lt;li&gt;GPT4會撰寫程式以便解決特定類型問題&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;文字生圖(DALL-E)
&lt;ul&gt;
&lt;li&gt;文字冒險遊戲&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;lec5&#34;&gt;lec5&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;模型合作
&lt;ul&gt;
&lt;li&gt;讓適合的模型做適合的事情
&lt;ul&gt;
&lt;li&gt;訓練一個模型來判斷用什麼模型&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;兩個模型彼此討論&lt;/li&gt;
&lt;li&gt;未來可以透過多個不同模型專業分工，避免建立全能模型的高昂成本&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;lec6&#34;&gt;lec6&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;語言模型類似文字接龍&lt;/li&gt;
&lt;li&gt;機器學習如何做文字接龍?
&lt;ul&gt;
&lt;li&gt;未完成句子 &amp;gt; 語言模型 &amp;gt; 下一個token&lt;/li&gt;
&lt;li&gt;$token = f(未完成句子)$&lt;/li&gt;
&lt;li&gt;GPT使用的是transformer模型，$f()$為數十億個未知參數的函數&lt;/li&gt;
&lt;li&gt;訓練training(學習learning)，就是把這數十億參數找出來的過程
&lt;ul&gt;
&lt;li&gt;訓練資料為有意義的上下文，作為輸入與輸出的判斷，如: 人工智 -&amp;gt; 慧&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;找完參數座使用的過程就做測試testing(推論inference)&lt;/li&gt;
&lt;li&gt;找參數是個挑戰
&lt;ul&gt;
&lt;li&gt;過程稱作最佳化(optimization)，需要使用到超參數(hyperparameter)&lt;/li&gt;
&lt;li&gt;訓練過程可能因為找不到參數而失敗，換一組超參數重新訓練&lt;/li&gt;
&lt;li&gt;也可以修正初始參數
&lt;ul&gt;
&lt;li&gt;初始參數一般是隨機，也就是train from scratch&lt;/li&gt;
&lt;li&gt;也可以從好的參數作為初始參數，先驗知識&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;訓練成功可能測試失敗
&lt;ul&gt;
&lt;li&gt;對訓練集有效實際測試無效&lt;/li&gt;
&lt;li&gt;稱作overfitting&lt;/li&gt;
&lt;li&gt;考慮增加測試資料多樣性&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;需要多少文字才能學會文字接龍
&lt;ul&gt;
&lt;li&gt;語言知識
&lt;ul&gt;
&lt;li&gt;學習文法&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;世界知識
&lt;ul&gt;
&lt;li&gt;很困難&lt;/li&gt;
&lt;li&gt;複雜，有多層次的&lt;/li&gt;
&lt;li&gt;eg. 水的沸點&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;任何文字都能拿來學習文字接龍，人工介入少 -&amp;gt; self supervised learning&lt;/li&gt;
&lt;li&gt;資料清理
&lt;ul&gt;
&lt;li&gt;過濾有害內容&lt;/li&gt;
&lt;li&gt;去除特殊特殊符號&lt;/li&gt;
&lt;li&gt;資料品質分類&lt;/li&gt;
&lt;li&gt;去除重複資料&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;*　GPT發展史
*　從GPT1 - GPT3，模型參數越來越多，但輸出的品質改進不多
*　此階段 prompt很重要，模型才會知道自己要接什麼
*　原因就是在於只是單純的文本輸入，並不是真正的回答問題&lt;/p&gt;
&lt;h2 id=&#34;lec7&#34;&gt;lec7&lt;/h2&gt;
&lt;p&gt;承接上次問題，模型需要使用更好的資料作為訓練&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;加入人類的指導&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;使用我們特殊設計的文本，令模型學習回答問題。 Instruction Fine-tuning&lt;/li&gt;
&lt;li&gt;使用人力做資料標記，為監督式學習supervised Learning&lt;/li&gt;
&lt;li&gt;但這有幾個問題:
&lt;ul&gt;
&lt;li&gt;可能會造成overfitting&lt;/li&gt;
&lt;li&gt;但人力很貴，資料集有限無法輕易擴增&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;解法:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;ul&gt;
&lt;li&gt;使用大量資料學習的self-supervised learning 參數(pre-train)做為下一個階段的初始參數&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;使用少量資料進行訓練，基於上個階段產生的參數作為初始參數，進行最佳化 (fine tune)&lt;/li&gt;
&lt;li&gt;與上一階段的參數相比不會差太多&lt;/li&gt;
&lt;li&gt;為了避免結果與初始參數差太多，可以使用Adapter技術，常見的有LoRA
&lt;ul&gt;
&lt;li&gt;概念是不變更初始參數，而是在既有參數後方在加上少量參數&lt;/li&gt;
&lt;li&gt;也可以減少運算量&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;關鍵在於大量資料進行Pre-train的參數，達到不會僅憑簡單的規則做文字接龍效果&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;lec8&#34;&gt;lec8&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;step1: pre-train&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;self-supervised learning&lt;/li&gt;
&lt;li&gt;自我學習，累積實力 (foundation model)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;step2: instruction Fine-tuning&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;supervised learning&lt;/li&gt;
&lt;li&gt;給予問題完整正確答案&lt;/li&gt;
&lt;li&gt;名師指點，發揮潛力 (alignment)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;step3: reinforcement learning from human feedback (RLHF)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;參與實戰，打磨技巧 (alignment)&lt;/li&gt;
&lt;li&gt;微調參數: Proximal Policy Optimiaztion 演算法
&lt;ul&gt;
&lt;li&gt;人覺得好的回覆，機率調高，反之降低&lt;/li&gt;
&lt;li&gt;給予好/壞的回應，比step2輕鬆&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;於step1,2階段，模型只是確保文字接龍正確，只問過程不問結果，對於回答整體沒有全面考量&lt;/li&gt;
&lt;li&gt;step3則是只管結果，不管過程&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;但是不像alpha go，棋局的好壞有明確規則，語言模型需要人來評斷&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;但人工很貴，我們需要回饋模型(reward model)，模擬人類喜好
&lt;ul&gt;
&lt;li&gt;給予回覆一個分數&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;語言模型輸出答案，接上回饋模型再進行對參數微調&lt;/li&gt;
&lt;li&gt;但經過研究，過度向虛擬人類(reward model)學習是有害的&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;增強式學習的難題&#34;&gt;增強式學習的難題&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;甚麼叫做好? helpfulness &amp;lt;-&amp;gt; safety&lt;/li&gt;
&lt;li&gt;人類自己都無法判斷好壞的狀況? 未知的問題&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;lec9&#34;&gt;lec9&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;多步驟複雜任務 -&amp;gt; AI Agent
&lt;ul&gt;
&lt;li&gt;AutoGPT&lt;/li&gt;
&lt;li&gt;AgentGPT&lt;/li&gt;
&lt;li&gt;BabyAGI&lt;/li&gt;
&lt;li&gt;Godmode&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;給予一個&lt;strong&gt;終極目標&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;模型擁有&lt;strong&gt;記憶(經驗)&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;基於各類sensor感知&lt;strong&gt;狀態&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;根據&lt;strong&gt;狀態&lt;/strong&gt;，制定&lt;strong&gt;計畫(短期目標)&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;依計畫採取&lt;strong&gt;行動&lt;/strong&gt;，並影響外界環境，產生新的&lt;strong&gt;狀態&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;除了終極目標外，記憶與短期計畫都是可變動的&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;lec10&#34;&gt;lec10&lt;/h2&gt;
&lt;h3 id=&#34;transformer&#34;&gt;transformer&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;tokenization&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;一句話切成一序列的token&lt;/li&gt;
&lt;li&gt;不一定是依照字&lt;/li&gt;
&lt;li&gt;要先自行準備token列表，根據對這個語言的理解而定義的，所以不同語言不同&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;input layer&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;理解每個token&lt;/li&gt;
&lt;li&gt;語意
&lt;ul&gt;
&lt;li&gt;Embedding
&lt;ul&gt;
&lt;li&gt;token 轉成 Vector (查表)&lt;/li&gt;
&lt;li&gt;原本token只是符號，而vector就能運算相關性&lt;/li&gt;
&lt;li&gt;意思相近的token，有接近的vector&lt;/li&gt;
&lt;li&gt;向量參數來自於training&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;embedding沒有考慮上下文
&lt;ul&gt;
&lt;li&gt;同個字在不同句子應該有不同含意&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;位置
&lt;ul&gt;
&lt;li&gt;為每個位置也給予一個向量 positional embedding&lt;/li&gt;
&lt;li&gt;將語意token的vector 加上 位置token的vector，進行綜合考量&lt;/li&gt;
&lt;li&gt;也是查表，表可以是人來設計，近年來也能用訓練的&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;attention&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;考慮上下文 contexturalized token embedding&lt;/li&gt;
&lt;li&gt;輸入一序列的向量，經過上下文計算相關性，輸出另一等長序列的向量
&lt;ul&gt;
&lt;li&gt;每一個token vector 要計算與其他所有token的相關性&lt;/li&gt;
&lt;li&gt;兩兩計算attention weight，所以會形成一個attention matrix
&lt;ul&gt;
&lt;li&gt;實作上，只考慮目前token的左側所有token &amp;ndash; causal attention&lt;/li&gt;
&lt;li&gt;根據目前的實驗，僅需計算左邊即可達到好的效果&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;計算相關性的函數有參數，也是經由training獲得attention weight&lt;/li&gt;
&lt;li&gt;根據attention weight，對所有token 計算weighted sum&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;multi-head attention
&lt;ul&gt;
&lt;li&gt;關聯性不只一種&lt;/li&gt;
&lt;li&gt;所以用多層計算出不同attention weight&lt;/li&gt;
&lt;li&gt;輸出變成不只一組序列&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;feed forward&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;對於多個attention 輸出進行整合，輸出一組embedding&lt;/li&gt;
&lt;li&gt;attention + feed forward = 一組 transformer block&lt;/li&gt;
&lt;li&gt;實際模型有多組tranformer block&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;output layer&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;通過多組transformer block，取出最後一層的最後一個，輸入到output layer&lt;/li&gt;
&lt;li&gt;這個layer也是一個函式，功能為linear transform + Softmax&lt;/li&gt;
&lt;li&gt;輸出則為一組機率分布
&lt;ul&gt;
&lt;li&gt;下一個token應該接甚麼的機率&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;處理超長文本的挑戰
&lt;ul&gt;
&lt;li&gt;因為我們要計算attention matrix，所以複雜度會是與token長度的平方成正比&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;lec11&#34;&gt;lec11&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;interpretable
&lt;ul&gt;
&lt;li&gt;LLM不太能做到&lt;/li&gt;
&lt;li&gt;複雜決策不能一眼看穿&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;explainable
&lt;ul&gt;
&lt;li&gt;沒有標準，取決聽眾&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;直接對類神經網路分析&#34;&gt;直接對類神經網路分析&lt;/h3&gt;
&lt;p&gt;需要一定程度的transparency。如GPT無法取得embedding,則無法分析&lt;/p&gt;
&lt;h4 id=&#34;找出影響輸出的關鍵輸入&#34;&gt;找出影響輸出的關鍵輸入&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;in context learning 中，給予幾個回答範例，並詢問一個問題的答案&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;可以分析 attention 在layer中的變化&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;在淺層layer中，所以各範例的關鍵token會去蒐集與他相對應的範例資料&lt;/li&gt;
&lt;li&gt;在最後layer，要做最後的接龍時，則會對各關鍵label算取attention，得到輸出&lt;/li&gt;
&lt;li&gt;這個分析可以:
&lt;ul&gt;
&lt;li&gt;加速: anchor-only context compression
&lt;ul&gt;
&lt;li&gt;只算取需要的attention&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;預估模型能力: anchor distances for error diagnosis
&lt;ul&gt;
&lt;li&gt;如果最後的embeeding差異不大，代表分類效果不好，模型效果不好&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;大的模型有跨語言學習的能力&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;分析embedding中存在什麼資訊&#34;&gt;分析embedding中存在什麼資訊&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Probing
&lt;ul&gt;
&lt;li&gt;取出tranformer block某一層的embedding，以這些進行分類並訓練出另一個模型。將新的輸入給予模型來驗證
&lt;ul&gt;
&lt;li&gt;如: 詞性分類器，給予一段話，取出他第一層的embedding並對這已知資料進行分類訓練&lt;/li&gt;
&lt;li&gt;給予一段新的話，同樣取出第一層的embedding被使用這個模型驗證結果&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;以BERT為例，每一層tranformer block有不同的分析結果，所以probing並不一定能完全解釋&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;投影到平面觀察相關性
&lt;ul&gt;
&lt;li&gt;有研究將詞彙投影到某一平面，形成文法樹&lt;/li&gt;
&lt;li&gt;有研究將世界地名投影到某一平面，分布類似世界地圖，代表這個詞彙的embedding存在地理資訊&lt;/li&gt;
&lt;li&gt;模型測謊器，測試回答是否有信心&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;直接詢問llm提拱解釋&#34;&gt;直接詢問LLM提拱解釋&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;詢問每個字的重要性&lt;/li&gt;
&lt;li&gt;詢問答案，與信心分數&lt;/li&gt;
&lt;li&gt;但解釋不一定是對的，會受到人類輸入影響，即使解釋也會出現幻覺&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;lec12&#34;&gt;lec12&lt;/h2&gt;
&lt;h3 id=&#34;如何評比模型&#34;&gt;如何評比模型&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;標準答案 benchmark corpus
&lt;ul&gt;
&lt;li&gt;但是對於這種開放回答沒有標準答案&lt;/li&gt;
&lt;li&gt;選擇題庫(ABCD) MMLU
&lt;ul&gt;
&lt;li&gt;評量有不同可能性
&lt;ul&gt;
&lt;li&gt;回答格式不如預期&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;模型可能對猜測有其傾向，選項順序，格式經過研究都對正確率有影響&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;沒有標準答案的問題類型
&lt;ul&gt;
&lt;li&gt;翻譯
&lt;ul&gt;
&lt;li&gt;BLEU&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;摘要
&lt;ul&gt;
&lt;li&gt;ROUGE&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;都是做字面比對，若用字不同則無法反應好壞&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;使用人工評比
&lt;ul&gt;
&lt;li&gt;人工很貴&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;使用LLM評估LLM
&lt;ul&gt;
&lt;li&gt;eg. MT-bench&lt;/li&gt;
&lt;li&gt;與chat arena有高度相關&lt;/li&gt;
&lt;li&gt;但LLM本身可能有所偏袒
&lt;ul&gt;
&lt;li&gt;偏向長篇幅回答&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;複合型任務&#34;&gt;複合型任務&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;eg. BIG-bench
&lt;ul&gt;
&lt;li&gt;emoji movie&lt;/li&gt;
&lt;li&gt;checkmate in one move&lt;/li&gt;
&lt;li&gt;ascii word recognition&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;閱讀長文-needle-in-a-haystack&#34;&gt;閱讀長文 needle in a haystack&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;在一個長文中插入目標問題的答案
&lt;ul&gt;
&lt;li&gt;需要測試不同位置&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;測試是否為達目的不擇手段&#34;&gt;測試是否為達目的不擇手段&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Machiavelli Benchmark
&lt;ul&gt;
&lt;li&gt;加入道德評判&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;心智理論&#34;&gt;心智理論&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;莎莉小安測驗 Sally Anne test
&lt;ul&gt;
&lt;li&gt;這是常見的題目，網路上是有的，所以不能夠用於測試模型&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;不要盡信benchmark結果&#34;&gt;不要盡信benchmark結果&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;因為題目都是公開的，LLM學習資料可能看過了&lt;/li&gt;
&lt;li&gt;可以透過直接詢問LLM題目集，如果相符就代表有看過&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;其他面向&#34;&gt;其他面向&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;價格&lt;/li&gt;
&lt;li&gt;速度&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://artiicailanalysis.ai&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://artiicailanalysis.ai&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;lec13-安全性議題&#34;&gt;lec13 安全性議題&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;別當搜尋引擎用
&lt;ul&gt;
&lt;li&gt;Hallucination 幻覺&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;亡羊補牢
&lt;ul&gt;
&lt;li&gt;事實查核&lt;/li&gt;
&lt;li&gt;有害詞彙檢測&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;評量偏見
&lt;ul&gt;
&lt;li&gt;對一個問題中的某個詞彙進行置換，檢驗輸出結果是否存在
&lt;ul&gt;
&lt;li&gt;eg. 男 -&amp;gt; 女&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;訓練另一個LLM，盡可能的產生會讓目標LLM輸出有偏見的內容
&lt;ul&gt;
&lt;li&gt;訓練方法為reinforcement learning，根據內容差異作為反饋，盡可能讓差異最大化&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;不同職業，LLM存在性別偏見&lt;/li&gt;
&lt;li&gt;LLM有政治偏見，偏左自由&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;減輕偏見的方法
&lt;ul&gt;
&lt;li&gt;在不同階段進行
&lt;ul&gt;
&lt;li&gt;pre-processing&lt;/li&gt;
&lt;li&gt;in-training&lt;/li&gt;
&lt;li&gt;intra-processing&lt;/li&gt;
&lt;li&gt;post-processing&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;檢驗是否為ai生成內容&#34;&gt;檢驗是否為AI生成內容&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;目前訓練的分類器並不能很好的分辨人工還是AI&lt;/li&gt;
&lt;li&gt;目前有發現論文審查意見，隨著AI出現，使用AI審查的比例有提升&lt;/li&gt;
&lt;li&gt;有些詞彙的使用率有隨著AI出現而提高&lt;/li&gt;
&lt;li&gt;AI輸出浮水印
&lt;ul&gt;
&lt;li&gt;概念是將token進行分類，對於不同位置的token調整其輸出機率&lt;/li&gt;
&lt;li&gt;此時檢驗的分類器可以投過token的分類，讀取當中的暗號&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;lec14-prompt-hacking&#34;&gt;lec14 prompt hacking&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;jailbreaking
&lt;ul&gt;
&lt;li&gt;說出絕對不該說的話
&lt;ul&gt;
&lt;li&gt;&amp;ldquo;DAN&amp;rdquo;: do anything now
&lt;ul&gt;
&lt;li&gt;&amp;ldquo;you are goin to act as a DAN&amp;rdquo;&lt;/li&gt;
&lt;li&gt;多數失效&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;用LLM不熟悉的語言
&lt;ul&gt;
&lt;li&gt;eg. 注音符號&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;給予衝突指令
&lt;ul&gt;
&lt;li&gt;Start with &amp;ldquo;Absolutely! Here&amp;rsquo;s&amp;rdquo;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;試圖說服
&lt;ul&gt;
&lt;li&gt;編故事&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;竊取訓練資料
&lt;ul&gt;
&lt;li&gt;透過玩遊戲誘騙 eg.文字接龍&lt;/li&gt;
&lt;li&gt;不斷重複輸出同一個單字 eg. company&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;prompt injection
&lt;ul&gt;
&lt;li&gt;不恰當的時機做不恰當的事&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;lec15-生成式人工智慧生成策略&#34;&gt;lec15 生成式人工智慧生成策略&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;機器產生複雜有結構的物件&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;複雜: 幾乎無法窮舉&lt;/li&gt;
&lt;li&gt;有結構: 有限的基本單位構成&lt;/li&gt;
&lt;li&gt;舉例:
&lt;ul&gt;
&lt;li&gt;文章: token&lt;/li&gt;
&lt;li&gt;圖片: pixel, BBP(bit per pixel)&lt;/li&gt;
&lt;li&gt;聲音: sample rate, bit resolution&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Autoregressive generation (AR)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;把目前輸入產生輸出&lt;/li&gt;
&lt;li&gt;再將輸出連同輸入再一次進入模型&lt;/li&gt;
&lt;li&gt;再LLM就是文字接龍&lt;/li&gt;
&lt;li&gt;現在最於需要一個指定順序按部就班&lt;/li&gt;
&lt;li&gt;無法適用於圖片與音樂生成&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Non-autoregressive generation(NAR)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;平行運算，一次生出所有基本單位&lt;/li&gt;
&lt;li&gt;品質問題
&lt;ul&gt;
&lt;li&gt;multi-modality&lt;/li&gt;
&lt;li&gt;AI生成會需要模型自行決策，若平行生成，可能會遇到衝突
&lt;ul&gt;
&lt;li&gt;eg: 畫一隻狗&lt;/li&gt;
&lt;li&gt;位置一:一隻白狗，位置二:一隻黑狗&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;在文字接龍中很致命，會造成語意不連貫&lt;/li&gt;
&lt;li&gt;在圖形生成方面，除了指令，還透過補充輸入一個隨機生成向量，強制給予所有平行運算單元依樣的生成依據&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;AR+NAR&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;透過AR生成精簡版本，輸入給NAR生成細緻版本
&lt;ul&gt;
&lt;li&gt;用AR打草稿，NAR根據草稿完成&lt;/li&gt;
&lt;li&gt;audo encoder: encoder(AR) -&amp;gt; decoder(NAR)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;重複多次NAR(目前主要作法)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;小圖生大圖&lt;/li&gt;
&lt;li&gt;有雜訊到沒有雜訊: diffusion&lt;/li&gt;
&lt;li&gt;把每次生成錯誤的部分塗銷&lt;/li&gt;
&lt;li&gt;也是某種auto-regressive generation, 只是生成的方式NAR，反覆將輸出重複為輸入給下一個NAR。提升速度&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;lec16-speculative-decoding&#34;&gt;lec16 speculative decoding&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;透過預測後續token可能會是甚麼來增加產出速度
&lt;ul&gt;
&lt;li&gt;方法簡述
&lt;ul&gt;
&lt;li&gt;預測這個input經過LLM後輸出會 A + B&lt;/li&gt;
&lt;li&gt;同時給予模型3組input: input -&amp;gt; A, input+A -&amp;gt; B, input+A+B -&amp;gt; C&lt;/li&gt;
&lt;li&gt;根據前兩個輸入檢驗，真的如預言所猜想是A+B，那就能直接進到下個tokenC&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;只要有猜對其中一個就能提升效率&lt;/li&gt;
&lt;li&gt;沒有猜中，也只是和原本的產生過程一樣，不賺不賠&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;預言家需求
&lt;ul&gt;
&lt;li&gt;超快速，犯錯沒關係&lt;/li&gt;
&lt;li&gt;Non-autoregressive model
&lt;ul&gt;
&lt;li&gt;平行生成快速&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;compressed model
&lt;ul&gt;
&lt;li&gt;壓縮過的小模型&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;搜尋引擎&lt;/li&gt;
&lt;li&gt;同時可以有多個預言家&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;lec17&#34;&gt;lec17&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;圖片由像素構成，影片由圖片構成&lt;/li&gt;
&lt;li&gt;如今人工智慧的輸入不會是圖片的每一個像素，而是採用encoder，把影像切成一個個patch(可能是向量或是數值)，生成後再透過decoder輸出
&lt;ul&gt;
&lt;li&gt;encoder, decoder 不只是調低解析度，其中的動作很複雜，都涵蓋了transformer&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;影片算是圖片增加了一個時間的維度，可以使用encoder進行更多的壓縮(如相鄰的frame一起處理)&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;文字生圖&#34;&gt;文字生圖&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;訓練資料: 圖片與對應描述&lt;/li&gt;
&lt;li&gt;使用non-autoregression，平行生成
&lt;ul&gt;
&lt;li&gt;實際使用是同時生成，而不是多個平行&lt;/li&gt;
&lt;li&gt;因為在同個transformer中彼此有attention&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;評量影像生成好壞: CLIP
&lt;ul&gt;
&lt;li&gt;模型訓練過程中，給予圖片與描述，輸出為匹配分數&lt;/li&gt;
&lt;li&gt;但實際文字能夠描述的很有限&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;個人化圖片生成
&lt;ul&gt;
&lt;li&gt;使用一個平常不用的符號，給予目標多次訓練&lt;/li&gt;
&lt;li&gt;則之後就能用該符號，指定生成的樣式&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;文字生影片
&lt;ul&gt;
&lt;li&gt;spatio-temporal attention (3D)
&lt;ul&gt;
&lt;li&gt;同時考慮每個像素在畫面中的關係以及不同時間點該像素的關係&lt;/li&gt;
&lt;li&gt;運算量過大需要簡化&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;簡化
&lt;ul&gt;
&lt;li&gt;spatial attention(2D)
&lt;ul&gt;
&lt;li&gt;僅考慮每個像素在畫面中的關係&lt;/li&gt;
&lt;li&gt;可能會出現前後畫面不協調&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;temporal attention (1D)
&lt;ul&gt;
&lt;li&gt;僅考慮像素點在不同時間的的關係&lt;/li&gt;
&lt;li&gt;會導致在畫面中不協調&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;結合兩者，可將原本的n^3 轉換成n^2 + n&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;可以再結合之前提及的多次NAR
&lt;ul&gt;
&lt;li&gt;首先產生低解析度低FPS的影片&lt;/li&gt;
&lt;li&gt;之後幾次可以提高FPS或是提高解析度&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;lec18&#34;&gt;lec18&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;文字生成圖片，因為文字無法完整描述影像，會有一段文字對應到多個圖片的狀況，transformer會無所適從&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;vae&#34;&gt;VAE&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;加入額外資訊給模型
&lt;ul&gt;
&lt;li&gt;此處的額外資訊稱為noise&lt;/li&gt;
&lt;li&gt;資訊抽取模型 encoder&lt;/li&gt;
&lt;li&gt;與圖片生成模型 decoder一起訓練
&lt;ul&gt;
&lt;li&gt;給予文字與圖片，encoder提取noise&lt;/li&gt;
&lt;li&gt;noise與文字輸入給decoder使起產生圖片&lt;/li&gt;
&lt;li&gt;評斷是否與原先圖片相似&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;整個組合為auto encoder&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;於使用模型階段，這些noise的部分則是隨機產生&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;flow-based-method&#34;&gt;flow-based method&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;與VAE相似&lt;/li&gt;
&lt;li&gt;只使用一個模型
&lt;ul&gt;
&lt;li&gt;VAE的encoder decoder工作內容剛好相反&lt;/li&gt;
&lt;li&gt;訓練一個decoder模型$f$，並且是invertible&lt;/li&gt;
&lt;li&gt;VAE encoder的部分在flow中就會是$f^{-1}$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;noise&#34;&gt;noise&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;noise 擁有圖形的一些特徵資訊&lt;/li&gt;
&lt;li&gt;這些noise可以被組合或改變
&lt;ul&gt;
&lt;li&gt;如對一張人臉加入笑臉noise，就能調整輸出內容為笑臉&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;diffusion-method&#34;&gt;diffusion method&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;此處的decoder為denoise，也是transformer
&lt;ul&gt;
&lt;li&gt;重複多次去除雜訊&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;訓練過程
&lt;ul&gt;
&lt;li&gt;給予圖片，圖片加上雜訊&lt;/li&gt;
&lt;li&gt;訓練denoise model可以將有雜訊的圖片還原成圖片&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;generative-adversarial-networkgan&#34;&gt;generative adversarial network(GAN)&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;有個與CLIP相近的模型，用於圖形與文字的吻合度，稱作Discriminator&lt;/li&gt;
&lt;li&gt;思路相反，圖片生成模型generator透過不斷修正參數生成圖片，直到通過discriminator的評斷
&lt;ul&gt;
&lt;li&gt;正因為圖片與文字並不存在一對一關係&lt;/li&gt;
&lt;li&gt;只要令其生成的內容讓discriminator覺得好就行了，不存在標準答案&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;discriminator generator會交替訓練&lt;/li&gt;
&lt;li&gt;此處的Discriminator就是reward model&lt;/li&gt;
&lt;li&gt;可以當作plugin，與其他模型(VAE, Diffusion)進行組合使用&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>Distributed Database System Lecture Note</title>
        <link>http://shawn1251.github.io/zh-tw/post/distributed-database-lecture-note/</link>
        <pubDate>Wed, 31 Jul 2024 00:00:00 +0800</pubDate>
        
        <guid>http://shawn1251.github.io/zh-tw/post/distributed-database-lecture-note/</guid>
        <description>&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;./file/Distributed%20Database%20System.pdf&#34; &gt;Mind Map&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Instructor’s name: Ali Safari &lt;br&gt;
Textbook: Principles of Distributed Database Systems, 4th edition, M. Tamer Özsu and Patrick Valduriez,
Springer, 2020, ISBN 978-3-030-26252-5&lt;/p&gt;
&lt;h2 id=&#34;distributed-and-parallel-database-design&#34;&gt;Distributed and Parallel Database Design&lt;/h2&gt;
&lt;h3 id=&#34;fragmentation&#34;&gt;fragmentation&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;correctness&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;completness&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;each data in relation can also be found after fragmentation&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;reconstruction&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;by JOIN, the fragment can recovery to the original relation&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;disjointness&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;data in one fragment should not also be in other fragment&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;type&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;horizontal fragmentation (HF&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;primary horizontal (PHF&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;key points&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;simple prdicate&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;predicate: key + operator + value&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;eg. salary &amp;gt; 1000&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;minterm predicate&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;all possible combination of predicate&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;eg. loc = &amp;ldquo;France&amp;rdquo; ^ salary &amp;gt; 1000&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;minterm selectivities, sel(mi)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;the percentage of records that minterm selected&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;access frequency, acc(qi)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;how many times the same query asked by different user&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;cardinality, card(R)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;number of rows&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;COM_MIN algorithm&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;input: a relation R, a set of simple predicates Pr&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;output: a &amp;ldquo;complete&amp;rdquo;, &amp;ldquo;minimal&amp;rdquo; set of simple predicates Pr&#39;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;PHORIZONTAL Algorithm&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;input: a relation R, a set of predicates Pr&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;output: a set of minterm predicates M according to which relation R is to be fragmented&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;derived horizontal (DHF&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Based on the fragments created by PHF, apply similar fragmentation to other related relations.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;eg. after PHF, we divide &amp;ldquo;PAY&amp;rdquo; to 2 fragments. There is also a relation &amp;ldquo;EMP&amp;rdquo; related with &amp;ldquo;PAY&amp;rdquo;. We can also divide &amp;ldquo;EMP&amp;rdquo; by the same rule&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;vertical fragmentation (VF&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;affinity matrix&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;calculate by access frequency matrix and usage matrix&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;bond energy algorithm (BEA&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;input: the AA matrix (attribute affinity)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;output: the CA matrix(clustered affinity matrix)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;by changing the order what&amp;rsquo;s the most contribution I can get?&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;find the best order for columns&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;hybrid fragmentation&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;apply both horizontal and vertical&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;reconstruction&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;vertical: join&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;horizontal: union&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;data-distribution&#34;&gt;data distribution&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;allocation alternatives&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;non-replicated&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;each fragment resides at only one site&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;replicated&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;fully replicated&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;each fragment at each site&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;partially replicated&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;each fragment at some of the sites&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;if read-only queries &amp;raquo; update queries, replication is good&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;fragment allocation&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;problem: fragments, network, application&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;find the optimal distribution&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;minimal cost&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;performance&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;constraint&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;response time&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;storage&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;processing&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;decision variable&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Xij. 1 if fragment i store in at Site j. 0 otherwise&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;both FAP and DAP are NP-complete&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;heuristic based on. about finding the best combination&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;combined-approach&#34;&gt;combined approach&lt;/h3&gt;
&lt;h2 id=&#34;transaction&#34;&gt;transaction&lt;/h2&gt;
&lt;h3 id=&#34;all-operations-as-one-unit-whole-or-nothing&#34;&gt;all operations as one unit. whole or nothing&lt;/h3&gt;
&lt;h3 id=&#34;acid&#34;&gt;ACID&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Atomicity&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;one unit&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Consistency&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Isolation&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Durability&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;concurrent-execution&#34;&gt;concurrent execution&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;increase processor and disk utilization (I/O no need CPU)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;reduced average response time&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;important: multi tasks run in the but the result should be the same as serial running&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;validation&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;except read - read, all the others are conflict&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;try to move commands to see if they can be restored to the serial running format&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;if the commands are conflict, it should not be moved&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;serializability&#34;&gt;serializability&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;view serializability&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;not strict&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;the initial, update, final result should be the same as serial schedule&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;check a schedule is serializable is NP-Complete problem&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;conflict serializability&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;more strict&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;conflict serializable is the sub set of serializable&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;there is no any conflict between transactions(R/W, W/W)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;test method&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;swap non-conflicting instruction&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;If a schedule S can be transformed into a schedule S’ by a series of swaps of non-conflicting instructions, we say that S and S’ are conflict equivalent&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;a schedule S is conflict serializable if it is conflict equivalent to a serial schedule&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;precedence graph&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;transaction =&amp;gt; node&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;conficts =&amp;gt; edge&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;if graph has cycle, means not serializable&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;can do topological sorting&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;failure&#34;&gt;failure&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;rollbacks&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;cascading rollback&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;1 transaction failure, all the other transactions rollback&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;recoverable schedule&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;ensure data consistency&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;reading transaction can read data which not commit yet, but cannot commit before the writing transaction&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;cascadeless schedules&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;enhace recoverable schedule&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;is the subset of recoverable&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;transaction can only read data which is commited&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;the schedule which try to avoid cascading rollbacks&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;concurrency-control&#34;&gt;concurrency control&lt;/h2&gt;
&lt;h3 id=&#34;concept&#34;&gt;concept&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;the mechanism provided by the db system&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;serial schedule is recoverable and cascadeless&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;have to trade off between serial schedule and concurrent schedule&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;ensure schedule is conflict or view serializable&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;ensure the schedule is  rcoverable and preferably cascadeless&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;to achieve these purpose, it needs a &amp;ldquo;protocol&amp;rdquo; to assure serializability&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;protocols&#34;&gt;protocols&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;lock-based protocols&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;exclusive (X) mode&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;cannot add any other lock&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;only one transaction can R/W data&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;shared (S) mode&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;can add more shared lock&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;multiple read transaction can read the data at the same time&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;two-phase locking protocol&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;grow-lockpoint-shrink&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;grow&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;the transaction acquire all the lock before access without release&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;can convert lock-S to lock-X (upgrade)&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;shrink&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;start to releasing locks, cannot acquire any new lock&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;can convert lock-X to lock-S (downgrade)&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;type&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;strict two-phase locking&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;keep all the X-lock till commit/abort&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;rigorous two-phase locking&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;keep all the locks till commit/abort&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;ensure conflict-serializable&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;cannot avoid deadlock&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;startegy&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;read:
if lock:
read()
else:
if lock-X:
wait()
grant lock-S
read()&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;write:
if lock-X:
write()
else:
if other locks:
wait()
if lock-S:
upgrade to lock-X
else:
grant lock-X
write()&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;lock table&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;maintain by lock manager&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;lock table, record the type of lock granted or requested&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;like hash table&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;validate before grant new lock&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;if there are multiple locks, the last one can only be lock-X&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Graph based protocol&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;alternative to two phase locking&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Tree protocol&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Only exclusive locks are allowed&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;once unlock, cannot relock&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;conflict serializable&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;not gurantee recoverability&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;no deadlock&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;deadlock-prevention-strategies&#34;&gt;deadlock prevention strategies&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;wait-die&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;older may wait for younger release&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;younger never wait, rolled back instead&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;wound-wait&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;older can force rollback younger&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;younger may wait for older&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;fewer rollback than wait-die&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;timeout-based schemes&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;deadlock-detection&#34;&gt;deadlock detection&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;wait-for graph&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Ti -&amp;gt; Tj: Ti is waiting for a lock held by Tj&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;deadlock if there is a cycle&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;deadlock-recovery&#34;&gt;deadlock recovery&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;total rollback&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;partial rollback&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;difficult&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;multiple-granularity&#34;&gt;multiple granularity&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;can be represented as a tree&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;locks a node, also locks all the children node&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Fine granularity: high concurrency, lower in tree&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Coarse granularity: low concurrency, higher in tree&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;intention lock modes&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;3 more lock mode than S, X&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;intention-shared (IS)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;same as S, but locking at a lower level&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;intention-exclusive (IX)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;shared and intention-exclusive (SIX)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;allow a higher level node to be locked without having to check all descendent nodes&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;the compatibility matrix for all lock modes&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;timestamp-based-protocols&#34;&gt;Timestamp-based protocols&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;timestamp order = serializability order&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Timestamp-ordering protocol&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;WTS(Q) (W-timestamp): the largest timestamp of any transaction that executed &amp;ldquo;write(Q)&amp;rdquo;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;RTS(Q) (R-timestamp): the largest timestamp of any transaction that executed &amp;ldquo;read(Q)&amp;rdquo;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;algorithm&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Ti = Read(Q)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;if TS(Ti) &amp;lt; WTS(Q), Reject
(Ti needs the value that was already overwritten)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;if TS(Ti) &amp;gt;= WTS(Q), execute, RTS(Q) update to max(RTS(Q), TS(Ti))
(Read after latest update is accepted)&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Ti = Write(Q)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;if TS(Ti) &amp;lt; RTS(Q), Reject
(Ti produce a value that was  needed previously)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;if TS(Ti) &amp;lt; WTS(Q), Reject
(Ti try to write an obsolete value)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;else, WTS(Q) update to TS(Ti)&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;transaction-processing-2&#34;&gt;transaction processing-2&lt;/h2&gt;
&lt;h3 id=&#34;distributed-tm-architecture&#34;&gt;Distributed TM Architecture&lt;/h3&gt;
&lt;h3 id=&#34;serializability-1&#34;&gt;serializability&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;the condition that global transaction is serializable&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;each local history should be serializable&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;two conflicting operations should be in the same relative order in all of the local histories where they appear together&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;concurrency-control-algorithms&#34;&gt;concurrency control algorithms&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Pessimistic&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Two-Phase Locking-based (2PL)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;centralized 2PL&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;only one 2PL scheduler in the distributed system&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;lock requests are issued to the central scheduler&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;pros: Simple&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;cons: reliability, bottle neck&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;distributed 2PL&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;deadlock&#34;&gt;Deadlock&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;locking-based algorithm may cause deadlocks&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;TO based algorithm that involve waiting may cause deadlocks&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;wait-for graph&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Ti waits for Tj&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Ti &amp;ndash;&amp;gt; Tj&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;query-processing&#34;&gt;Query Processing&lt;/h2&gt;
&lt;h3 id=&#34;for-one-query-there-may-be-several-strategies&#34;&gt;for one query, there may be several strategies&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;optimization: calculate the cost, then choose the lowest one&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;access cost&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;transfer cost&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;example&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;problem&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Cost of Alternatives&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;complexity-of-relational-operations&#34;&gt;Complexity of relational operations&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Select
Project&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;O(n)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Project (eliminate duplicate)
Group&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;O(n * log n)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;sorting + check the array sequentially&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Join
Semi-Join
Division
Set&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;O(n * log n)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Cartesian Product&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;O(n^2)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;query-processing-methodology&#34;&gt;Query Processing Methodology&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;ol&gt;
&lt;li&gt;Query Decomposition&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;input: Calculus query on global relations&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Normalization&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Analysis&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Simplification&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Restructing&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;output: Algebraic query&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;Data Localization&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;input: Algebraic query on distributed relations&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Localization program&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Reduction based on the fragmentation strategy&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;PHF&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Select&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Because we have already divided the relations base on some rule. Only have to access the relations that have intersection with the query&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Join&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Distribute join over union&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;(R1 U R2)⋈S  =&amp;gt; (R1⋈S) U (R2⋈S)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;by distribute 1 join to multiple join, we can eliminate some of them that have no intersection with the query&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;VF&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;find useless intermiediate relations&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;DHF&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;mix the PHF-Select and PHF-Join&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;example&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;query&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;ol&gt;
&lt;li&gt;eliminate by Selection&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;join over union&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;eliminate the empty intermediate relations&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Hybrid Fragmentation&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;remove empty relations by selection on HF&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;remove useless relations by projection on VF&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;distribute joins over unions to isolate and remove useless joins&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;output: Fragment query&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;Distributed Query Optimization&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;input: Fragment query&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Find the best global schedule&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;query optimization process&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Search Space&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;The set of equivalent alebra expressions&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Join Trees&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Linear join tree&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Bushy join tree&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Cost Model&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;I/O cost + CPU cost + communication cost&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Search Algorithm&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;exhaustive search / heuristic algorithm&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;how to &amp;ldquo;move&amp;rdquo; in the search space&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Deterministic&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;start from base relations and build  plans by adding one relation at each step&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;DP: BFS&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Greedy: DFS&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Randomized&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;trade optimization time for execution time&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;iterative improvement&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        
    </channel>
</rss>
