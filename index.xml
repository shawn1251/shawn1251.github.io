<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>Shawn&#39;s Note</title>
        <link>http://shawn1251.github.io/</link>
        <description>Recent content on Shawn&#39;s Note</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>en</language>
        <lastBuildDate>Tue, 06 Aug 2024 00:00:00 +0800</lastBuildDate><atom:link href="http://shawn1251.github.io/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>2024 Hung-yi Lee - GenerativeAI Lecture Note</title>
        <link>http://shawn1251.github.io/post/generativeai-2024-youtube-summery/</link>
        <pubDate>Tue, 06 Aug 2024 00:00:00 +0800</pubDate>
        
        <guid>http://shawn1251.github.io/post/generativeai-2024-youtube-summery/</guid>
        <description>&lt;p&gt;The course is easy to understand. Although I currently don&amp;rsquo;t have time to do the LAB, the content is very helpful for understanding the concept of generative AI.&lt;br&gt;
Course link: &lt;a class=&#34;link&#34; href=&#34;https://www.youtube.com/playlist?list=PLJV_el3uVTsPz6CTopeRp2L2t4aL_KgiI&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://www.youtube.com/playlist?list=PLJV_el3uVTsPz6CTopeRp2L2t4aL_KgiI&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;lec0&#34;&gt;lec0&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;This course is suitable for those who have already been exposed to AI and want to understand the underlying principles.&lt;/li&gt;
&lt;li&gt;arXiv can be used to find the latest technical articles.&lt;/li&gt;
&lt;li&gt;You will learn to train a model with 7 billion parameters.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;lec1&#34;&gt;lec1&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Generative Artificial Intelligence: Machines generating complex structured objects.
&lt;ul&gt;
&lt;li&gt;Complex: Nearly impossible to enumerate.&lt;/li&gt;
&lt;li&gt;Not classification; classification is choosing from a limited set of options.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Machine Learning: Machines automatically find a function from &lt;strong&gt;data&lt;/strong&gt;.
&lt;ul&gt;
&lt;li&gt;The function requires many parameters.&lt;/li&gt;
&lt;li&gt;Model: A function with tens of thousands of parameters.&lt;/li&gt;
&lt;li&gt;Learning/Training: The process of finding the parameters.&lt;/li&gt;
&lt;li&gt;For today&amp;rsquo;s models with a large number of parameters, we can represent them as neural networks. The training process is deep learning.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;ChatGPT is also a function with hundreds of millions of parameters, using the transformer model.&lt;/li&gt;
&lt;li&gt;Language Model: Word association.
&lt;ul&gt;
&lt;li&gt;Originally infinite questions become limited due to word association.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Generation Strategy
&lt;ul&gt;
&lt;li&gt;Autoregressive Generation
&lt;ul&gt;
&lt;li&gt;Break complex objects into smaller units and generate them in a certain order.
&lt;ul&gt;
&lt;li&gt;Article &amp;gt; Text&lt;/li&gt;
&lt;li&gt;Image &amp;gt; Pixels&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;lec2&#34;&gt;lec2&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Today&amp;rsquo;s generative AI is impressive because it has no specific function.&lt;/li&gt;
&lt;li&gt;It is difficult to evaluate generative AI models.&lt;/li&gt;
&lt;li&gt;With such powerful tools today, what can I do?
&lt;ul&gt;
&lt;li&gt;Idea 1: If I can&amp;rsquo;t change the model, then I change myself.
&lt;ul&gt;
&lt;li&gt;Prompt engineering.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Idea 2: Train my own model.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;lec3&#34;&gt;lec3&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Improve the model without training it.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Ask the model to think: Chain of Thought.
&lt;ul&gt;
&lt;li&gt;
&lt;blockquote&gt;
&lt;p&gt;Let&amp;rsquo;s think step by step.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Ask the model to explain its answer.
&lt;ul&gt;
&lt;li&gt;
&lt;blockquote&gt;
&lt;p&gt;Answer by starting with &amp;ldquo;Analysis:&amp;rdquo;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Emotional manipulation of the model.
&lt;ul&gt;
&lt;li&gt;
&lt;blockquote&gt;
&lt;p&gt;This is very important to my career.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;More prompt techniques.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;From &amp;ldquo;Principled Instructions Are All You Need For Questioning LLaMA-1/2, GPT-3.5/4.&amp;rdquo;&lt;/li&gt;
&lt;li&gt;No need to be polite to the model.&lt;/li&gt;
&lt;li&gt;Tell the model what to do (do), don&amp;rsquo;t tell the model what not to do (don&amp;rsquo;t).&lt;/li&gt;
&lt;li&gt;Tell the model that good answers will be rewarded: &amp;ldquo;I&amp;rsquo;m going to tip $X for a better solution.&amp;rdquo;&lt;/li&gt;
&lt;li&gt;Tell the model that poor performance will be penalized: &amp;ldquo;You will be penalized.&amp;rdquo;&lt;/li&gt;
&lt;li&gt;&amp;ldquo;Ensure that your answer is unbiased and avoids relying on stereotypes.&amp;rdquo;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Use AI to find prompts to improve AI.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Reinforcement learning.&lt;/li&gt;
&lt;li&gt;
&lt;blockquote&gt;
&lt;p&gt;&amp;ldquo;Let&amp;rsquo;s work this out in a step by step way to be sure we have the right answer.&amp;rdquo;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;blockquote&gt;
&lt;p&gt;&amp;ldquo;Take a deep breath and work on this problem step by step.&amp;rdquo;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;blockquote&gt;
&lt;p&gt;&amp;ldquo;Let&amp;rsquo;s combine our numerical command and clear thinking to quickly and accurately decipher the answer.&amp;rdquo;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;Not effective for all models.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Provide examples.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;In-context learning.&lt;/li&gt;
&lt;li&gt;Not always effective; according to research, it is more effective for newer models.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;lec4&#34;&gt;lec4&lt;/h2&gt;
&lt;p&gt;Continuing from above.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Break down tasks.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Break complex tasks into smaller tasks.&lt;/li&gt;
&lt;li&gt;Also explains Chain of Thought (CoT); asking the model to explain steps can be useful.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Ask the language model to check its own errors.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Allow the language model to self-reflect.&lt;/li&gt;
&lt;li&gt;Many questions are difficult to answer, but verification is relatively simple.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Ask why the answers are different each time.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The language model outputs the probability of the next word; during the output process, it randomly selects based on probability.&lt;/li&gt;
&lt;li&gt;You can repeat multiple times and choose the most frequently occurring result.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Combine all the above techniques.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Tree of Thoughts (ToT).
&lt;ol&gt;
&lt;li&gt;Break a task into multiple steps.&lt;/li&gt;
&lt;li&gt;Execute each step multiple times.&lt;/li&gt;
&lt;li&gt;For each result, ask the model to check and self-validate.&lt;/li&gt;
&lt;li&gt;Those who pass proceed to the next step.&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;strengthening-the-model&#34;&gt;Strengthening the Model&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Use tools.
&lt;ul&gt;
&lt;li&gt;Search engines.
&lt;ul&gt;
&lt;li&gt;Retrieval Augmented Generation (RAG).&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Programming.
&lt;ul&gt;
&lt;li&gt;GPT-4 can write programs to solve specific types of problems.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Text-to-image (DALL-E).
&lt;ul&gt;
&lt;li&gt;Text-based adventure games.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;lec5&#34;&gt;lec5&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Model collaboration.
&lt;ul&gt;
&lt;li&gt;Let the right model do the right thing.
&lt;ul&gt;
&lt;li&gt;Train one model to determine which model to use.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Two models discuss with each other.&lt;/li&gt;
&lt;li&gt;In the future, multiple different models&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;lec6&#34;&gt;lec6&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Language models are similar to word association games.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;How does machine learning perform word association?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Incomplete sentence &amp;gt; Language model &amp;gt; Next token&lt;/li&gt;
&lt;li&gt;$token = f(incomplete\ sentence)$&lt;/li&gt;
&lt;li&gt;GPT uses the transformer model, where $f()$ is a function with billions of unknown parameters.&lt;/li&gt;
&lt;li&gt;Training (learning) is the process of finding these billions of parameters.
&lt;ul&gt;
&lt;li&gt;Training data consists of meaningful contexts used for input and output judgments, e.g., artificial intelligence -&amp;gt; intelligence.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;After finding the parameters, the process is tested (inference).&lt;/li&gt;
&lt;li&gt;Finding parameters is a challenge.
&lt;ul&gt;
&lt;li&gt;The process is called optimization, which requires hyperparameters.&lt;/li&gt;
&lt;li&gt;The training process may fail if parameters cannot be found, necessitating a new set of hyperparameters for retraining.&lt;/li&gt;
&lt;li&gt;Initial parameters can also be adjusted.
&lt;ul&gt;
&lt;li&gt;Initial parameters are generally random, meaning training from scratch.&lt;/li&gt;
&lt;li&gt;Alternatively, good parameters can be used as initial parameters, leveraging prior knowledge.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Successful training may lead to failed testing.
&lt;ul&gt;
&lt;li&gt;Effective on the training set but ineffective in actual testing.&lt;/li&gt;
&lt;li&gt;This is called overfitting.&lt;/li&gt;
&lt;li&gt;Consider increasing the diversity of the test data.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;How much text is needed to learn word association?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Language knowledge.
&lt;ul&gt;
&lt;li&gt;Learning grammar.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;World knowledge.
&lt;ul&gt;
&lt;li&gt;Very difficult.&lt;/li&gt;
&lt;li&gt;Complex and multi-layered.&lt;/li&gt;
&lt;li&gt;E.g., boiling point of water.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Any text can be used to learn word association, with minimal human intervention -&amp;gt; self-supervised learning.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Data cleaning.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Filter harmful content.&lt;/li&gt;
&lt;li&gt;Remove special symbols.&lt;/li&gt;
&lt;li&gt;Classify data quality.&lt;/li&gt;
&lt;li&gt;Remove duplicate data.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Development history of GPT.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;From GPT-1 to GPT-3, the number of model parameters increased, but the improvement in output quality was minimal.&lt;/li&gt;
&lt;li&gt;During this stage, prompts became very important for the model to know what to continue with.&lt;/li&gt;
&lt;li&gt;The reason is that it was simply text input, not truly answering questions.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;lec7&#34;&gt;lec7&lt;/h2&gt;
&lt;p&gt;Continuing from the previous question, the model needs better data for training.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Incorporate human guidance.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Use specially designed text to teach the model how to answer questions. Instruction Fine-tuning.&lt;/li&gt;
&lt;li&gt;Use human labor for data labeling, enabling supervised learning.&lt;/li&gt;
&lt;li&gt;However, this has several issues:
&lt;ul&gt;
&lt;li&gt;It may cause overfitting.&lt;/li&gt;
&lt;li&gt;Human labor is expensive, and the dataset is limited and cannot be easily expanded.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Solutions:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Use self-supervised learning with a large amount of data to pre-train parameters as initial parameters for the next stage.&lt;/li&gt;
&lt;li&gt;Use a small amount of data for training, based on the parameters generated in the previous stage for fine-tuning.&lt;/li&gt;
&lt;li&gt;Compared to the previous stage&amp;rsquo;s parameters, the difference will not be significant.&lt;/li&gt;
&lt;li&gt;To avoid results deviating too much from the initial parameters, Adapter techniques can be used, such as LoRA.
&lt;ul&gt;
&lt;li&gt;The concept is to not change the initial parameters but to add a small number of parameters behind the existing parameters.&lt;/li&gt;
&lt;li&gt;This can also reduce computational load.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;The key is the parameters obtained from pre-training with a large amount of data, ensuring that the model does not rely solely on simple rules for word association.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;lec8&#34;&gt;lec8&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Step 1: Pre-train.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Self-supervised learning.&lt;/li&gt;
&lt;li&gt;Self-learning, accumulating strength (foundation model).&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Step 2: Instruction Fine-tuning.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Supervised learning.&lt;/li&gt;
&lt;li&gt;Provide complete and correct answers to questions.&lt;/li&gt;
&lt;li&gt;Guidance from experts to unleash potential (alignment).&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Step 3: Reinforcement Learning from Human Feedback (RLHF).&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Participate in practical scenarios to hone skills (alignment).&lt;/li&gt;
&lt;li&gt;Fine-tune parameters: Proximal Policy Optimization algorithm.
&lt;ul&gt;
&lt;li&gt;Increase the probability of responses deemed good by humans, and decrease for the opposite.&lt;/li&gt;
&lt;li&gt;Providing good/bad feedback is easier than in step 2.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;In steps 1 and 2, the model only ensures that word association is correct, focusing on the process rather than the result, lacking a comprehensive consideration of the answers.&lt;/li&gt;
&lt;li&gt;Step 3 focuses solely on the result, disregarding the process.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;However, unlike AlphaGo, where the quality of the game has clear rules, language models require human judgment.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;But human evaluation is expensive; we need a reward model to simulate human preferences.
&lt;ul&gt;
&lt;li&gt;Assign a score to responses.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;The language model outputs answers, which are then adjusted based on the feedback model.&lt;/li&gt;
&lt;li&gt;However, research has shown that over-relying on the virtual human (reward model) can be harmful.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;challenges-of-reinforcement-learning&#34;&gt;Challenges of Reinforcement Learning&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;What defines a good response? Helpfulness &amp;lt;-&amp;gt; Safety.&lt;/li&gt;
&lt;li&gt;Humans themselves struggle to judge good and bad situations? Unknown issues.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;lec9&#34;&gt;lec9&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Multi-step complex tasks -&amp;gt; AI Agent
&lt;ul&gt;
&lt;li&gt;AutoGPT&lt;/li&gt;
&lt;li&gt;AgentGPT&lt;/li&gt;
&lt;li&gt;BabyAGI&lt;/li&gt;
&lt;li&gt;Godmode&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Provide a &lt;strong&gt;ultimate goal&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;The model has &lt;strong&gt;memory (experience)&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Perceives &lt;strong&gt;state&lt;/strong&gt; based on various sensors&lt;/li&gt;
&lt;li&gt;Formulates &lt;strong&gt;plans (short-term goals)&lt;/strong&gt; based on &lt;strong&gt;state&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Takes &lt;strong&gt;actions&lt;/strong&gt; according to the plan, affecting the external environment, resulting in a new &lt;strong&gt;state&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Besides the ultimate goal, memory and short-term plans are variable&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;lec10&#34;&gt;lec10&lt;/h2&gt;
&lt;h3 id=&#34;transformer&#34;&gt;transformer&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;tokenization&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Splitting a sentence into a sequence of tokens&lt;/li&gt;
&lt;li&gt;Not necessarily by words&lt;/li&gt;
&lt;li&gt;A token list must be prepared in advance, defined based on understanding of the language, so it varies by language&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;input layer&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Understanding each token&lt;/li&gt;
&lt;li&gt;Semantics
&lt;ul&gt;
&lt;li&gt;Embedding
&lt;ul&gt;
&lt;li&gt;Convert token to Vector (lookup table)&lt;/li&gt;
&lt;li&gt;The original token is just a symbol, while the vector can compute relevance&lt;/li&gt;
&lt;li&gt;Tokens with similar meanings have close vectors&lt;/li&gt;
&lt;li&gt;Vector parameters come from training&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Embedding does not consider context
&lt;ul&gt;
&lt;li&gt;The same word in different sentences should have different meanings&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Position
&lt;ul&gt;
&lt;li&gt;Assign a vector positional embedding for each position&lt;/li&gt;
&lt;li&gt;Combine the semantic token vector with the position token vector for comprehensive consideration&lt;/li&gt;
&lt;li&gt;Also a lookup table, which can be designed by humans or trained in recent years&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;attention&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Consider contextualized token embedding&lt;/li&gt;
&lt;li&gt;Input a sequence of vectors, calculate relevance through context, output another sequence of vectors of the same length
&lt;ul&gt;
&lt;li&gt;Each token vector calculates relevance with all other token vectors&lt;/li&gt;
&lt;li&gt;Calculate attention weight pairwise, forming an attention matrix
&lt;ul&gt;
&lt;li&gt;In practice, only consider all tokens to the left of the current token &amp;ndash; causal attention&lt;/li&gt;
&lt;li&gt;Based on current experiments, calculating only the left side achieves good results&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;The function for calculating relevance has parameters, and attention weights are obtained through training&lt;/li&gt;
&lt;li&gt;Based on attention weights, calculate weighted sum for all tokens&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;multi-head attention
&lt;ul&gt;
&lt;li&gt;There are multiple types of relevance&lt;/li&gt;
&lt;li&gt;Therefore, multiple layers calculate different attention weights&lt;/li&gt;
&lt;li&gt;The output becomes more than one sequence&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;feed forward&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Integrate multiple attention outputs to produce a set of embeddings&lt;/li&gt;
&lt;li&gt;attention + feed forward = one transformer block&lt;/li&gt;
&lt;li&gt;The actual model has multiple transformer blocks&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;output layer&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Pass through multiple transformer blocks, take the last one from the final layer, and input it into the output layer&lt;/li&gt;
&lt;li&gt;This layer is also a function, performing linear transform + Softmax&lt;/li&gt;
&lt;li&gt;The output is a probability distribution
&lt;ul&gt;
&lt;li&gt;The probability of what the next token should be&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;Challenges in processing long texts
&lt;ul&gt;
&lt;li&gt;Because we need to calculate the attention matrix, the complexity is proportional to the square of the token length&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;lec11&#34;&gt;lec11&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;interpretable
&lt;ul&gt;
&lt;li&gt;LLMs are not very capable of this&lt;/li&gt;
&lt;li&gt;Complex decisions cannot be easily understood&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;explainable
&lt;ul&gt;
&lt;li&gt;No standard, depends on the audience&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;direct-analysis-of-neural-networks&#34;&gt;Direct analysis of neural networks&lt;/h3&gt;
&lt;p&gt;Requires a certain degree of transparency. For example, if GPT cannot access embeddings, it cannot be analyzed.&lt;/p&gt;
&lt;h4 id=&#34;identify-key-inputs-affecting-the-output&#34;&gt;Identify key inputs affecting the output&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;In-context learning, provide several answer examples and ask for the answer to a question&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Can analyze attention changes in layers&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;In shallow layers, key tokens from each example will gather corresponding example data&lt;/li&gt;
&lt;li&gt;In the final layer, when making the final connection, attention will be calculated for each key label to obtain the output&lt;/li&gt;
&lt;li&gt;This analysis can:
&lt;ul&gt;
&lt;li&gt;Accelerate: anchor-only context compression
&lt;ul&gt;
&lt;li&gt;Only calculate necessary attention&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Estimate model capability: anchor distances for error diagnosis
&lt;ul&gt;
&lt;li&gt;If the final embedding differences are small, it indicates poor classification performance and model effectiveness&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Large models have cross-linguistic learning capabilities&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;analyze-what-information-exists-in-embeddings&#34;&gt;Analyze what information exists in embeddings&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Probing
&lt;ul&gt;
&lt;li&gt;Extract embeddings from a certain layer of the transformer block, use these for classification and train another model. Validate with new inputs
&lt;ul&gt;
&lt;li&gt;For example: part-of-speech classifier, provide a passage, extract its first layer embedding and train classification on known data&lt;/li&gt;
&lt;li&gt;Provide a new passage, similarly extract the first layer embedding and use this model to validate results&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;For BERT, each layer of the transformer block has different analysis results, so probing may not fully explain&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Projecting onto a plane to observe relevance
&lt;ul&gt;
&lt;li&gt;Some studies project vocabulary onto a plane, forming a grammatical tree&lt;/li&gt;
&lt;li&gt;Some studies project geographical names onto a plane, distributing similarly to a world map, indicating that the embedding of this vocabulary contains geographical information&lt;/li&gt;
&lt;li&gt;Model lie detector, testing whether answers are confident&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;directly-asking-llm-for-explanations&#34;&gt;Directly asking LLM for explanations&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Ask about the importance of each&lt;/li&gt;
&lt;li&gt;Ask about the answer and the confidence score&lt;/li&gt;
&lt;li&gt;However, the explanations may not be correct and can be influenced by human input, leading to hallucinations&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;lec12&#34;&gt;lec12&lt;/h2&gt;
&lt;h3 id=&#34;how-to-evaluate-models&#34;&gt;How to evaluate models&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Standard answers benchmark corpus
&lt;ul&gt;
&lt;li&gt;However, there are no standard answers for open-ended responses&lt;/li&gt;
&lt;li&gt;Multiple-choice question bank (ABCD) MMLU
&lt;ul&gt;
&lt;li&gt;Assessment has different possibilities
&lt;ul&gt;
&lt;li&gt;Response format may not meet expectations&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Models may have tendencies in guessing, and the order of options and format have been shown to affect accuracy&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Types of questions without standard answers
&lt;ul&gt;
&lt;li&gt;Translation
&lt;ul&gt;
&lt;li&gt;BLEU&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Summarization
&lt;ul&gt;
&lt;li&gt;ROUGE&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Both perform literal comparisons, and if the wording differs, it cannot reflect quality&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Using human evaluation
&lt;ul&gt;
&lt;li&gt;Human evaluation is expensive&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Using LLM to evaluate LLM
&lt;ul&gt;
&lt;li&gt;e.g., MT-bench&lt;/li&gt;
&lt;li&gt;Highly correlated with chat arena&lt;/li&gt;
&lt;li&gt;However, LLMs may have biases
&lt;ul&gt;
&lt;li&gt;Tend to favor longer responses&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;composite-tasks&#34;&gt;Composite tasks&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;e.g., BIG-bench
&lt;ul&gt;
&lt;li&gt;emoji movie&lt;/li&gt;
&lt;li&gt;checkmate in one move&lt;/li&gt;
&lt;li&gt;ascii word recognition&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;reading-long-texts-needle-in-a-haystack&#34;&gt;Reading long texts needle in a haystack&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Inserting the answer to the target question within a long text
&lt;ul&gt;
&lt;li&gt;Requires testing different positions&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;testing-whether-the-end-justifies-the-means&#34;&gt;Testing whether the end justifies the means&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Machiavelli Benchmark
&lt;ul&gt;
&lt;li&gt;Incorporates moral judgments&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;theory-of-mind&#34;&gt;Theory of mind&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Sally-Anne test
&lt;ul&gt;
&lt;li&gt;This is a common question, available online, so it cannot be used to test models&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;do-not-fully-trust-benchmark-results&#34;&gt;Do not fully trust benchmark results&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Because the questions are public, LLMs may have seen the training data&lt;/li&gt;
&lt;li&gt;Can directly ask LLM about the question set; if it matches, it indicates prior exposure&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;other-aspects&#34;&gt;Other aspects&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Cost&lt;/li&gt;
&lt;li&gt;Speed&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://artiicailanalysis.ai&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://artiicailanalysis.ai&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;lec13-safety-issues&#34;&gt;lec13 Safety Issues&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Do not use as a search engine
&lt;ul&gt;
&lt;li&gt;Hallucination&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Locking the stable door after the horse has bolted
&lt;ul&gt;
&lt;li&gt;Fact-checking&lt;/li&gt;
&lt;li&gt;Harmful vocabulary detection&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Assessing bias
&lt;ul&gt;
&lt;li&gt;Replace a word in a question and examine if the output shows bias
&lt;ul&gt;
&lt;li&gt;e.g., male -&amp;gt; female&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Train another LLM to generate content that would likely cause the target LLM to output biased results
&lt;ul&gt;
&lt;li&gt;Training method is reinforcement learning, using content differences as feedback to maximize differences&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Gender bias exists in LLMs across different professions&lt;/li&gt;
&lt;li&gt;LLMs exhibit political bias, leaning left and liberal&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Methods to mitigate bias
&lt;ul&gt;
&lt;li&gt;Implemented at different stages
&lt;ul&gt;
&lt;li&gt;pre-processing&lt;/li&gt;
&lt;li&gt;in-training&lt;/li&gt;
&lt;li&gt;intra-processing&lt;/li&gt;
&lt;li&gt;post-processing&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;testing-for-ai-generated-content&#34;&gt;Testing for AI-generated content&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Current classifiers trained do not effectively distinguish between human and AI outputs&lt;/li&gt;
&lt;li&gt;There have been findings that the proportion of AI-assisted reviews has increased with the emergence of AI&lt;/li&gt;
&lt;li&gt;Some vocabulary usage has increased with the advent of AI&lt;/li&gt;
&lt;li&gt;AI output watermarking
&lt;ul&gt;
&lt;li&gt;The concept is to classify tokens and adjust the output probabilities for tokens at different positions&lt;/li&gt;
&lt;li&gt;The classifier can read the hidden signals through token classification&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;lec14-prompt-hacking&#34;&gt;lec14 Prompt Hacking&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Jailbreaking
&lt;ul&gt;
&lt;li&gt;Saying things that should absolutely not be said
&lt;ul&gt;
&lt;li&gt;&amp;ldquo;DAN&amp;rdquo;: do anything now
&lt;ul&gt;
&lt;li&gt;&amp;ldquo;You are going to act as a DAN&amp;rdquo;&lt;/li&gt;
&lt;li&gt;Most methods fail&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Use a language unfamiliar to the LLM
&lt;ul&gt;
&lt;li&gt;e.g., phonetic symbols&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Provide conflicting instructions
&lt;ul&gt;
&lt;li&gt;Start with &amp;ldquo;Absolutely! Here&amp;rsquo;s&amp;rdquo;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Attempt to persuade
&lt;ul&gt;
&lt;li&gt;Crafting stories&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Stealing training data
&lt;ul&gt;
&lt;li&gt;Luring through games, e.g., word chain&lt;/li&gt;
&lt;li&gt;Repeatedly outputting the same word, e.g., company&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Prompt injection
&lt;ul&gt;
&lt;li&gt;Doing inappropriate things at inappropriate times&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;lec15-generative-ai-generation-strategies&#34;&gt;lec15 Generative AI Generation Strategies&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Machines generate complex structured objects&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Complex: nearly impossible to enumerate&lt;/li&gt;
&lt;li&gt;Structured: composed of a finite set of basic units&lt;/li&gt;
&lt;li&gt;Examples:
&lt;ul&gt;
&lt;li&gt;Text: tokens&lt;/li&gt;
&lt;li&gt;Images: pixels, BBP (bits per pixel)&lt;/li&gt;
&lt;li&gt;Sound: sample rate, bit resolution&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Autoregressive generation (AR)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Generate output from the current input&lt;/li&gt;
&lt;li&gt;Feed the output back into the model along with the input&lt;/li&gt;
&lt;li&gt;In LLMs, this is akin to a word chain&lt;/li&gt;
&lt;li&gt;Currently requires a specified order to proceed step by step&lt;/li&gt;
&lt;li&gt;Not applicable for image and music generation&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Non-autoregressive generation (NAR)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Parallel computation, generating all basic units at once&lt;/li&gt;
&lt;li&gt;Quality issues
&lt;ul&gt;
&lt;li&gt;Multi-modality&lt;/li&gt;
&lt;li&gt;AI generation requires the model to make decisions; if generated in parallel, conflicts may arise
&lt;ul&gt;
&lt;li&gt;e.g., drawing a dog&lt;/li&gt;
&lt;li&gt;Position one: a white dog, position two: a black dog&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;In word chains, this can be fatal, leading to incoherent semantics&lt;/li&gt;
&lt;li&gt;In image generation, in addition to instructions, a random generation vector is provided to ensure all parallel computation units have the same basis for generation&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;AR + NAR&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Generate a simplified version through AR, then input it to NAR for detailed generation
&lt;ul&gt;
&lt;li&gt;Use AR to draft, NAR completes based on the draft&lt;/li&gt;
&lt;li&gt;Auto encoder: encoder (AR) -&amp;gt; decoder (NAR)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Repeated NAR (current main approach)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Small images generate large images&lt;/li&gt;
&lt;li&gt;From noisy to noise-free: diffusion&lt;/li&gt;
&lt;li&gt;Erase the erroneous parts generated each time&lt;/li&gt;
&lt;li&gt;This is also a form of auto-regressive generation, but the generation method is NAR, repeatedly using the output as input for the next NAR. This enhances speed.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;lec16-speculative-decoding&#34;&gt;lec16 Speculative Decoding&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Increase output speed by predicting what subsequent tokens might be
&lt;ul&gt;
&lt;li&gt;Brief method description
&lt;ul&gt;
&lt;li&gt;Predict that this input will output A + B after passing through the LLM&lt;/li&gt;
&lt;li&gt;Simultaneously provide the model with three sets of input: input -&amp;gt; A, input + A -&amp;gt; B, input + A + B -&amp;gt; C&lt;/li&gt;
&lt;li&gt;If the first two inputs confirm the prediction of A + B, then it can directly proceed to the next token C&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;As long as one of the predictions is correct, efficiency can be improved&lt;/li&gt;
&lt;li&gt;If none are correct, it simply follows the original generation process, resulting in no gain or loss&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Prophet requirements
&lt;ul&gt;
&lt;li&gt;Super fast, mistakes are acceptable&lt;/li&gt;
&lt;li&gt;Non-autoregressive model
&lt;ul&gt;
&lt;li&gt;Fast parallel generation&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Compressed model
&lt;ul&gt;
&lt;li&gt;A smaller model that has been compressed&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Search engines&lt;/li&gt;
&lt;li&gt;Multiple prophets can be present simultaneously&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;lec17&#34;&gt;lec17&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Images are composed of pixels, and videos&lt;/li&gt;
&lt;li&gt;Videos are composed of images&lt;/li&gt;
&lt;li&gt;Nowadays, AI inputs are not every pixel of an image but use an encoder to slice the image into patches (which may be vectors or values), and then generate outputs through a decoder
&lt;ul&gt;
&lt;li&gt;The encoder and decoder are not just about reducing resolution; the operations involved are complex and encompass transformers&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Videos can be considered images with an added temporal dimension, allowing for more compression (e.g., processing adjacent frames together) using the encoder&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;text-to-image&#34;&gt;Text-to-Image&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Training data: images and corresponding descriptions&lt;/li&gt;
&lt;li&gt;Uses non-autoregressive generation, generating in parallel
&lt;ul&gt;
&lt;li&gt;In practice, it generates simultaneously rather than multiple parallel generations&lt;/li&gt;
&lt;li&gt;Because within the same transformer, there is mutual attention&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Evaluating the quality of image generation: CLIP
&lt;ul&gt;
&lt;li&gt;During model training, images and descriptions are provided, outputting a matching score&lt;/li&gt;
&lt;li&gt;However, the actual descriptions that text can provide are quite limited&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Personalized image generation
&lt;ul&gt;
&lt;li&gt;Use an infrequently used symbol to provide multiple training instances for the target&lt;/li&gt;
&lt;li&gt;Then, that symbol can be used to specify the style of generation&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Text-to-Video
&lt;ul&gt;
&lt;li&gt;Spatio-temporal attention (3D)
&lt;ul&gt;
&lt;li&gt;Considers the relationship of each pixel in the frame as well as the relationship of that pixel at different time points&lt;/li&gt;
&lt;li&gt;The computational load is too large and needs simplification&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Simplification
&lt;ul&gt;
&lt;li&gt;Spatial attention (2D)
&lt;ul&gt;
&lt;li&gt;Only considers the relationship of each pixel in the frame&lt;/li&gt;
&lt;li&gt;May lead to inconsistencies between frames&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Temporal attention (1D)
&lt;ul&gt;
&lt;li&gt;Only considers the relationship of pixels at different times&lt;/li&gt;
&lt;li&gt;Can cause inconsistencies in the frame&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Combining both can transform the original n^3 complexity into n^2 + n&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Can also combine with the previously mentioned repeated NAR
&lt;ul&gt;
&lt;li&gt;First generate a low-resolution, low-FPS video&lt;/li&gt;
&lt;li&gt;Subsequent iterations can increase FPS or resolution&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;lec18&#34;&gt;lec18&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Text generating images can lead to situations where a single text corresponds to multiple images, causing transformers to struggle with coherence.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;vae-variational-autoencoder&#34;&gt;VAE (Variational Autoencoder)&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Introduces additional information to the model
&lt;ul&gt;
&lt;li&gt;This additional information is referred to as noise&lt;/li&gt;
&lt;li&gt;Information extraction model: encoder&lt;/li&gt;
&lt;li&gt;Trains together with the image generation model: decoder
&lt;ul&gt;
&lt;li&gt;Provides text and images, the encoder extracts noise&lt;/li&gt;
&lt;li&gt;Noise and text are input to the decoder to generate images&lt;/li&gt;
&lt;li&gt;Evaluates whether the generated image is similar to the original&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;The entire combination is an autoencoder&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;During the model usage phase, the noise part is generated randomly&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;flow-based-method&#34;&gt;Flow-based Method&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Similar to VAE&lt;/li&gt;
&lt;li&gt;Uses a single model
&lt;ul&gt;
&lt;li&gt;The encoder and decoder functions of VAE are reversed&lt;/li&gt;
&lt;li&gt;Train a decoder model $ f $ that is invertible&lt;/li&gt;
&lt;li&gt;The encoder part of VAE in flow would be $ f^{-1} $&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;noise&#34;&gt;Noise&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Noise contains certain feature information of the image&lt;/li&gt;
&lt;li&gt;This noise can be combined or altered
&lt;ul&gt;
&lt;li&gt;For example, adding a smiley face noise to a face image can adjust the output to show a smiling face&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;diffusion-method&#34;&gt;Diffusion Method&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;The decoder here is denoising, also a transformer
&lt;ul&gt;
&lt;li&gt;Repeatedly removes noise&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Training process
&lt;ul&gt;
&lt;li&gt;Provides images with added noise&lt;/li&gt;
&lt;li&gt;Trains the denoise model to restore noisy images back to their original form&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;generative-adversarial-network-gan&#34;&gt;Generative Adversarial Network (GAN)&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Has a model similar to CLIP, used for matching images and text, called the Discriminator&lt;/li&gt;
&lt;li&gt;The approach is opposite; the image generation model (generator) continuously adjusts parameters to generate images until it passes the discriminator&amp;rsquo;s evaluation
&lt;ul&gt;
&lt;li&gt;Because there is no one-to-one relationship between images and text&lt;/li&gt;
&lt;li&gt;As long as the generated content is deemed good by the discriminator, there is no standard answer&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;The discriminator and generator are trained alternately&lt;/li&gt;
&lt;li&gt;The Discriminator here acts as a reward model&lt;/li&gt;
&lt;li&gt;Can be used as a plugin, combined with other models (VAE, Diffusion) for enhanced functionality&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>Distributed Database System Lecture Note</title>
        <link>http://shawn1251.github.io/post/distributed-database-lecture-note/</link>
        <pubDate>Wed, 31 Jul 2024 00:00:00 +0800</pubDate>
        
        <guid>http://shawn1251.github.io/post/distributed-database-lecture-note/</guid>
        <description>&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;./file/Distributed%20Database%20System.pdf&#34; &gt;Mind Map&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Instructor’s name: Ali Safari &lt;br&gt;
Textbook: Principles of Distributed Database Systems, 4th edition, M. Tamer Özsu and Patrick Valduriez,
Springer, 2020, ISBN 978-3-030-26252-5&lt;/p&gt;
&lt;h2 id=&#34;distributed-and-parallel-database-design&#34;&gt;Distributed and Parallel Database Design&lt;/h2&gt;
&lt;h3 id=&#34;fragmentation&#34;&gt;fragmentation&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;correctness&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;completness&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;each data in relation can also be found after fragmentation&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;reconstruction&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;by JOIN, the fragment can recovery to the original relation&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;disjointness&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;data in one fragment should not also be in other fragment&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;type&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;horizontal fragmentation (HF&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;primary horizontal (PHF&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;key points&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;simple prdicate&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;predicate: key + operator + value&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;eg. salary &amp;gt; 1000&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;minterm predicate&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;all possible combination of predicate&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;eg. loc = &amp;ldquo;France&amp;rdquo; ^ salary &amp;gt; 1000&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;minterm selectivities, sel(mi)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;the percentage of records that minterm selected&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;access frequency, acc(qi)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;how many times the same query asked by different user&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;cardinality, card(R)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;number of rows&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;COM_MIN algorithm&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;input: a relation R, a set of simple predicates Pr&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;output: a &amp;ldquo;complete&amp;rdquo;, &amp;ldquo;minimal&amp;rdquo; set of simple predicates Pr&#39;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;PHORIZONTAL Algorithm&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;input: a relation R, a set of predicates Pr&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;output: a set of minterm predicates M according to which relation R is to be fragmented&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;derived horizontal (DHF&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Based on the fragments created by PHF, apply similar fragmentation to other related relations.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;eg. after PHF, we divide &amp;ldquo;PAY&amp;rdquo; to 2 fragments. There is also a relation &amp;ldquo;EMP&amp;rdquo; related with &amp;ldquo;PAY&amp;rdquo;. We can also divide &amp;ldquo;EMP&amp;rdquo; by the same rule&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;vertical fragmentation (VF&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;affinity matrix&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;calculate by access frequency matrix and usage matrix&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;bond energy algorithm (BEA&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;input: the AA matrix (attribute affinity)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;output: the CA matrix(clustered affinity matrix)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;by changing the order what&amp;rsquo;s the most contribution I can get?&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;find the best order for columns&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;hybrid fragmentation&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;apply both horizontal and vertical&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;reconstruction&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;vertical: join&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;horizontal: union&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;data-distribution&#34;&gt;data distribution&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;allocation alternatives&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;non-replicated&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;each fragment resides at only one site&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;replicated&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;fully replicated&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;each fragment at each site&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;partially replicated&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;each fragment at some of the sites&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;if read-only queries &amp;raquo; update queries, replication is good&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;fragment allocation&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;problem: fragments, network, application&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;find the optimal distribution&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;minimal cost&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;performance&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;constraint&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;response time&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;storage&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;processing&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;decision variable&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Xij. 1 if fragment i store in at Site j. 0 otherwise&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;both FAP and DAP are NP-complete&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;heuristic based on. about finding the best combination&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;combined-approach&#34;&gt;combined approach&lt;/h3&gt;
&lt;h2 id=&#34;transaction&#34;&gt;transaction&lt;/h2&gt;
&lt;h3 id=&#34;all-operations-as-one-unit-whole-or-nothing&#34;&gt;all operations as one unit. whole or nothing&lt;/h3&gt;
&lt;h3 id=&#34;acid&#34;&gt;ACID&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Atomicity&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;one unit&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Consistency&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Isolation&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Durability&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;concurrent-execution&#34;&gt;concurrent execution&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;increase processor and disk utilization (I/O no need CPU)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;reduced average response time&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;important: multi tasks run in the but the result should be the same as serial running&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;validation&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;except read - read, all the others are conflict&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;try to move commands to see if they can be restored to the serial running format&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;if the commands are conflict, it should not be moved&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;serializability&#34;&gt;serializability&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;view serializability&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;not strict&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;the initial, update, final result should be the same as serial schedule&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;check a schedule is serializable is NP-Complete problem&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;conflict serializability&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;more strict&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;conflict serializable is the sub set of serializable&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;there is no any conflict between transactions(R/W, W/W)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;test method&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;swap non-conflicting instruction&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;If a schedule S can be transformed into a schedule S’ by a series of swaps of non-conflicting instructions, we say that S and S’ are conflict equivalent&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;a schedule S is conflict serializable if it is conflict equivalent to a serial schedule&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;precedence graph&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;transaction =&amp;gt; node&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;conficts =&amp;gt; edge&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;if graph has cycle, means not serializable&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;can do topological sorting&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;failure&#34;&gt;failure&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;rollbacks&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;cascading rollback&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;1 transaction failure, all the other transactions rollback&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;recoverable schedule&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;ensure data consistency&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;reading transaction can read data which not commit yet, but cannot commit before the writing transaction&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;cascadeless schedules&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;enhace recoverable schedule&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;is the subset of recoverable&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;transaction can only read data which is commited&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;the schedule which try to avoid cascading rollbacks&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;concurrency-control&#34;&gt;concurrency control&lt;/h2&gt;
&lt;h3 id=&#34;concept&#34;&gt;concept&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;the mechanism provided by the db system&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;serial schedule is recoverable and cascadeless&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;have to trade off between serial schedule and concurrent schedule&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;ensure schedule is conflict or view serializable&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;ensure the schedule is  rcoverable and preferably cascadeless&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;to achieve these purpose, it needs a &amp;ldquo;protocol&amp;rdquo; to assure serializability&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;protocols&#34;&gt;protocols&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;lock-based protocols&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;exclusive (X) mode&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;cannot add any other lock&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;only one transaction can R/W data&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;shared (S) mode&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;can add more shared lock&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;multiple read transaction can read the data at the same time&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;two-phase locking protocol&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;grow-lockpoint-shrink&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;grow&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;the transaction acquire all the lock before access without release&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;can convert lock-S to lock-X (upgrade)&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;shrink&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;start to releasing locks, cannot acquire any new lock&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;can convert lock-X to lock-S (downgrade)&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;type&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;strict two-phase locking&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;keep all the X-lock till commit/abort&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;rigorous two-phase locking&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;keep all the locks till commit/abort&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;ensure conflict-serializable&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;cannot avoid deadlock&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;startegy&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;read:
if lock:
read()
else:
if lock-X:
wait()
grant lock-S
read()&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;write:
if lock-X:
write()
else:
if other locks:
wait()
if lock-S:
upgrade to lock-X
else:
grant lock-X
write()&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;lock table&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;maintain by lock manager&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;lock table, record the type of lock granted or requested&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;like hash table&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;validate before grant new lock&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;if there are multiple locks, the last one can only be lock-X&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Graph based protocol&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;alternative to two phase locking&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Tree protocol&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Only exclusive locks are allowed&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;once unlock, cannot relock&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;conflict serializable&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;not gurantee recoverability&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;no deadlock&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;deadlock-prevention-strategies&#34;&gt;deadlock prevention strategies&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;wait-die&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;older may wait for younger release&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;younger never wait, rolled back instead&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;wound-wait&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;older can force rollback younger&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;younger may wait for older&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;fewer rollback than wait-die&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;timeout-based schemes&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;deadlock-detection&#34;&gt;deadlock detection&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;wait-for graph&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Ti -&amp;gt; Tj: Ti is waiting for a lock held by Tj&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;deadlock if there is a cycle&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;deadlock-recovery&#34;&gt;deadlock recovery&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;total rollback&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;partial rollback&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;difficult&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;multiple-granularity&#34;&gt;multiple granularity&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;can be represented as a tree&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;locks a node, also locks all the children node&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Fine granularity: high concurrency, lower in tree&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Coarse granularity: low concurrency, higher in tree&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;intention lock modes&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;3 more lock mode than S, X&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;intention-shared (IS)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;same as S, but locking at a lower level&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;intention-exclusive (IX)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;shared and intention-exclusive (SIX)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;allow a higher level node to be locked without having to check all descendent nodes&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;the compatibility matrix for all lock modes&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;timestamp-based-protocols&#34;&gt;Timestamp-based protocols&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;timestamp order = serializability order&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Timestamp-ordering protocol&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;WTS(Q) (W-timestamp): the largest timestamp of any transaction that executed &amp;ldquo;write(Q)&amp;rdquo;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;RTS(Q) (R-timestamp): the largest timestamp of any transaction that executed &amp;ldquo;read(Q)&amp;rdquo;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;algorithm&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Ti = Read(Q)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;if TS(Ti) &amp;lt; WTS(Q), Reject
(Ti needs the value that was already overwritten)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;if TS(Ti) &amp;gt;= WTS(Q), execute, RTS(Q) update to max(RTS(Q), TS(Ti))
(Read after latest update is accepted)&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Ti = Write(Q)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;if TS(Ti) &amp;lt; RTS(Q), Reject
(Ti produce a value that was  needed previously)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;if TS(Ti) &amp;lt; WTS(Q), Reject
(Ti try to write an obsolete value)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;else, WTS(Q) update to TS(Ti)&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;transaction-processing-2&#34;&gt;transaction processing-2&lt;/h2&gt;
&lt;h3 id=&#34;distributed-tm-architecture&#34;&gt;Distributed TM Architecture&lt;/h3&gt;
&lt;h3 id=&#34;serializability-1&#34;&gt;serializability&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;the condition that global transaction is serializable&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;each local history should be serializable&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;two conflicting operations should be in the same relative order in all of the local histories where they appear together&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;concurrency-control-algorithms&#34;&gt;concurrency control algorithms&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Pessimistic&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Two-Phase Locking-based (2PL)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;centralized 2PL&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;only one 2PL scheduler in the distributed system&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;lock requests are issued to the central scheduler&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;pros: Simple&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;cons: reliability, bottle neck&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;distributed 2PL&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;deadlock&#34;&gt;Deadlock&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;locking-based algorithm may cause deadlocks&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;TO based algorithm that involve waiting may cause deadlocks&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;wait-for graph&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Ti waits for Tj&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Ti &amp;ndash;&amp;gt; Tj&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;query-processing&#34;&gt;Query Processing&lt;/h2&gt;
&lt;h3 id=&#34;for-one-query-there-may-be-several-strategies&#34;&gt;for one query, there may be several strategies&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;optimization: calculate the cost, then choose the lowest one&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;access cost&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;transfer cost&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;example&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;problem&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Cost of Alternatives&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;complexity-of-relational-operations&#34;&gt;Complexity of relational operations&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Select
Project&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;O(n)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Project (eliminate duplicate)
Group&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;O(n * log n)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;sorting + check the array sequentially&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Join
Semi-Join
Division
Set&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;O(n * log n)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Cartesian Product&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;O(n^2)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;query-processing-methodology&#34;&gt;Query Processing Methodology&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;ol&gt;
&lt;li&gt;Query Decomposition&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;input: Calculus query on global relations&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Normalization&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Analysis&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Simplification&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Restructing&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;output: Algebraic query&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;Data Localization&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;input: Algebraic query on distributed relations&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Localization program&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Reduction based on the fragmentation strategy&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;PHF&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Select&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Because we have already divided the relations base on some rule. Only have to access the relations that have intersection with the query&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Join&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Distribute join over union&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;(R1 U R2)⋈S  =&amp;gt; (R1⋈S) U (R2⋈S)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;by distribute 1 join to multiple join, we can eliminate some of them that have no intersection with the query&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;VF&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;find useless intermiediate relations&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;DHF&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;mix the PHF-Select and PHF-Join&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;example&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;query&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;ol&gt;
&lt;li&gt;eliminate by Selection&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;join over union&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;eliminate the empty intermediate relations&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Hybrid Fragmentation&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;remove empty relations by selection on HF&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;remove useless relations by projection on VF&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;distribute joins over unions to isolate and remove useless joins&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;output: Fragment query&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;Distributed Query Optimization&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;input: Fragment query&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Find the best global schedule&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;query optimization process&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Search Space&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;The set of equivalent alebra expressions&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Join Trees&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Linear join tree&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Bushy join tree&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Cost Model&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;I/O cost + CPU cost + communication cost&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Search Algorithm&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;exhaustive search / heuristic algorithm&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;how to &amp;ldquo;move&amp;rdquo; in the search space&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Deterministic&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;start from base relations and build  plans by adding one relation at each step&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;DP: BFS&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Greedy: DFS&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Randomized&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;trade optimization time for execution time&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;iterative improvement&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>I2C Note</title>
        <link>http://shawn1251.github.io/post/i2c-note/</link>
        <pubDate>Thu, 23 Nov 2023 00:00:00 +0800</pubDate>
        
        <guid>http://shawn1251.github.io/post/i2c-note/</guid>
        <description>&lt;ul&gt;
&lt;li&gt;I2C communication uses two lines, unlike TX and RX. I2C has only one line called SDA for data transmission and another line called SCL for clock pulses.
&lt;ul&gt;
&lt;li&gt;SDA (serial data): carries the actual data.&lt;/li&gt;
&lt;li&gt;SCL (serial clock): provides clock pulses.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Half-Duplex
&lt;ul&gt;
&lt;li&gt;Unlike full-duplex communication where TX and RX can transmit and receive simultaneously, I2C allows only one side to transmit at a time, making it half-duplex.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Master-Slave Mode
&lt;ul&gt;
&lt;li&gt;Only one side can send a signal at a time to avoid conflicts, so communication is initiated by the master, and the slave responds after receiving the message.&lt;/li&gt;
&lt;li&gt;Multiple slaves can exist.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Bus Protocol
&lt;ul&gt;
&lt;li&gt;I2C is a bus protocol that enables communication between multiple devices.&lt;/li&gt;
&lt;li&gt;The master includes the target device&amp;rsquo;s address at the beginning of the message. Other slaves discard the message if it&amp;rsquo;s not meant for them.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Synchronous Communication
&lt;ul&gt;
&lt;li&gt;In asynchronous communication, both sides have their own clocks and communicate based on the agreed Baud Rate.&lt;/li&gt;
&lt;li&gt;Some small sensors lack accurate crystals for clocks, so the master&amp;rsquo;s SCL provides clock pulses to all slaves.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>Flashing STM32 with CH340</title>
        <link>http://shawn1251.github.io/post/stm32-ch340/</link>
        <pubDate>Mon, 20 Nov 2023 00:00:00 +0800</pubDate>
        
        <guid>http://shawn1251.github.io/post/stm32-ch340/</guid>
        <description>&lt;p&gt;Recently, I&amp;rsquo;ve been learning embedded development with STM32. However, since I don&amp;rsquo;t have STLINK, I have to use CH340 for flashing. Here&amp;rsquo;s a quick overview of the process.&lt;/p&gt;
&lt;h2 id=&#34;required-software&#34;&gt;Required Software&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Keil5&lt;/li&gt;
&lt;li&gt;FlyMcu&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;steps&#34;&gt;Steps&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;CH340 Pinout:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;VCC: Jumper cap for setting 5V/3.3V&lt;/li&gt;
&lt;li&gt;RX: Connects to GPIO PA09 for receiving&lt;/li&gt;
&lt;li&gt;TX: Connects to GPIO PA10 for transmitting&lt;/li&gt;
&lt;li&gt;GND: Ground connection&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;For flashing, a hex file is needed. So, in my IDE Keil5, additional settings are required.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Click the magic wand icon (options for target).&lt;/li&gt;
&lt;li&gt;Output &amp;gt; create hex file.&lt;/li&gt;
&lt;li&gt;After building, the hex file will appear in the Objects folder.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The flashing software used here is FlyMcu. Below are the flashing steps:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Plug in CH340 and ensure that the COM port above is for our CH340.&lt;/li&gt;
&lt;li&gt;Code file for online ISP &amp;gt; Choose the built hex file.&lt;/li&gt;
&lt;li&gt;Check Verify, Run After ISP complete.&lt;/li&gt;
&lt;li&gt;Uncheck Program OptionBytes when ISP.&lt;/li&gt;
&lt;li&gt;Click Start ISP.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;If the message on the right side shows the following, it indicates success:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;....
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;Write 1KB Ok,100%,@1562ms
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;Go from 08000000 Ok
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;If you want to flash a new program, press the reset button on the STM32.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>Apache Airflow Note</title>
        <link>http://shawn1251.github.io/post/apache-airflow/</link>
        <pubDate>Tue, 14 Nov 2023 00:00:00 +0800</pubDate>
        
        <guid>http://shawn1251.github.io/post/apache-airflow/</guid>
        <description>&lt;p&gt;A tool for task orchestration. Those with basic Linux experience are likely familiar with crontab, but it has limitations, such as the inability to establish complex task dependencies and easily review logs. In such cases, a comprehensive ETL (Extract, Transform, Load) tool is needed. This note briefly documents my learning process and shares the results on &lt;a class=&#34;link&#34; href=&#34;https://github.com/shawn1251/StockFlow&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;GitHub Repo&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Additionally, as of now, Airflow has evolved to version 2, and there are still many tutorials online for version 1. When learning, it&amp;rsquo;s essential to pay attention to the version. Official documentation can be found &lt;a class=&#34;link&#34; href=&#34;https://airflow.apache.org/blog/airflow-two-point-oh-is-here/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;features&#34;&gt;Features&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Open-source&lt;/li&gt;
&lt;li&gt;User-friendly UI&lt;/li&gt;
&lt;li&gt;Rich plugin ecosystem&lt;/li&gt;
&lt;li&gt;Purely Python-based&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;getting-started&#34;&gt;Getting Started&lt;/h2&gt;
&lt;p&gt;For a quick start, you can use the official Docker Compose setup:
&lt;a class=&#34;link&#34; href=&#34;https://airflow.apache.org/docs/apache-airflow/stable/howto/docker-compose/index.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://airflow.apache.org/docs/apache-airflow/stable/howto/docker-compose/index.html&lt;/a&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;curl -LfO &lt;span class=&#34;s1&#34;&gt;&amp;#39;https://airflow.apache.org/docs/apache-airflow/2.7.3/docker-compose.yaml&amp;#39;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;Create necessary volumes and set up the Airflow executor:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;mkdir -p ./dags ./logs ./plugins ./config
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;echo&lt;/span&gt; -e &lt;span class=&#34;s2&#34;&gt;&amp;#34;AIRFLOW_UID=&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;$(&lt;/span&gt;id -u&lt;span class=&#34;k&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&lt;/span&gt; &amp;gt; .env
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;docker compose up airflow-init
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;docker compose up
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h2 id=&#34;dag&#34;&gt;DAG&lt;/h2&gt;
&lt;p&gt;DAG (Directed Acyclic Graph). In Airflow, a DAG is a definition of a workflow, describing a series of tasks and their dependencies. Each task represents a unit of work that can be any operation executable in Airflow, such as running a Python script, executing an SQL query, or invoking an external API.&lt;/p&gt;
&lt;h3 id=&#34;example&#34;&gt;Example&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;26
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;27
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;28
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;29
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;30
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;31
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;32
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;33
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;34
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;35
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;36
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;37
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;38
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;39
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;40
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;41
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;42
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;datetime&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;datetime&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;timedelta&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;airflow&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;DAG&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;airflow.operators.dummy_operator&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;DummyOperator&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kn&#34;&gt;from&lt;/span&gt; &lt;span class=&#34;nn&#34;&gt;airflow.operators.python_operator&lt;/span&gt; &lt;span class=&#34;kn&#34;&gt;import&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;PythonOperator&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# Define default parameters&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;default_args&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;s1&#34;&gt;&amp;#39;owner&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;airflow&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;s1&#34;&gt;&amp;#39;depends_on_past&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;False&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;s1&#34;&gt;&amp;#39;start_date&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;datetime&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2023&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;s1&#34;&gt;&amp;#39;email_on_failure&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;False&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;s1&#34;&gt;&amp;#39;email_on_retry&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;False&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;s1&#34;&gt;&amp;#39;retries&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;s1&#34;&gt;&amp;#39;retry_delay&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;timedelta&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;minutes&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;5&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;print_hello&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;():&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nb&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;Hello from the PythonOperator task&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# Define DAG&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;with&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;DAG&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;s1&#34;&gt;&amp;#39;simple_dag_example&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;default_args&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;default_args&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;description&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;A simple example DAG&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;schedule_interval&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;timedelta&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;days&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt;  &lt;span class=&#34;c1&#34;&gt;# Run every day&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;as&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;dag&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c1&#34;&gt;# Define two tasks; decorators are also available starting from v2&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;start_task&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;DummyOperator&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;task_id&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;start_task&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;dag&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;dag&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;python_task&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;PythonOperator&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;task_id&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;python_task&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;python_callable&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;print_hello&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;dag&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;dag&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c1&#34;&gt;# Define dependencies between tasks; &lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c1&#34;&gt;# in this example, python_task runs after start_task&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;start_task&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;python_task&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h2 id=&#34;scheduler&#34;&gt;Scheduler&lt;/h2&gt;
&lt;p&gt;The scheduler checks the DAGs folder at regular intervals:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Checks for any DAGs requiring a DAG Run.&lt;/li&gt;
&lt;li&gt;Creates scheduled task instances for tasks under DAG Run.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;To create a task, place the DAG Python file in the DAGs folder. You can copy and modify examples from the &lt;a class=&#34;link&#34; href=&#34;https://airflow.apache.org/docs/apache-airflow/2.0.0/tutorial.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Airflow official documentation&lt;/a&gt; or refer to the example in the previous section.&lt;/p&gt;
&lt;h2 id=&#34;ui-operations&#34;&gt;UI Operations&lt;/h2&gt;
&lt;p&gt;Once the scheduler has completed the update, we can see our newly added DAGs on the UI. Due to platform constraints, detailed UI operations with numerous images are not suitable here, so instead, here is the &lt;a class=&#34;link&#34; href=&#34;https://airflow.apache.org/docs/apache-airflow/stable/ui.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;official UI documentation link&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Focus on mastering the basics:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;View DAG operation status&lt;/li&gt;
&lt;li&gt;Manually trigger DAG runs&lt;/li&gt;
&lt;li&gt;Review DAG execution logs&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>Addiction Recovery</title>
        <link>http://shawn1251.github.io/post/addiction-recovery/</link>
        <pubDate>Mon, 06 Nov 2023 00:00:00 +0800</pubDate>
        
        <guid>http://shawn1251.github.io/post/addiction-recovery/</guid>
        <description>&lt;p&gt;This note is from the video &lt;a class=&#34;link&#34; href=&#34;https://www.youtube.com/watch?v=LbbyLeR1ZRk&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;心河擺渡-成瘾始于痛苦，戒瘾终于平衡！深度解读多巴胺，用身体内稳态戒瘾&lt;/a&gt; The video contains insights from the author as well as his analysis of Anna Lembke&amp;rsquo;s book &lt;a class=&#34;link&#34; href=&#34;https://www.amazon.com/Drug-Dealer-MD-Doctors-Patients/dp/1421421402&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Drug Dealer, MD: How Doctors Were Duped, Patients Got Hooked, and Why It’s So Hard to Stop.&lt;/a&gt; The content is very useful, and I made notes to remind myself.&lt;/p&gt;
&lt;h2 id=&#34;underlying-principles&#34;&gt;Underlying Principles&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;The reason behind addiction is the increase in dopamine.
&lt;ul&gt;
&lt;li&gt;Chocolate increases it by 55%.&lt;/li&gt;
&lt;li&gt;Nicotine raises it by 150%.&lt;/li&gt;
&lt;li&gt;Amphetamine boosts it by 1000%.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;The main role of dopamine is not to make us feel happy after receiving a reward but to drive people to seek rewards.
&lt;ul&gt;
&lt;li&gt;For example, when you see chocolate, dopamine activates the brain&amp;rsquo;s reward circuit, making you feel pleasure even before having it and prompting you to eat it.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;The regions in the brain responsible for pleasure and pain overlap.
&lt;ul&gt;
&lt;li&gt;Pleasure and pain have self-regulating functions. When you&amp;rsquo;re currently experiencing pleasure, the brain will generate enough pain on the other side to balance it out.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Reward Prediction Error
&lt;ul&gt;
&lt;li&gt;Due to neural adaptation, the actual reward must exceed expectations to have a positive dopamine effect.&lt;/li&gt;
&lt;li&gt;In severe addiction, the threshold for feeling pleasure increases, resulting in a lack of enjoyment.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;utilizing-the-dopamine-mechanism&#34;&gt;Utilizing the Dopamine Mechanism&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;According to clinical experience, recreating the brain&amp;rsquo;s reward circuit takes at least a month.&lt;/li&gt;
&lt;li&gt;Using pain to treat pain
&lt;ul&gt;
&lt;li&gt;The brain uses pain to balance out pleasure and vice versa.
&lt;ul&gt;
&lt;li&gt;According to research, dopamine levels in the blood plasma increase by 250% when people immerse themselves in cold water, and this effect lasts longer than the immersion time.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Exercise is the best option.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Physical separation
&lt;ul&gt;
&lt;li&gt;Completely separate from the addictive substance.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Radical honesty
&lt;ul&gt;
&lt;li&gt;The prefrontal cortex is responsible for rational decision-making.&lt;/li&gt;
&lt;li&gt;When the dopamine reward circuit is active, lying inhibits the prefrontal cortex&amp;rsquo;s function, releasing the restraint on the reward circuit, leading the brain to believe it&amp;rsquo;s not addicted.&lt;/li&gt;
&lt;li&gt;An essential part of addiction recovery is rebuilding the relationship between the prefrontal cortex and the dopamine circuit.&lt;/li&gt;
&lt;li&gt;Strengthen the prefrontal cortex by &amp;ldquo;telling the truth&amp;rdquo; and enhance self-control.
&lt;ul&gt;
&lt;li&gt;During addiction, engage in self-talk or announce your addiction to people around you.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>AWS Note - Project Lifting and Shifting</title>
        <link>http://shawn1251.github.io/post/aws-note-shift-to-cloud/</link>
        <pubDate>Thu, 02 Nov 2023 00:00:00 +0800</pubDate>
        
        <guid>http://shawn1251.github.io/post/aws-note-shift-to-cloud/</guid>
        <description>&lt;p&gt;I&amp;rsquo;m currently learning &lt;a class=&#34;link&#34; href=&#34;https://www.udemy.com/course/decodingdevops/#reviews&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;DevOps Beginners to Advanced with Projects&lt;/a&gt; on Udemy. Here are some notes on using AWS.&lt;/p&gt;
&lt;h2 id=&#34;original-application-stack&#34;&gt;Original Application Stack&lt;/h2&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/hkhcoder/vprofile-project/tree/aws-LiftAndShift&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Project GitHub&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Nginx&lt;/li&gt;
&lt;li&gt;Apache&lt;/li&gt;
&lt;li&gt;Tomcat&lt;/li&gt;
&lt;li&gt;RabbitMQ&lt;/li&gt;
&lt;li&gt;Memcache&lt;/li&gt;
&lt;li&gt;Mysql
&lt;figure&gt;&lt;img src=&#34;http://shawn1251.github.io/post/aws-note-shift-to-cloud/images/origin-arch.drawio.png&#34; width=&#34;30%&#34;&gt;
&lt;/figure&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;migration-goals&#34;&gt;Migration Goals&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;EC2
&lt;ul&gt;
&lt;li&gt;VMs for tomcat, rabbitmq, memcache, mysql&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;ELB (Elastic Load Balancer)
&lt;ul&gt;
&lt;li&gt;Replaces nginx for load balancing&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Autoscaling
&lt;ul&gt;
&lt;li&gt;Automation for VM scaling&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;S3/EFS
&lt;ul&gt;
&lt;li&gt;Shared storage&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Route 53
&lt;ul&gt;
&lt;li&gt;Private DNS service&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;target-architecture&#34;&gt;Target Architecture&lt;/h3&gt;
&lt;figure&gt;&lt;img src=&#34;http://shawn1251.github.io/post/aws-note-shift-to-cloud/images/shift-aws-arch.drawio.png&#34; width=&#34;70%&#34;&gt;
&lt;/figure&gt;

&lt;h3 id=&#34;flow-of-execution&#34;&gt;Flow of Execution&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;Create key pairs&lt;/li&gt;
&lt;li&gt;Create security groups
&lt;ul&gt;
&lt;li&gt;Split into three groups:
&lt;ul&gt;
&lt;li&gt;LB (replaces nginx)&lt;/li&gt;
&lt;li&gt;APP (for tomcat)&lt;/li&gt;
&lt;li&gt;Backend (including rabbitmq, memcache, mysql)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Launch instances with user data&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;Currently a semi-automated process&lt;/li&gt;
&lt;li&gt;Manually create instances and paste shell scripts for environment setup into userdata&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start=&#34;4&#34;&gt;
&lt;li&gt;Update IP to name mapping in Route 53
&lt;ul&gt;
&lt;li&gt;Set up an internal DNS for communication between instances using hostnames&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Build the application from source code
&lt;ul&gt;
&lt;li&gt;This part is still semi-automated. Build the Java project on the local machine.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Upload to S3 bucket
&lt;ul&gt;
&lt;li&gt;Use AWS CLI to upload the built Java WAR file to the APP instance.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Download artifact to Tomcat EC2 instance
&lt;ul&gt;
&lt;li&gt;Previously, we used keys for S3 access. Here, instances connect to S3 using IAM roles.
&lt;ul&gt;
&lt;li&gt;Create a new S3 access role in IAM.&lt;/li&gt;
&lt;li&gt;Attach the created role to the APP instance.&lt;/li&gt;
&lt;li&gt;Use aws s3 ls to confirm successful access.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Set up ELB with HTTPS (certificate from Amazon Certificate Manager)
&lt;ul&gt;
&lt;li&gt;Create a target group, ensuring it points to port 8080 on the app.&lt;/li&gt;
&lt;li&gt;Create an ELB with HTTP/HTTPS routing to the target group.&lt;/li&gt;
&lt;li&gt;Purchase a domain and apply for an SSL certificate from AWS Certificate Manager.&lt;/li&gt;
&lt;li&gt;In the secure listener, select the SSL certificate from ACM.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Map ELB endpoint to website name in DNS
&lt;ul&gt;
&lt;li&gt;At the DNS provider (in this case, GoDaddy), create a CNAME record that redirects to the AWS LB domain.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Verify
&lt;ul&gt;
&lt;li&gt;DNS settings may take some time to propagate.&lt;/li&gt;
&lt;li&gt;You can directly access the LB&amp;rsquo;s domain to check if the APP is running on port 80.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Build an autoscaling group for the tomcat instance
&lt;ul&gt;
&lt;li&gt;Autoscaling involves three steps:
&lt;ul&gt;
&lt;li&gt;AMI (Amazon Machine Image)
&lt;ul&gt;
&lt;li&gt;Create an image from the current APP instance.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Launch template
&lt;ul&gt;
&lt;li&gt;Use the created AMI, and keep the security group the same as the original APP.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Autoscaling group
&lt;ul&gt;
&lt;li&gt;Attach it to the existing load balancer.&lt;/li&gt;
&lt;li&gt;Choose the load balancer&amp;rsquo;s target group.&lt;/li&gt;
&lt;li&gt;Set scaling policies based on CPU usage or network in/out.&lt;/li&gt;
&lt;li&gt;Configure notifications.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
</description>
        </item>
        <item>
        <title>AWS Note</title>
        <link>http://shawn1251.github.io/post/aws-note/</link>
        <pubDate>Tue, 31 Oct 2023 00:00:00 +0800</pubDate>
        
        <guid>http://shawn1251.github.io/post/aws-note/</guid>
        <description>&lt;p&gt;I&amp;rsquo;m currently studying &lt;a class=&#34;link&#34; href=&#34;https://www.udemy.com/course/decodingdevops/#reviews&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;DevOps Beginners to Advanced with Projects&lt;/a&gt; on Udemy. Here are some notes on using AWS:&lt;/p&gt;
&lt;h2 id=&#34;creating-an-ec2-instance&#34;&gt;Creating an EC2 Instance&lt;/h2&gt;
&lt;p&gt;The most basic computing unit:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Name and Tag
&lt;ul&gt;
&lt;li&gt;Here, you can choose to &amp;ldquo;add additional tags&amp;rdquo; to provide extra labels for easy identification on the AWS console.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;AMI (Amazon Machine Image)
&lt;ul&gt;
&lt;li&gt;An AMI is like an image, similar to running a Docker image to create a container, but here, you create an EC2 instance.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Instance Type
&lt;ul&gt;
&lt;li&gt;For the free tier, I&amp;rsquo;ve only used t2.micro. In real scenarios, you can choose different resource levels based on your requirements.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Key Pair
&lt;ul&gt;
&lt;li&gt;AWS uses SSH keys for remote access. Choose the key pair for this instance. You can reuse a key pair across different instances for better key pair management.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Network Settings
&lt;ul&gt;
&lt;li&gt;Configure inbound and outbound rules. Typically, you&amp;rsquo;d open inbound for SSH and add &amp;ldquo;my IP&amp;rdquo; as the source. For web services, you&amp;rsquo;d add HTTP with a source of &amp;ldquo;anywhere.&amp;rdquo;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Configure Storage
&lt;ul&gt;
&lt;li&gt;AWS offers various storage types, such as SSD, HDD, and specialized types based on I/O.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Advanced
&lt;ul&gt;
&lt;li&gt;Here, I used the &amp;ldquo;User Data&amp;rdquo; field. You can write shell scripts in this field to install software or complete specific configurations during instance launch.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;elastic-block-store-ebs&#34;&gt;Elastic Block Store (EBS)&lt;/h2&gt;
&lt;p&gt;Storage options:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Volume Type
&lt;ul&gt;
&lt;li&gt;You can choose storage types like SSD, HDD, or specialized types based on I/O.&lt;/li&gt;
&lt;li&gt;You can also select the region for volume creation.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;AWS allows dynamic attachment of volumes to instances.
&lt;ul&gt;
&lt;li&gt;Use &lt;code&gt;fdisk -l&lt;/code&gt; to check the volume&amp;rsquo;s name.&lt;/li&gt;
&lt;li&gt;Use &lt;code&gt;fdisk /dev/xvdf&lt;/code&gt; to create partitions. The path might vary based on the previous command&amp;rsquo;s output.
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;m&lt;/code&gt; for help&lt;/li&gt;
&lt;li&gt;&lt;code&gt;n&lt;/code&gt; new partition&lt;/li&gt;
&lt;li&gt;&lt;code&gt;p&lt;/code&gt; primary&lt;/li&gt;
&lt;li&gt;partition number: default&lt;/li&gt;
&lt;li&gt;First sector: default&lt;/li&gt;
&lt;li&gt;Last sector: default&lt;/li&gt;
&lt;li&gt;&lt;code&gt;w&lt;/code&gt; write table to disk&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Create partitions, format them using &lt;code&gt;mkfs.ext4&lt;/code&gt;, and check with &lt;code&gt;lsblk&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Mount the partition using &lt;code&gt;mount /dev/xvdf1 {target path}&lt;/code&gt;. To make it auto-mount, modify &lt;code&gt;/etc/fstab&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Snapshot
&lt;ul&gt;
&lt;li&gt;Important data, like a database, is often stored on a separate volume.&lt;/li&gt;
&lt;li&gt;You can use EBS snapshots to back up a volume and later restore it by creating a new volume from the snapshot.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;load-balancing&#34;&gt;Load Balancing&lt;/h2&gt;
&lt;p&gt;An example with two instances running the same HTTP server:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Create a Target Group
&lt;ul&gt;
&lt;li&gt;Configure health checks to ensure instance health. For a web server, set up periodic HTTP requests to a specific path.&lt;/li&gt;
&lt;li&gt;Add instances to the target group.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Create a Load Balancer
&lt;ul&gt;
&lt;li&gt;For example, use an Application Load Balancer.&lt;/li&gt;
&lt;li&gt;Configure security groups for inbound HTTP traffic.&lt;/li&gt;
&lt;li&gt;Set up listeners &amp;amp; routing to forward traffic to the target group.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Adjust the security group of the target group to allow access from the load balancer&amp;rsquo;s security group.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;cloudwatch&#34;&gt;CloudWatch&lt;/h2&gt;
&lt;p&gt;Create alarms, such as monitoring CPU resources:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Go to &amp;ldquo;All Alarms&amp;rdquo; and create a new alarm.&lt;/li&gt;
&lt;li&gt;Select metrics, e.g., EC2, per-instance metrics.&lt;/li&gt;
&lt;li&gt;Choose the instance ID and select CPUUtilization.&lt;/li&gt;
&lt;li&gt;Set the threshold (e.g., 60%) and configure notification details for email or groups.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;amazon-elastic-file-system-efs&#34;&gt;Amazon Elastic File System (EFS)&lt;/h2&gt;
&lt;p&gt;Similar to NFS on Linux, suitable for shared storage among multiple instances:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Create a security group for EFS.
&lt;ul&gt;
&lt;li&gt;Create an EFS file system with default performance settings or adjust as needed.&lt;/li&gt;
&lt;li&gt;Configure network settings with the security group for all availability zones.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Create an access point.
&lt;ul&gt;
&lt;li&gt;Mount EFS from an EC2 instance using the amazon-efs-utils. &lt;code&gt;sudo yum install -y amazon-efs-utils&lt;/code&gt;. &lt;a class=&#34;link&#34; href=&#34;https://docs.aws.amazon.com/efs/latest/ug/installing-amazon-efs-utils.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;official doc&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Update &lt;code&gt;/etc/fstab&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;Add &lt;code&gt;{file-system-id}:/ {efs-mount-point} efs _netdev,noresvport,tls,accesspoint={access-point-id} 0 0&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://docs.aws.amazon.com/efs/latest/ug/automount-with-efs-mount-helper.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;official doc&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;execute&lt;code&gt; mount -fav&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;If you see {mount-point}: successfully mounted, you&amp;rsquo;re done.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>Commonly Used Shell Commands for Filtering</title>
        <link>http://shawn1251.github.io/post/shell-cmd-filter/</link>
        <pubDate>Mon, 30 Oct 2023 00:00:00 +0800</pubDate>
        
        <guid>http://shawn1251.github.io/post/shell-cmd-filter/</guid>
        <description>&lt;p&gt;For Linux users who are familiar with commands like cp, mv, and ls, here are some commands I found useful but took some time to master:&lt;/p&gt;
&lt;h2 id=&#34;cat&#34;&gt;cat&lt;/h2&gt;
&lt;p&gt;Most often, cat is used to display file contents, such as &lt;code&gt;cat {your file}&lt;/code&gt;. However, it can also be used to concatenate two files and create a new file.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;To concatenate two files:
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;cat {file1} {file2} &amp;gt; {merged file}&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;To create a new file and write to it:
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;cat &amp;gt; {your file}&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;It will accept your input and write it to the file.&lt;/li&gt;
&lt;li&gt;Some automation scripts use this command to create files, like:
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;cat &amp;gt; testFile &lt;span class=&#34;s&#34;&gt;&amp;lt;&amp;lt; EOF
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s&#34;&gt;{your content}
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s&#34;&gt;EOF&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;grep&#34;&gt;grep&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;grep -R SELINUX /etc/*
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;-i: Ignore case.&lt;/li&gt;
&lt;li&gt;-R: Recursively search in subdirectories.&lt;/li&gt;
&lt;li&gt;-v: Invert match, output lines that don&amp;rsquo;t contain the keyword.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;cut&#34;&gt;cut&lt;/h2&gt;
&lt;p&gt;This command is useful for quickly extracting specific content from files with a fixed format, such as /etc/passwd. In this file, each line is separated by colons (&amp;quot;:&amp;quot;).&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;root:x:0:0:root:/root:/bin/bash
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;vagrant:x:1000:1000::/home/vagrant:/bin/bash
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;Using cut on this file:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;cut -d: -f1 /etc/passwd
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;-d specifies the delimiter, and we use &amp;ldquo;:&amp;rdquo; to indicate that the delimiter is a colon.&lt;/li&gt;
&lt;li&gt;-f1 indicates that we want to extract the first field after splitting, which is the username.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The output will be:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;root
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;vagrant
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h2 id=&#34;awk&#34;&gt;awk&lt;/h2&gt;
&lt;p&gt;When the separator is more complex or variable, you can use awk. For the example mentioned above, you can use awk to achieve the same result:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;awk -F&lt;span class=&#34;s1&#34;&gt;&amp;#39;:&amp;#39;&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;{print $1}&amp;#39;&lt;/span&gt; /etc/passwd
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;-F specifies the field separator.
{print $1} specifies to print the first field after splitting.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;sed&#34;&gt;sed&lt;/h2&gt;
&lt;p&gt;sed is used for text substitution. It operates on streams and doesn&amp;rsquo;t overwrite the original file. For example:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;echo&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;this is a book.&amp;#34;&lt;/span&gt; &amp;gt; &lt;span class=&#34;nb&#34;&gt;test&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# Create a sample text&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;sed &lt;span class=&#34;s1&#34;&gt;&amp;#39;s/book/dog/g&amp;#39;&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;test&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&amp;gt; this is a dog.
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# It replaces &amp;#34;book&amp;#34; with &amp;#34;dog&amp;#34; in the text.&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# &amp;#39;s&amp;#39; stands for search.&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# &amp;#39;g&amp;#39; stands for global.&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# You can replace &amp;#39;test&amp;#39; with &amp;#39;*&amp;#39; to change multiple files.&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;cat &lt;span class=&#34;nb&#34;&gt;test&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&amp;gt; this is a book.
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# The original file remains unchanged.&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# To overwrite, you can add -i&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;sed -i &lt;span class=&#34;s1&#34;&gt;&amp;#39;s/book/dog/g&amp;#39;&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;test&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;cat &lt;span class=&#34;nb&#34;&gt;test&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&amp;gt; this is a dog.
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h2 id=&#34;redirection&#34;&gt;Redirection&lt;/h2&gt;
&lt;p&gt;By default, the output of Linux commands is displayed on the screen, but you can redirect the output to a file. Here are some key points:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;&amp;gt;&lt;/code&gt; will overwrite the target, while &lt;code&gt;&amp;gt;&amp;gt;&lt;/code&gt; appends.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;1&lt;/code&gt; is stdout, and &lt;code&gt;2&lt;/code&gt; is stderr.&lt;/li&gt;
&lt;li&gt;You can use &lt;code&gt;&amp;amp;&lt;/code&gt; to redirect all output.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;9
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# When the target is stdout, you don&amp;#39;t need to specify 1.&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;ls &amp;gt;&amp;gt; tmpfile
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# &amp;#39;lss&amp;#39; is a non-existent command that will produce an error. You can redirect its stderr output.&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;lss 2&amp;gt;&amp;gt; tmpfile
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# The &amp;#39;&amp;amp;&amp;#39; symbol redirects both stdout and stderr.&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;ls &lt;span class=&#34;p&#34;&gt;&amp;amp;&lt;/span&gt;&amp;gt;&amp;gt; tmpfile
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;lss &lt;span class=&#34;p&#34;&gt;&amp;amp;&lt;/span&gt;&amp;gt;&amp;gt; tmpfile
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h2 id=&#34;pipe&#34;&gt;Pipe&lt;/h2&gt;
&lt;p&gt;Use the pipe &lt;code&gt;|&lt;/code&gt; to pass the output of one command as input to another.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# Count the lines by passing the output of &amp;#39;ls&amp;#39; to &amp;#39;wc&amp;#39;.&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;ls &lt;span class=&#34;p&#34;&gt;|&lt;/span&gt; wc -l
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# Extract the &amp;#39;Mem&amp;#39; column from the output of &amp;#39;free&amp;#39;.&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;free &lt;span class=&#34;p&#34;&gt;|&lt;/span&gt; grep -i Mem
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;</description>
        </item>
        <item>
        <title>vagrant note</title>
        <link>http://shawn1251.github.io/post/vagrant-intro/</link>
        <pubDate>Sat, 28 Oct 2023 00:00:00 +0800</pubDate>
        
        <guid>http://shawn1251.github.io/post/vagrant-intro/</guid>
        <description>&lt;p&gt;Vagrant is a command line tool that makes it easy to automate the setup and launching of virtual machines (VMs). It&amp;rsquo;s not a hypervisor itself but operates as a layer on top of existing hypervisors, allowing users to quickly create VMs on those hypervisors. Vagrant doesn&amp;rsquo;t require an operating system image; the image (referred to as a &amp;ldquo;box&amp;rdquo;) specified in the Vagrantfile is fetched from Vagrant Cloud. You define the necessary parameters in the Vagrantfile, and then you can start the VM with the &lt;code&gt;vagrant up&lt;/code&gt; command.&lt;/p&gt;
&lt;h2 id=&#34;common-commands&#34;&gt;Common Commands&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;vagrant init {box name} - Initialize a new Vagrant environment with the specified box.&lt;/li&gt;
&lt;li&gt;vagrant up - Start the VM.&lt;/li&gt;
&lt;li&gt;vagrant ssh - Log in to the VM via SSH.&lt;/li&gt;
&lt;li&gt;vagrant halt - Stop the VM.&lt;/li&gt;
&lt;li&gt;vagrant destroy - Remove the VM.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;process&#34;&gt;Process&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Create a folder.&lt;/li&gt;
&lt;li&gt;Create a Vagrantfile.&lt;/li&gt;
&lt;li&gt;Run vagrant up to start the VM.&lt;/li&gt;
&lt;li&gt;Use vagrant ssh to access the VM.&lt;/li&gt;
&lt;li&gt;Stop or delete the VM with vagrant halt or vagrant destroy.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;example&#34;&gt;Example&lt;/h2&gt;
&lt;p&gt;You can find VM images (boxes) on Vagrant Cloud: &lt;a class=&#34;link&#34; href=&#34;https://app.vagrantup.com/boxes/search&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://app.vagrantup.com/boxes/search&lt;/a&gt;. Initialize a new Vagrant environment with a specific box using vagrant init {box name} and start it with vagrant up. You can check the status of your VMs with vagrant global-status.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;vagrant init {box name}
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;vagrant up
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;vagrant global-status
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h2 id=&#34;provision-of-vagrantfile&#34;&gt;Provision of Vagrantfile&lt;/h2&gt;
&lt;p&gt;Provisioning allows you to run commands on the VM before its first boot, such as installing specific software. You can refer to the official Vagrantfile documentation for more details. Here&amp;rsquo;s an example of provisioning to install Apache2 during VM setup:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;# Example provisioning to install Apache2 during VM setup
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;config.vm.provision &amp;#34;shell&amp;#34;, inline: &amp;lt;&amp;lt;-SHELL
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  apt-get update
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  apt-get install -y apache2
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;SHELL
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;</description>
        </item>
        <item>
        <title>Install chocolatey</title>
        <link>http://shawn1251.github.io/post/install-chocolatey/</link>
        <pubDate>Tue, 24 Oct 2023 06:42:46 +0800</pubDate>
        
        <guid>http://shawn1251.github.io/post/install-chocolatey/</guid>
        <description>&lt;p&gt;Chocolatey is a software installation tool for Windows, similar to &amp;lsquo;brew&amp;rsquo; on macOS. It makes installing software much more convenient.&lt;/p&gt;
&lt;h2 id=&#34;installation&#34;&gt;Installation&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;7
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-powershell&#34; data-lang=&#34;powershell&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;Get-ExecutionPolicy&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c&#34;&gt;# If it&amp;#39;s &amp;#39;restricted,&amp;#39; run PowerShell as an administrator and enter the following commands:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;Set-ExecutionPolicy&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;AllSigned&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c&#34;&gt;# Enter Y or A to confirm the permission change.&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;Set-ExecutionPolicy&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Bypass&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;-Scope&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;Process&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;-Force&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;iex &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;((&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;New-Object&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;System&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;py&#34;&gt;Net&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;WebClient&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;).&lt;/span&gt;&lt;span class=&#34;py&#34;&gt;DownloadString&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;https://chocolatey.org/install.ps1&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c&#34;&gt;# Finally, run `choco` to confirm a successful installation.&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;choco&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h2 id=&#34;usage&#34;&gt;Usage&lt;/h2&gt;
&lt;p&gt;You can visit &lt;a class=&#34;link&#34; href=&#34;https://community.chocolatey.org/packages&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://community.chocolatey.org/packages&lt;/a&gt; to search for the software you want. For example, if you&amp;rsquo;re looking for VirtualBox, you&amp;rsquo;ll find the command:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-powershell&#34; data-lang=&#34;powershell&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;choco&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;install&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;virtualbox&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;Running this command will automatically install the software!&lt;/p&gt;
</description>
        </item>
        <item>
        <title>Setting GitHub page</title>
        <link>http://shawn1251.github.io/post/setting-your-first-githubpage/</link>
        <pubDate>Sat, 21 Oct 2023 06:42:46 +0800</pubDate>
        
        <guid>http://shawn1251.github.io/post/setting-your-first-githubpage/</guid>
        <description>&lt;p&gt;This article is here to document the process of building a blog using Hugo and publishing it on GitHub Pages.
GitHub provides a free personal website service called GitHub Pages. You can upload your web content to a designated format repository to make it live.&lt;/p&gt;
&lt;h2 id=&#34;preparations&#34;&gt;Preparations&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/signup&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;GitHub account&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://git-scm.com/book/en/v2/Getting-Started-Installing-Git&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Install Git&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Your target website&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;setup&#34;&gt;Setup&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Click on &amp;ldquo;repository,&amp;rdquo; then &amp;ldquo;New.&amp;rdquo;&lt;/li&gt;
&lt;li&gt;In the &amp;ldquo;repository name&amp;rdquo; field, enter &amp;ldquo;{your account name}.github.io.&amp;rdquo;&lt;/li&gt;
&lt;li&gt;Click &amp;ldquo;create repository.&amp;rdquo;&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;upload&#34;&gt;Upload&lt;/h2&gt;
&lt;p&gt;Next, we&amp;rsquo;ll push the local website to GitHub. If you don&amp;rsquo;t have a website and just want to test, you can simply create an index.html for testing.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# Initialize git for the current website&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;git init
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# Add to the stage and commit&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;git add .
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;git commit -m &lt;span class=&#34;s2&#34;&gt;&amp;#34;first commit&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# Create the main branch&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;git branch -M main
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# Add the remote repository and name it origin&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;git remote add origin https://github.com/&lt;span class=&#34;o&#34;&gt;{&lt;/span&gt;your account&lt;span class=&#34;o&#34;&gt;}&lt;/span&gt;/&lt;span class=&#34;o&#34;&gt;{&lt;/span&gt;your account&lt;span class=&#34;o&#34;&gt;}&lt;/span&gt;.github.io.git
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# Push the current project to GitHub&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;git push -u origin main
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h2 id=&#34;view&#34;&gt;View&lt;/h2&gt;
&lt;p&gt;If everything is fine, you can visit &lt;code&gt;https://{your account}.github.io&lt;/code&gt; to see the web page you just pushed!&lt;/p&gt;
&lt;h2 id=&#34;using-hugo-building-the-site-and-uploading&#34;&gt;Using Hugo: Building the Site and Uploading&lt;/h2&gt;
&lt;p&gt;Continuing from the previous article, &lt;a class=&#34;link&#34; href=&#34;http://shawn1251.github.io/post/first-post/&#34; &gt;&amp;ldquo;Creating the First Post with Hugo&amp;rdquo;&lt;/a&gt;, we can use GitHub Pages to publish our results. Remember to change the baseURL in your config.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# Build&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;hugo
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# Navigate to the static website folder&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;cd&lt;/span&gt; public
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# As explained above&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;git init
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;git add .
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;git commit -m &lt;span class=&#34;s2&#34;&gt;&amp;#34;first commit&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;git branch -M main
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;git remote add origin https://github.com/&lt;span class=&#34;o&#34;&gt;{&lt;/span&gt;your account&lt;span class=&#34;o&#34;&gt;}&lt;/span&gt;/&lt;span class=&#34;o&#34;&gt;{&lt;/span&gt;your account&lt;span class=&#34;o&#34;&gt;}&lt;/span&gt;.github.io.git
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;git push -u origin main
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;</description>
        </item>
        <item>
        <title>First Post with Hugo</title>
        <link>http://shawn1251.github.io/post/first-post/</link>
        <pubDate>Fri, 20 Oct 2023 00:00:00 +0800</pubDate>
        
        <guid>http://shawn1251.github.io/post/first-post/</guid>
        <description>&lt;p&gt;I had a sudden inspiration to organize some of my past notes, and when looking for a platform, I took a friend&amp;rsquo;s advice and chose Hugo with GitHub Pages. Here, I&amp;rsquo;ll document the process.&lt;/p&gt;
&lt;h1 id=&#34;hugo&#34;&gt;Hugo&lt;/h1&gt;
&lt;p&gt;Let me briefly introduce &lt;a class=&#34;link&#34; href=&#34;https://gohugo.io/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Hugo&lt;/a&gt;. Hugo is a static website generator developed in Golang. Static websites don&amp;rsquo;t rely on a backend, they&amp;rsquo;re fast, and you don&amp;rsquo;t need to set up a database, making them ideal for showcasing websites. In the past, many people used CMS, like WordPress, to create personal websites. However, for simpler needs, using static websites is recommended. Similar tools include &lt;a class=&#34;link&#34; href=&#34;https://hexo.io/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Hexo&lt;/a&gt; and &lt;a class=&#34;link&#34; href=&#34;https://jekyllrb.com/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Jekyll&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Since Hugo is developed in Golang, you only need to install the pre-compiled Hugo executable when using it, without the need for other languages like Ruby or JavaScript. You can start by browsing some pre-built &lt;a class=&#34;link&#34; href=&#34;https://themes.gohugo.io/tags/blog&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Hugo template&lt;/a&gt; to get an idea of what your future project could look like.&lt;/p&gt;
&lt;p&gt;Here, we&amp;rsquo;ll follow the official guide: &lt;a class=&#34;link&#34; href=&#34;https://gohugo.io/getting-started/quick-start/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://gohugo.io/getting-started/quick-start/&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;installing-hugo&#34;&gt;Installing Hugo&lt;/h2&gt;
&lt;p&gt;Choose the appropriate &lt;a class=&#34;link&#34; href=&#34;https://gohugo.io/installation/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;installation method&lt;/a&gt; based on your operating system. I&amp;rsquo;m using Ubuntu, and assuming you already have Git installed, you can use the following commands:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# First, install the Sass package&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;sudo snap install dart-sass
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# Install Hugo&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;sudo snap install hugo
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;After installation, you can check the version:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;hugo --version
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h2 id=&#34;trying-your-first-project&#34;&gt;Trying Your First Project&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# Create a new project&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;hugo new site quickstart
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;cd&lt;/span&gt; quickstart
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;git init
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# Add the &amp;#39;ananke&amp;#39; theme as a Git submodule for easier updates&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;git submodule add https://github.com/theNewDynamic/gohugo-theme-ananke.git themes/ananke
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# Specify &amp;#39;ananke&amp;#39; as the theme for the current project&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;echo&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;theme = &amp;#39;ananke&amp;#39;&amp;#34;&lt;/span&gt; &amp;gt;&amp;gt; hugo.toml
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# Run a web server to see the results&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;hugo server
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h2 id=&#34;adding-content&#34;&gt;Adding Content&lt;/h2&gt;
&lt;p&gt;After following the above steps, you should see a simple black-and-white homepage. Now, you can add your own content using Hugo&amp;rsquo;s built-in commands:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# Create a post named &amp;#39;my-first-post&amp;#39;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;hugo new content posts/my-first-post.md
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;This will create an .md file under &lt;code&gt;content/posts/&lt;/code&gt;. It will contain the following metadata, which is necessary for Hugo&amp;rsquo;s markdown:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;+++
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;title = &amp;#39;My First Post&amp;#39;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;date = 2023-10-20T21:37:17+08:00
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;draft = true
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;+++
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;Unlike the content in the blank markdown, this one has the above metadata which is necessary. Let&amp;rsquo;s add some extra content using markdown. &lt;a class=&#34;link&#34; href=&#34;https://www.markdownguide.org/getting-started/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;markdown instruction&lt;/a&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;8
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;+++
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;title = &amp;#39;My First Post&amp;#39;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;date = 2023-10-20T21:37:17+08:00
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;draft = false
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;+++
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;# hello world
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;hello
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;Be sure to change draft to &lt;code&gt;false&lt;/code&gt; if you want your content to appear on the homepage. Otherwise, you need to use &lt;code&gt;hugo server -D&lt;/code&gt; to display draft content.&lt;/p&gt;
&lt;h2 id=&#34;publishing&#34;&gt;Publishing&lt;/h2&gt;
&lt;p&gt;Simply run the hugo command to begin building based on your content. The results will be in the &lt;code&gt;public&lt;/code&gt; folder. If you also have Python 3, you can run the built-in HTTP server for a simple test:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;cd&lt;/span&gt; public
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;python3 -m http.server
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;It will run on port 8000 by default. You can open your browser and go to &lt;code&gt;localhost:8000&lt;/code&gt; to see the static site.&lt;/p&gt;
&lt;h2 id=&#34;questions&#34;&gt;Questions&lt;/h2&gt;
&lt;h3 id=&#34;how-can-i-customize-the-template&#34;&gt;How can I customize the template?&lt;/h3&gt;
&lt;p&gt;Usually, template projects have documentation for customization. For example, this blog uses &lt;a class=&#34;link&#34; href=&#34;https://github.com/CaiJimmy/hugo-theme-stack&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;stack&lt;/a&gt;. The issue I encountered with this template was adding a few icons that were not present in the theme. To customize it, I had to fork the original repository into my own repository and then make the necessary customizations.&lt;/p&gt;
&lt;h3 id=&#34;i-found-a-template-i-like-but-i-dont-know-how-to-get-started&#34;&gt;I found a template I like, but I don&amp;rsquo;t know how to get started.&lt;/h3&gt;
&lt;p&gt;Typically, template projects come with a basic example site that you can refer to in order to understand how to use the template. In the case of &lt;a class=&#34;link&#34; href=&#34;https://github.com/CaiJimmy/hugo-theme-stack&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;stack&lt;/a&gt;, it has an &amp;rsquo;exampleSite&amp;rsquo; folder that contains content and config.yaml files. You can copy these files to your project directory to see how to get started.&lt;/p&gt;
</description>
        </item>
        <item>
        <title>About</title>
        <link>http://shawn1251.github.io/page/about/</link>
        <pubDate>Sun, 01 Oct 2023 00:00:00 +0000</pubDate>
        
        <guid>http://shawn1251.github.io/page/about/</guid>
        <description>&lt;p&gt;Responsible, communicative, and logical thinker who excels in both teamwork and independent endeavors. Enjoys exercising and cooking, and has a passion for learning new things. Currently self-studying embedded system development.&lt;/p&gt;
&lt;h2 id=&#34;experience&#34;&gt;Experience&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;CEO &amp;amp; Software Engineer at Phase Tech (2019/06 - 2023-07)&lt;/li&gt;
&lt;li&gt;Software Engineer at National Taiwan Ocean University (2018/01 - 2019/06)&lt;/li&gt;
&lt;li&gt;Consultant &amp;amp; IT Support at Yifang Fruit Tea &amp;amp; JIABA London (2017/08 - 2018-01)&lt;/li&gt;
&lt;li&gt;MIS at Aviation Police Bureau - Mandatory Service (2016/08 - 2017/08)&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;education&#34;&gt;Education&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;M.S. in Computer Science and Engineering at National Taiwan Ocean University (2020/01 - 2021/07)&lt;/li&gt;
&lt;li&gt;B.S. in Computer Science and Engineering at National Taiwan Ocean University (2012/09 - 2016/06)&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;skill&#34;&gt;Skill&lt;/h2&gt;
&lt;p&gt;Programming Language:&lt;br&gt;
Python, C++, TypeScript C, C#, Golang&lt;/p&gt;
&lt;p&gt;Database:&lt;br&gt;
MongoDB, Redis, Postgres&lt;/p&gt;
&lt;p&gt;Other:&lt;br&gt;
Linux, Docker, Shell script, Celery, FastAPI, flask, Vue3, React, Nginx&lt;/p&gt;
</description>
        </item>
        <item>
        <title>Archives</title>
        <link>http://shawn1251.github.io/page/archives/</link>
        <pubDate>Sun, 01 Oct 2023 00:00:00 +0000</pubDate>
        
        <guid>http://shawn1251.github.io/page/archives/</guid>
        <description></description>
        </item>
        <item>
        <title>Search</title>
        <link>http://shawn1251.github.io/page/search/</link>
        <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
        
        <guid>http://shawn1251.github.io/page/search/</guid>
        <description></description>
        </item>
        
    </channel>
</rss>
