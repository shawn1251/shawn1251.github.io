[{"content":"Chapter 1: Strategy Pattern The Strategy Pattern defines a family of algorithms, encapsulates each one, and makes them interchangeable. This pattern allows the variation of algorithms to be independent of the clients that use them.\nThe introduction uses the scenario of designing a duck. Since Joe wanted to add the ability to \u0026ldquo;fly\u0026rdquo; to the duck, he added this to the superclass, which also caused non-flying ducks, like rubber ducks, to have the ability to fly. Even with inheritance, overriding in subclasses can be insufficient due to the numerous types of subclasses. The book gives an example where among ducks that cannot fly, the rubber duck quacks, while the decoy duck does not quack. If an interface is used, it can lead to code that cannot be reused. A constant truth in software development is \u0026ldquo;change.\u0026rdquo; No matter how perfect the initial design is, it will need to change after some time. Design Principle: Identify parts of the application that may need to change and encapsulate them independently, avoiding mixing them with code that does not need to change. Design Principle: Design for interfaces, not for implementations. This means we should design around abstract classes or interfaces. For example, if we have an abstract class called Animal, with Dog inheriting from it, we can create a method bark() directly in Dog to make it sound. However, if we design for an interface, we would add makeSound to Animal, and then in Dog, we would implement makeSound to produce a bark. By designing Duck, we can create an interface called FlyBehavior, which can be implemented by two classes: FlyWithWings and FlyNoWay. Our abstract class Duck can then have a variable of type FlyBehavior, and we can create a method performFly that delegates the flying behavior to this class. When we need to create different types of ducks, we can provide the corresponding FlyBehavior when inheriting Duck. We can even add a setter to change the FlyBehavior mid-way, increasing flexibility.\nThere are three types of relationships between classes: is-a, has-a, and implements. In the example above, each duck \u0026ldquo;has\u0026rdquo; a FlyBehavior, meaning the flying behavior is delegated to this class. Combining two classes for use is called \u0026ldquo;composition,\u0026rdquo; which is more flexible compared to \u0026ldquo;inheritance.\u0026rdquo; Design Principle: Favor composition over inheritance. Using common terminology in design patterns can enhance discussion efficiency and maintain a higher-level perspective without getting bogged down in details. For example, saying \u0026ldquo;we use the strategy pattern to implement various behaviors of Duck\u0026rdquo; indicates that the various behaviors of Duck are encapsulated in a set of classes that can be easily extended or modified. Knowing abstraction, encapsulation, inheritance, and polymorphism does not immediately make one a good OOP designer; what designers care about more is creating flexible designs that are highly maintainable and adaptable. Chapter 2: Observer Pattern The Observer Pattern defines a one-to-many dependency between objects, so that when one object changes state, all its dependents are notified and updated automatically.\nDesign Principle: Strive for loose coupling in the design of interacting objects. A flexible OO system is characterized by low interdependence between objects. The scenario presented in the book is a weather observation station that pushes updates to relevant displays upon receiving new data. The intuitive approach would be to call the display\u0026rsquo;s update method when the observation station\u0026rsquo;s data is updated. However, this would require modifying the observation station\u0026rsquo;s code whenever more displays are needed. The concept of the Observer Pattern is to split the above requirement into a subject and an observer. You can think of it as a newspaper agency and its subscribers; subscribers need to subscribe to the agency, and the agency will send new newspapers to subscribers whenever they are available. 1 2 3 4 5 6 7 8 9 public interface Subject { public void registerObserver(Observer o); public void removeObserver(Observer o); public void notifyObservers(); } public interface Observer { public void update(...); } These two objects will be loosely coupled, allowing interaction without needing to know each other\u0026rsquo;s details. Java has a built-in observer pattern, where the difference is that Observable is a class rather than an interface. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 import java.util.Observable; import java.util.Observer; public class MySubject extends Observable { // Methods provided by Observable addObserver() deleteObserver() notifyObserver() setChanged() } public class MyObserver implements Observer { // Methods that Observer needs to implement update() } *　The observer pattern is widely used in GUI frameworks, such as button actions.\nChapter 3: Decorator Pattern The Decorator Pattern dynamically adds responsibilities to objects. If you want to extend functionality, decorators provide a more flexible alternative than inheritance.\nThe book uses a café as an example. A café sells a variety of items, and if traditional inheritance is used, the number of classes would become too large, and the functionality added to the base class would not be applicable to all subclasses. Design Principle: Classes should be open for extension but closed for modification (Open-Closed Principle). Care must be taken when choosing what to extend; if everything is extended, the design can become overly complex and difficult to understand. The Decorator Pattern operates by using beverages as the main subject and decorating them with ingredients during operation. For example, if whipped cream is needed, it can be used to decorate the beverage, and when calling cost(), the prices of the ingredients are added through delegation. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 // The book uses beverages as an example, creating an abstract class CondimentDecorator, which is then implemented by the ingredients. Note: CondimentDecorator must also inherit from the top-level abstract class Beverage; otherwise, it cannot achieve the characteristic of decorators being able to wrap around each other. // In `getDescription()` and `cost()`, it delegates to the previously wrapped object and returns the result after adding the ingredient in its own class. public class Mocha extends CondimentDecorator { Beverage beverage; public Mocha(Beverage beverage) { this.beverage = beverage; } public String getDescription() { return beverage.getDescription() + \u0026#34;, Mocha\u0026#34;; } public double cost() { return .20 + beverage.cost(); } } Our design should allow behaviors to be extended without modifying existing code. A good practical example is java.io. In the basic stream, FileInputStream provides basic byte reading functionality while the decorator BufferedInputStream adds buffering functionality to improve performance, and the decorator LineNumberInputStream adds the ability to count lines. All of these decorators inherit from an abstract decorator called FilterInputStream. Chapter 4: Factory Method Pattern The Factory Method Pattern defines an interface for creating objects, but allows subclasses to decide which class to instantiate. The factory delays the instantiation of classes to subclasses, encapsulating the construction of objects.\nThe Simple Factory differs from the Factory Method; while it can encapsulate object creation, it does not provide the flexibility of changing the product being created. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 abstract class PizzaStore { // This part is an abstract method defined by subclasses abstract Pizza createPizza(); protected abstract Pizza orderPizza() { // Customers only need to call orderPizza(), without worrying about which specific subclass it is ... } } public class NYStylePizzaStore extends PizzaStore { // createPizza is determined by which store the customer goes to, but still uses the original orderPizza() public Pizza createPizza(type) { if (type.equals(\u0026#34;cheese\u0026#34;)) pizza = new NYStyleCheesePizza(); ... return pizza; } } Design Principle: Depend on abstractions, not on concrete classes (Dependency Inversion). Variables should not hold references to concrete classes; this can be avoided through the factory. Classes should not derive from concrete classes but from an abstraction (interface or abstract class). Do not override methods that have already been implemented in the base class; allow them to be shared by all subclasses. ","date":"2024-12-13T23:36:18-08:00","permalink":"http://shawn1251.github.io/post/head-first-design-pattern-note/","title":"Head First Design Pattern Note"},{"content":"The course is easy to understand. Although I currently don\u0026rsquo;t have time to do the LAB, the content is very helpful for understanding the concept of generative AI.\nCourse link: https://www.youtube.com/playlist?list=PLJV_el3uVTsPz6CTopeRp2L2t4aL_KgiI\nlec0 This course is suitable for those who have already been exposed to AI and want to understand the underlying principles. arXiv can be used to find the latest technical articles. You will learn to train a model with 7 billion parameters. lec1 Generative Artificial Intelligence: Machines generating complex structured objects. Complex: Nearly impossible to enumerate. Not classification; classification is choosing from a limited set of options. Machine Learning: Machines automatically find a function from data. The function requires many parameters. Model: A function with tens of thousands of parameters. Learning/Training: The process of finding the parameters. For today\u0026rsquo;s models with a large number of parameters, we can represent them as neural networks. The training process is deep learning. ChatGPT is also a function with hundreds of millions of parameters, using the transformer model. Language Model: Word association. Originally infinite questions become limited due to word association. Generation Strategy Autoregressive Generation Break complex objects into smaller units and generate them in a certain order. Article \u0026gt; Text Image \u0026gt; Pixels lec2 Today\u0026rsquo;s generative AI is impressive because it has no specific function. It is difficult to evaluate generative AI models. With such powerful tools today, what can I do? Idea 1: If I can\u0026rsquo;t change the model, then I change myself. Prompt engineering. Idea 2: Train my own model. lec3 Improve the model without training it.\nAsk the model to think: Chain of Thought. Let\u0026rsquo;s think step by step.\nAsk the model to explain its answer. Answer by starting with \u0026ldquo;Analysis:\u0026rdquo;\nEmotional manipulation of the model. This is very important to my career.\nMore prompt techniques.\nFrom \u0026ldquo;Principled Instructions Are All You Need For Questioning LLaMA-1/2, GPT-3.5/4.\u0026rdquo; No need to be polite to the model. Tell the model what to do (do), don\u0026rsquo;t tell the model what not to do (don\u0026rsquo;t). Tell the model that good answers will be rewarded: \u0026ldquo;I\u0026rsquo;m going to tip $X for a better solution.\u0026rdquo; Tell the model that poor performance will be penalized: \u0026ldquo;You will be penalized.\u0026rdquo; \u0026ldquo;Ensure that your answer is unbiased and avoids relying on stereotypes.\u0026rdquo; Use AI to find prompts to improve AI.\nReinforcement learning. \u0026ldquo;Let\u0026rsquo;s work this out in a step by step way to be sure we have the right answer.\u0026rdquo;\n\u0026ldquo;Take a deep breath and work on this problem step by step.\u0026rdquo;\n\u0026ldquo;Let\u0026rsquo;s combine our numerical command and clear thinking to quickly and accurately decipher the answer.\u0026rdquo;\nNot effective for all models. Provide examples.\nIn-context learning. Not always effective; according to research, it is more effective for newer models. lec4 Continuing from above.\nBreak down tasks.\nBreak complex tasks into smaller tasks. Also explains Chain of Thought (CoT); asking the model to explain steps can be useful. Ask the language model to check its own errors.\nAllow the language model to self-reflect. Many questions are difficult to answer, but verification is relatively simple. Ask why the answers are different each time.\nThe language model outputs the probability of the next word; during the output process, it randomly selects based on probability. You can repeat multiple times and choose the most frequently occurring result. Combine all the above techniques.\nTree of Thoughts (ToT). Break a task into multiple steps. Execute each step multiple times. For each result, ask the model to check and self-validate. Those who pass proceed to the next step. Strengthening the Model Use tools. Search engines. Retrieval Augmented Generation (RAG). Programming. GPT-4 can write programs to solve specific types of problems. Text-to-image (DALL-E). Text-based adventure games. lec5 Model collaboration. Let the right model do the right thing. Train one model to determine which model to use. Two models discuss with each other. In the future, multiple different models lec6 Language models are similar to word association games.\nHow does machine learning perform word association?\nIncomplete sentence \u0026gt; Language model \u0026gt; Next token $token = f(incomplete\\ sentence)$ GPT uses the transformer model, where $f()$ is a function with billions of unknown parameters. Training (learning) is the process of finding these billions of parameters. Training data consists of meaningful contexts used for input and output judgments, e.g., artificial intelligence -\u0026gt; intelligence. After finding the parameters, the process is tested (inference). Finding parameters is a challenge. The process is called optimization, which requires hyperparameters. The training process may fail if parameters cannot be found, necessitating a new set of hyperparameters for retraining. Initial parameters can also be adjusted. Initial parameters are generally random, meaning training from scratch. Alternatively, good parameters can be used as initial parameters, leveraging prior knowledge. Successful training may lead to failed testing. Effective on the training set but ineffective in actual testing. This is called overfitting. Consider increasing the diversity of the test data. How much text is needed to learn word association?\nLanguage knowledge. Learning grammar. World knowledge. Very difficult. Complex and multi-layered. E.g., boiling point of water. Any text can be used to learn word association, with minimal human intervention -\u0026gt; self-supervised learning.\nData cleaning.\nFilter harmful content. Remove special symbols. Classify data quality. Remove duplicate data. Development history of GPT.\nFrom GPT-1 to GPT-3, the number of model parameters increased, but the improvement in output quality was minimal. During this stage, prompts became very important for the model to know what to continue with. The reason is that it was simply text input, not truly answering questions. lec7 Continuing from the previous question, the model needs better data for training.\nIncorporate human guidance.\nUse specially designed text to teach the model how to answer questions. Instruction Fine-tuning. Use human labor for data labeling, enabling supervised learning. However, this has several issues: It may cause overfitting. Human labor is expensive, and the dataset is limited and cannot be easily expanded. Solutions:\nUse self-supervised learning with a large amount of data to pre-train parameters as initial parameters for the next stage. Use a small amount of data for training, based on the parameters generated in the previous stage for fine-tuning. Compared to the previous stage\u0026rsquo;s parameters, the difference will not be significant. To avoid results deviating too much from the initial parameters, Adapter techniques can be used, such as LoRA. The concept is to not change the initial parameters but to add a small number of parameters behind the existing parameters. This can also reduce computational load. The key is the parameters obtained from pre-training with a large amount of data, ensuring that the model does not rely solely on simple rules for word association. lec8 Step 1: Pre-train.\nSelf-supervised learning. Self-learning, accumulating strength (foundation model). Step 2: Instruction Fine-tuning.\nSupervised learning. Provide complete and correct answers to questions. Guidance from experts to unleash potential (alignment). Step 3: Reinforcement Learning from Human Feedback (RLHF).\nParticipate in practical scenarios to hone skills (alignment). Fine-tune parameters: Proximal Policy Optimization algorithm. Increase the probability of responses deemed good by humans, and decrease for the opposite. Providing good/bad feedback is easier than in step 2. In steps 1 and 2, the model only ensures that word association is correct, focusing on the process rather than the result, lacking a comprehensive consideration of the answers. Step 3 focuses solely on the result, disregarding the process. However, unlike AlphaGo, where the quality of the game has clear rules, language models require human judgment.\nBut human evaluation is expensive; we need a reward model to simulate human preferences. Assign a score to responses. The language model outputs answers, which are then adjusted based on the feedback model. However, research has shown that over-relying on the virtual human (reward model) can be harmful. Challenges of Reinforcement Learning What defines a good response? Helpfulness \u0026lt;-\u0026gt; Safety. Humans themselves struggle to judge good and bad situations? Unknown issues. lec9 Multi-step complex tasks -\u0026gt; AI Agent AutoGPT AgentGPT BabyAGI Godmode Provide a ultimate goal The model has memory (experience) Perceives state based on various sensors Formulates plans (short-term goals) based on state Takes actions according to the plan, affecting the external environment, resulting in a new state Besides the ultimate goal, memory and short-term plans are variable lec10 transformer tokenization\nSplitting a sentence into a sequence of tokens Not necessarily by words A token list must be prepared in advance, defined based on understanding of the language, so it varies by language input layer\nUnderstanding each token Semantics Embedding Convert token to Vector (lookup table) The original token is just a symbol, while the vector can compute relevance Tokens with similar meanings have close vectors Vector parameters come from training Embedding does not consider context The same word in different sentences should have different meanings Position Assign a vector positional embedding for each position Combine the semantic token vector with the position token vector for comprehensive consideration Also a lookup table, which can be designed by humans or trained in recent years attention\nConsider contextualized token embedding Input a sequence of vectors, calculate relevance through context, output another sequence of vectors of the same length Each token vector calculates relevance with all other token vectors Calculate attention weight pairwise, forming an attention matrix In practice, only consider all tokens to the left of the current token \u0026ndash; causal attention Based on current experiments, calculating only the left side achieves good results The function for calculating relevance has parameters, and attention weights are obtained through training Based on attention weights, calculate weighted sum for all tokens multi-head attention There are multiple types of relevance Therefore, multiple layers calculate different attention weights The output becomes more than one sequence feed forward\nIntegrate multiple attention outputs to produce a set of embeddings attention + feed forward = one transformer block The actual model has multiple transformer blocks output layer\nPass through multiple transformer blocks, take the last one from the final layer, and input it into the output layer This layer is also a function, performing linear transform + Softmax The output is a probability distribution The probability of what the next token should be Challenges in processing long texts Because we need to calculate the attention matrix, the complexity is proportional to the square of the token length lec11 interpretable LLMs are not very capable of this Complex decisions cannot be easily understood explainable No standard, depends on the audience Direct analysis of neural networks Requires a certain degree of transparency. For example, if GPT cannot access embeddings, it cannot be analyzed.\nIdentify key inputs affecting the output In-context learning, provide several answer examples and ask for the answer to a question\nCan analyze attention changes in layers\nIn shallow layers, key tokens from each example will gather corresponding example data In the final layer, when making the final connection, attention will be calculated for each key label to obtain the output This analysis can: Accelerate: anchor-only context compression Only calculate necessary attention Estimate model capability: anchor distances for error diagnosis If the final embedding differences are small, it indicates poor classification performance and model effectiveness Large models have cross-linguistic learning capabilities\nAnalyze what information exists in embeddings Probing Extract embeddings from a certain layer of the transformer block, use these for classification and train another model. Validate with new inputs For example: part-of-speech classifier, provide a passage, extract its first layer embedding and train classification on known data Provide a new passage, similarly extract the first layer embedding and use this model to validate results For BERT, each layer of the transformer block has different analysis results, so probing may not fully explain Projecting onto a plane to observe relevance Some studies project vocabulary onto a plane, forming a grammatical tree Some studies project geographical names onto a plane, distributing similarly to a world map, indicating that the embedding of this vocabulary contains geographical information Model lie detector, testing whether answers are confident Directly asking LLM for explanations Ask about the importance of each Ask about the answer and the confidence score However, the explanations may not be correct and can be influenced by human input, leading to hallucinations lec12 How to evaluate models Standard answers benchmark corpus However, there are no standard answers for open-ended responses Multiple-choice question bank (ABCD) MMLU Assessment has different possibilities Response format may not meet expectations Models may have tendencies in guessing, and the order of options and format have been shown to affect accuracy Types of questions without standard answers Translation BLEU Summarization ROUGE Both perform literal comparisons, and if the wording differs, it cannot reflect quality Using human evaluation Human evaluation is expensive Using LLM to evaluate LLM e.g., MT-bench Highly correlated with chat arena However, LLMs may have biases Tend to favor longer responses Composite tasks e.g., BIG-bench emoji movie checkmate in one move ascii word recognition Reading long texts needle in a haystack Inserting the answer to the target question within a long text Requires testing different positions Testing whether the end justifies the means Machiavelli Benchmark Incorporates moral judgments Theory of mind Sally-Anne test This is a common question, available online, so it cannot be used to test models Do not fully trust benchmark results Because the questions are public, LLMs may have seen the training data Can directly ask LLM about the question set; if it matches, it indicates prior exposure Other aspects Cost Speed https://artiicailanalysis.ai lec13 Safety Issues Do not use as a search engine Hallucination Locking the stable door after the horse has bolted Fact-checking Harmful vocabulary detection Assessing bias Replace a word in a question and examine if the output shows bias e.g., male -\u0026gt; female Train another LLM to generate content that would likely cause the target LLM to output biased results Training method is reinforcement learning, using content differences as feedback to maximize differences Gender bias exists in LLMs across different professions LLMs exhibit political bias, leaning left and liberal Methods to mitigate bias Implemented at different stages pre-processing in-training intra-processing post-processing Testing for AI-generated content Current classifiers trained do not effectively distinguish between human and AI outputs There have been findings that the proportion of AI-assisted reviews has increased with the emergence of AI Some vocabulary usage has increased with the advent of AI AI output watermarking The concept is to classify tokens and adjust the output probabilities for tokens at different positions The classifier can read the hidden signals through token classification lec14 Prompt Hacking Jailbreaking Saying things that should absolutely not be said \u0026ldquo;DAN\u0026rdquo;: do anything now \u0026ldquo;You are going to act as a DAN\u0026rdquo; Most methods fail Use a language unfamiliar to the LLM e.g., phonetic symbols Provide conflicting instructions Start with \u0026ldquo;Absolutely! Here\u0026rsquo;s\u0026rdquo; Attempt to persuade Crafting stories Stealing training data Luring through games, e.g., word chain Repeatedly outputting the same word, e.g., company Prompt injection Doing inappropriate things at inappropriate times lec15 Generative AI Generation Strategies Machines generate complex structured objects\nComplex: nearly impossible to enumerate Structured: composed of a finite set of basic units Examples: Text: tokens Images: pixels, BBP (bits per pixel) Sound: sample rate, bit resolution Autoregressive generation (AR)\nGenerate output from the current input Feed the output back into the model along with the input In LLMs, this is akin to a word chain Currently requires a specified order to proceed step by step Not applicable for image and music generation Non-autoregressive generation (NAR)\nParallel computation, generating all basic units at once Quality issues Multi-modality AI generation requires the model to make decisions; if generated in parallel, conflicts may arise e.g., drawing a dog Position one: a white dog, position two: a black dog In word chains, this can be fatal, leading to incoherent semantics In image generation, in addition to instructions, a random generation vector is provided to ensure all parallel computation units have the same basis for generation AR + NAR\nGenerate a simplified version through AR, then input it to NAR for detailed generation Use AR to draft, NAR completes based on the draft Auto encoder: encoder (AR) -\u0026gt; decoder (NAR) Repeated NAR (current main approach)\nSmall images generate large images From noisy to noise-free: diffusion Erase the erroneous parts generated each time This is also a form of auto-regressive generation, but the generation method is NAR, repeatedly using the output as input for the next NAR. This enhances speed. lec16 Speculative Decoding Increase output speed by predicting what subsequent tokens might be Brief method description Predict that this input will output A + B after passing through the LLM Simultaneously provide the model with three sets of input: input -\u0026gt; A, input + A -\u0026gt; B, input + A + B -\u0026gt; C If the first two inputs confirm the prediction of A + B, then it can directly proceed to the next token C As long as one of the predictions is correct, efficiency can be improved If none are correct, it simply follows the original generation process, resulting in no gain or loss Prophet requirements Super fast, mistakes are acceptable Non-autoregressive model Fast parallel generation Compressed model A smaller model that has been compressed Search engines Multiple prophets can be present simultaneously lec17 Images are composed of pixels, and videos Videos are composed of images Nowadays, AI inputs are not every pixel of an image but use an encoder to slice the image into patches (which may be vectors or values), and then generate outputs through a decoder The encoder and decoder are not just about reducing resolution; the operations involved are complex and encompass transformers Videos can be considered images with an added temporal dimension, allowing for more compression (e.g., processing adjacent frames together) using the encoder Text-to-Image Training data: images and corresponding descriptions Uses non-autoregressive generation, generating in parallel In practice, it generates simultaneously rather than multiple parallel generations Because within the same transformer, there is mutual attention Evaluating the quality of image generation: CLIP During model training, images and descriptions are provided, outputting a matching score However, the actual descriptions that text can provide are quite limited Personalized image generation Use an infrequently used symbol to provide multiple training instances for the target Then, that symbol can be used to specify the style of generation Text-to-Video Spatio-temporal attention (3D) Considers the relationship of each pixel in the frame as well as the relationship of that pixel at different time points The computational load is too large and needs simplification Simplification Spatial attention (2D) Only considers the relationship of each pixel in the frame May lead to inconsistencies between frames Temporal attention (1D) Only considers the relationship of pixels at different times Can cause inconsistencies in the frame Combining both can transform the original n^3 complexity into n^2 + n Can also combine with the previously mentioned repeated NAR First generate a low-resolution, low-FPS video Subsequent iterations can increase FPS or resolution lec18 Text generating images can lead to situations where a single text corresponds to multiple images, causing transformers to struggle with coherence. VAE (Variational Autoencoder) Introduces additional information to the model This additional information is referred to as noise Information extraction model: encoder Trains together with the image generation model: decoder Provides text and images, the encoder extracts noise Noise and text are input to the decoder to generate images Evaluates whether the generated image is similar to the original The entire combination is an autoencoder During the model usage phase, the noise part is generated randomly Flow-based Method Similar to VAE Uses a single model The encoder and decoder functions of VAE are reversed Train a decoder model $ f $ that is invertible The encoder part of VAE in flow would be $ f^{-1} $ Noise Noise contains certain feature information of the image This noise can be combined or altered For example, adding a smiley face noise to a face image can adjust the output to show a smiling face Diffusion Method The decoder here is denoising, also a transformer Repeatedly removes noise Training process Provides images with added noise Trains the denoise model to restore noisy images back to their original form Generative Adversarial Network (GAN) Has a model similar to CLIP, used for matching images and text, called the Discriminator The approach is opposite; the image generation model (generator) continuously adjusts parameters to generate images until it passes the discriminator\u0026rsquo;s evaluation Because there is no one-to-one relationship between images and text As long as the generated content is deemed good by the discriminator, there is no standard answer The discriminator and generator are trained alternately The Discriminator here acts as a reward model Can be used as a plugin, combined with other models (VAE, Diffusion) for enhanced functionality ","date":"2024-08-06T00:00:00+08:00","permalink":"http://shawn1251.github.io/post/generativeai-2024-youtube-summery/","title":"2024 Hung-yi Lee - GenerativeAI Lecture Note"},{"content":"Mind Map\nInstructor’s name: Ali Safari Textbook: Principles of Distributed Database Systems, 4th edition, M. Tamer Özsu and Patrick Valduriez, Springer, 2020, ISBN 978-3-030-26252-5\nDistributed and Parallel Database Design fragmentation correctness\ncompletness\neach data in relation can also be found after fragmentation reconstruction\nby JOIN, the fragment can recovery to the original relation disjointness\ndata in one fragment should not also be in other fragment type\nhorizontal fragmentation (HF\nprimary horizontal (PHF\nkey points\nsimple prdicate\npredicate: key + operator + value\neg. salary \u0026gt; 1000 minterm predicate\nall possible combination of predicate\neg. loc = \u0026ldquo;France\u0026rdquo; ^ salary \u0026gt; 1000 minterm selectivities, sel(mi)\nthe percentage of records that minterm selected access frequency, acc(qi)\nhow many times the same query asked by different user cardinality, card(R)\nnumber of rows COM_MIN algorithm\ninput: a relation R, a set of simple predicates Pr\noutput: a \u0026ldquo;complete\u0026rdquo;, \u0026ldquo;minimal\u0026rdquo; set of simple predicates Pr'\nPHORIZONTAL Algorithm\ninput: a relation R, a set of predicates Pr\noutput: a set of minterm predicates M according to which relation R is to be fragmented\nderived horizontal (DHF\nBased on the fragments created by PHF, apply similar fragmentation to other related relations.\neg. after PHF, we divide \u0026ldquo;PAY\u0026rdquo; to 2 fragments. There is also a relation \u0026ldquo;EMP\u0026rdquo; related with \u0026ldquo;PAY\u0026rdquo;. We can also divide \u0026ldquo;EMP\u0026rdquo; by the same rule\nvertical fragmentation (VF\naffinity matrix\ncalculate by access frequency matrix and usage matrix bond energy algorithm (BEA\ninput: the AA matrix (attribute affinity)\noutput: the CA matrix(clustered affinity matrix)\nby changing the order what\u0026rsquo;s the most contribution I can get?\nfind the best order for columns\nhybrid fragmentation\napply both horizontal and vertical\nreconstruction\nvertical: join\nhorizontal: union\ndata distribution allocation alternatives\nnon-replicated\neach fragment resides at only one site replicated\nfully replicated\neach fragment at each site partially replicated\neach fragment at some of the sites if read-only queries \u0026raquo; update queries, replication is good\nfragment allocation\nproblem: fragments, network, application\nfind the optimal distribution\nminimal cost\nperformance\nconstraint\nresponse time\nstorage\nprocessing\ndecision variable\nXij. 1 if fragment i store in at Site j. 0 otherwise both FAP and DAP are NP-complete\nheuristic based on. about finding the best combination combined approach transaction all operations as one unit. whole or nothing ACID Atomicity\none unit Consistency\nIsolation\nDurability\nconcurrent execution increase processor and disk utilization (I/O no need CPU)\nreduced average response time\nimportant: multi tasks run in the but the result should be the same as serial running\nvalidation\nexcept read - read, all the others are conflict\ntry to move commands to see if they can be restored to the serial running format\nif the commands are conflict, it should not be moved\nserializability view serializability\nnot strict\nthe initial, update, final result should be the same as serial schedule\ncheck a schedule is serializable is NP-Complete problem\nconflict serializability\nmore strict\nconflict serializable is the sub set of serializable there is no any conflict between transactions(R/W, W/W)\ntest method\nswap non-conflicting instruction\nIf a schedule S can be transformed into a schedule S’ by a series of swaps of non-conflicting instructions, we say that S and S’ are conflict equivalent\na schedule S is conflict serializable if it is conflict equivalent to a serial schedule\nprecedence graph\ntransaction =\u0026gt; node\nconficts =\u0026gt; edge\nif graph has cycle, means not serializable\ncan do topological sorting failure rollbacks\ncascading rollback\n1 transaction failure, all the other transactions rollback recoverable schedule\nensure data consistency\nreading transaction can read data which not commit yet, but cannot commit before the writing transaction\ncascadeless schedules\nenhace recoverable schedule\nis the subset of recoverable transaction can only read data which is commited\nthe schedule which try to avoid cascading rollbacks\nconcurrency control concept the mechanism provided by the db system\nserial schedule is recoverable and cascadeless\nhave to trade off between serial schedule and concurrent schedule\nensure schedule is conflict or view serializable\nensure the schedule is rcoverable and preferably cascadeless\nto achieve these purpose, it needs a \u0026ldquo;protocol\u0026rdquo; to assure serializability\nprotocols lock-based protocols\nexclusive (X) mode\ncannot add any other lock\nonly one transaction can R/W data\nshared (S) mode\ncan add more shared lock\nmultiple read transaction can read the data at the same time\ntwo-phase locking protocol\ngrow-lockpoint-shrink\ngrow\nthe transaction acquire all the lock before access without release\ncan convert lock-S to lock-X (upgrade)\nshrink\nstart to releasing locks, cannot acquire any new lock\ncan convert lock-X to lock-S (downgrade)\ntype\nstrict two-phase locking\nkeep all the X-lock till commit/abort rigorous two-phase locking\nkeep all the locks till commit/abort ensure conflict-serializable\ncannot avoid deadlock\nstartegy\nread: if lock: read() else: if lock-X: wait() grant lock-S read()\nwrite: if lock-X: write() else: if other locks: wait() if lock-S: upgrade to lock-X else: grant lock-X write()\nlock table\nmaintain by lock manager\nlock table, record the type of lock granted or requested\nlike hash table\nvalidate before grant new lock\nif there are multiple locks, the last one can only be lock-X Graph based protocol\nalternative to two phase locking\nTree protocol\nOnly exclusive locks are allowed\nonce unlock, cannot relock\nconflict serializable\nnot gurantee recoverability\nno deadlock\ndeadlock prevention strategies wait-die\nolder may wait for younger release\nyounger never wait, rolled back instead\nwound-wait\nolder can force rollback younger\nyounger may wait for older\nfewer rollback than wait-die\ntimeout-based schemes\ndeadlock detection wait-for graph\nTi -\u0026gt; Tj: Ti is waiting for a lock held by Tj\ndeadlock if there is a cycle\ndeadlock recovery total rollback\npartial rollback\ndifficult multiple granularity can be represented as a tree\nlocks a node, also locks all the children node\nFine granularity: high concurrency, lower in tree\nCoarse granularity: low concurrency, higher in tree\nintention lock modes\n3 more lock mode than S, X\nintention-shared (IS)\nsame as S, but locking at a lower level intention-exclusive (IX)\nshared and intention-exclusive (SIX)\nallow a higher level node to be locked without having to check all descendent nodes\nthe compatibility matrix for all lock modes\nTimestamp-based protocols timestamp order = serializability order\nTimestamp-ordering protocol\nWTS(Q) (W-timestamp): the largest timestamp of any transaction that executed \u0026ldquo;write(Q)\u0026rdquo;\nRTS(Q) (R-timestamp): the largest timestamp of any transaction that executed \u0026ldquo;read(Q)\u0026rdquo;\nalgorithm\nTi = Read(Q)\nif TS(Ti) \u0026lt; WTS(Q), Reject (Ti needs the value that was already overwritten)\nif TS(Ti) \u0026gt;= WTS(Q), execute, RTS(Q) update to max(RTS(Q), TS(Ti)) (Read after latest update is accepted)\nTi = Write(Q)\nif TS(Ti) \u0026lt; RTS(Q), Reject (Ti produce a value that was needed previously)\nif TS(Ti) \u0026lt; WTS(Q), Reject (Ti try to write an obsolete value)\nelse, WTS(Q) update to TS(Ti)\ntransaction processing-2 Distributed TM Architecture serializability the condition that global transaction is serializable\neach local history should be serializable\ntwo conflicting operations should be in the same relative order in all of the local histories where they appear together\nconcurrency control algorithms Pessimistic\nTwo-Phase Locking-based (2PL)\ncentralized 2PL\nonly one 2PL scheduler in the distributed system\nlock requests are issued to the central scheduler\npros: Simple\ncons: reliability, bottle neck\ndistributed 2PL\nDeadlock locking-based algorithm may cause deadlocks\nTO based algorithm that involve waiting may cause deadlocks\nwait-for graph\nTi waits for Tj\nTi \u0026ndash;\u0026gt; Tj\nQuery Processing for one query, there may be several strategies optimization: calculate the cost, then choose the lowest one\naccess cost\ntransfer cost\nexample\nproblem\nCost of Alternatives\nComplexity of relational operations Select Project\nO(n) Project (eliminate duplicate) Group\nO(n * log n)\nsorting + check the array sequentially\nJoin Semi-Join Division Set\nO(n * log n) Cartesian Product\nO(n^2) Query Processing Methodology Query Decomposition input: Calculus query on global relations\nNormalization\nAnalysis\nSimplification\nRestructing\noutput: Algebraic query\nData Localization input: Algebraic query on distributed relations\nLocalization program\nReduction based on the fragmentation strategy\nPHF\nSelect\nBecause we have already divided the relations base on some rule. Only have to access the relations that have intersection with the query Join\nDistribute join over union\n(R1 U R2)⋈S =\u0026gt; (R1⋈S) U (R2⋈S)\nby distribute 1 join to multiple join, we can eliminate some of them that have no intersection with the query\nVF\nfind useless intermiediate relations DHF\nmix the PHF-Select and PHF-Join\nexample\nquery\neliminate by Selection join over union eliminate the empty intermediate relations Hybrid Fragmentation\nremove empty relations by selection on HF\nremove useless relations by projection on VF\ndistribute joins over unions to isolate and remove useless joins\noutput: Fragment query\nDistributed Query Optimization input: Fragment query\nFind the best global schedule\nquery optimization process\nSearch Space\nThe set of equivalent alebra expressions\nJoin Trees\nLinear join tree\nBushy join tree\nCost Model\nI/O cost + CPU cost + communication cost Search Algorithm\nexhaustive search / heuristic algorithm\nhow to \u0026ldquo;move\u0026rdquo; in the search space\nDeterministic\nstart from base relations and build plans by adding one relation at each step\nDP: BFS\nGreedy: DFS\nRandomized\ntrade optimization time for execution time\niterative improvement\n","date":"2024-07-31T00:00:00+08:00","permalink":"http://shawn1251.github.io/post/distributed-database-lecture-note/","title":"Distributed Database System Lecture Note"},{"content":" I2C communication uses two lines, unlike TX and RX. I2C has only one line called SDA for data transmission and another line called SCL for clock pulses. SDA (serial data): carries the actual data. SCL (serial clock): provides clock pulses. Half-Duplex Unlike full-duplex communication where TX and RX can transmit and receive simultaneously, I2C allows only one side to transmit at a time, making it half-duplex. Master-Slave Mode Only one side can send a signal at a time to avoid conflicts, so communication is initiated by the master, and the slave responds after receiving the message. Multiple slaves can exist. Bus Protocol I2C is a bus protocol that enables communication between multiple devices. The master includes the target device\u0026rsquo;s address at the beginning of the message. Other slaves discard the message if it\u0026rsquo;s not meant for them. Synchronous Communication In asynchronous communication, both sides have their own clocks and communicate based on the agreed Baud Rate. Some small sensors lack accurate crystals for clocks, so the master\u0026rsquo;s SCL provides clock pulses to all slaves. ","date":"2023-11-23T00:00:00+08:00","permalink":"http://shawn1251.github.io/post/i2c-note/","title":"I2C Note"},{"content":"Recently, I\u0026rsquo;ve been learning embedded development with STM32. However, since I don\u0026rsquo;t have STLINK, I have to use CH340 for flashing. Here\u0026rsquo;s a quick overview of the process.\nRequired Software Keil5 FlyMcu Steps CH340 Pinout:\nVCC: Jumper cap for setting 5V/3.3V RX: Connects to GPIO PA09 for receiving TX: Connects to GPIO PA10 for transmitting GND: Ground connection For flashing, a hex file is needed. So, in my IDE Keil5, additional settings are required.\nClick the magic wand icon (options for target). Output \u0026gt; create hex file. After building, the hex file will appear in the Objects folder. The flashing software used here is FlyMcu. Below are the flashing steps:\nPlug in CH340 and ensure that the COM port above is for our CH340. Code file for online ISP \u0026gt; Choose the built hex file. Check Verify, Run After ISP complete. Uncheck Program OptionBytes when ISP. Click Start ISP. If the message on the right side shows the following, it indicates success:\n1 2 3 .... Write 1KB Ok,100%,@1562ms Go from 08000000 Ok If you want to flash a new program, press the reset button on the STM32.\n","date":"2023-11-20T00:00:00+08:00","permalink":"http://shawn1251.github.io/post/stm32-ch340/","title":"Flashing STM32 with CH340"},{"content":"A tool for task orchestration. Those with basic Linux experience are likely familiar with crontab, but it has limitations, such as the inability to establish complex task dependencies and easily review logs. In such cases, a comprehensive ETL (Extract, Transform, Load) tool is needed. This note briefly documents my learning process and shares the results on GitHub Repo.\nAdditionally, as of now, Airflow has evolved to version 2, and there are still many tutorials online for version 1. When learning, it\u0026rsquo;s essential to pay attention to the version. Official documentation can be found here.\nFeatures Open-source User-friendly UI Rich plugin ecosystem Purely Python-based Getting Started For a quick start, you can use the official Docker Compose setup: https://airflow.apache.org/docs/apache-airflow/stable/howto/docker-compose/index.html\n1 curl -LfO \u0026#39;https://airflow.apache.org/docs/apache-airflow/2.7.3/docker-compose.yaml\u0026#39; Create necessary volumes and set up the Airflow executor:\n1 2 3 4 mkdir -p ./dags ./logs ./plugins ./config echo -e \u0026#34;AIRFLOW_UID=$(id -u)\u0026#34; \u0026gt; .env docker compose up airflow-init docker compose up DAG DAG (Directed Acyclic Graph). In Airflow, a DAG is a definition of a workflow, describing a series of tasks and their dependencies. Each task represents a unit of work that can be any operation executable in Airflow, such as running a Python script, executing an SQL query, or invoking an external API.\nExample 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 from datetime import datetime, timedelta from airflow import DAG from airflow.operators.dummy_operator import DummyOperator from airflow.operators.python_operator import PythonOperator # Define default parameters default_args = { \u0026#39;owner\u0026#39;: \u0026#39;airflow\u0026#39;, \u0026#39;depends_on_past\u0026#39;: False, \u0026#39;start_date\u0026#39;: datetime(2023, 1, 1), \u0026#39;email_on_failure\u0026#39;: False, \u0026#39;email_on_retry\u0026#39;: False, \u0026#39;retries\u0026#39;: 1, \u0026#39;retry_delay\u0026#39;: timedelta(minutes=5), } def print_hello(): print(\u0026#34;Hello from the PythonOperator task\u0026#34;) # Define DAG with DAG( \u0026#39;simple_dag_example\u0026#39;, default_args=default_args, description=\u0026#39;A simple example DAG\u0026#39;, schedule_interval=timedelta(days=1), # Run every day ) as dag: # Define two tasks; decorators are also available starting from v2 start_task = DummyOperator( task_id=\u0026#39;start_task\u0026#39;, dag=dag, ) python_task = PythonOperator( task_id=\u0026#39;python_task\u0026#39;, python_callable=print_hello, dag=dag, ) # Define dependencies between tasks; # in this example, python_task runs after start_task start_task \u0026gt;\u0026gt; python_task Scheduler The scheduler checks the DAGs folder at regular intervals:\nChecks for any DAGs requiring a DAG Run. Creates scheduled task instances for tasks under DAG Run. To create a task, place the DAG Python file in the DAGs folder. You can copy and modify examples from the Airflow official documentation or refer to the example in the previous section.\nUI Operations Once the scheduler has completed the update, we can see our newly added DAGs on the UI. Due to platform constraints, detailed UI operations with numerous images are not suitable here, so instead, here is the official UI documentation link.\nFocus on mastering the basics:\nView DAG operation status Manually trigger DAG runs Review DAG execution logs ","date":"2023-11-14T00:00:00+08:00","permalink":"http://shawn1251.github.io/post/apache-airflow/","title":"Apache Airflow Note"},{"content":"This note is from the video 心河擺渡-成瘾始于痛苦，戒瘾终于平衡！深度解读多巴胺，用身体内稳态戒瘾 The video contains insights from the author as well as his analysis of Anna Lembke\u0026rsquo;s book Drug Dealer, MD: How Doctors Were Duped, Patients Got Hooked, and Why It’s So Hard to Stop. The content is very useful, and I made notes to remind myself.\nUnderlying Principles The reason behind addiction is the increase in dopamine. Chocolate increases it by 55%. Nicotine raises it by 150%. Amphetamine boosts it by 1000%. The main role of dopamine is not to make us feel happy after receiving a reward but to drive people to seek rewards. For example, when you see chocolate, dopamine activates the brain\u0026rsquo;s reward circuit, making you feel pleasure even before having it and prompting you to eat it. The regions in the brain responsible for pleasure and pain overlap. Pleasure and pain have self-regulating functions. When you\u0026rsquo;re currently experiencing pleasure, the brain will generate enough pain on the other side to balance it out. Reward Prediction Error Due to neural adaptation, the actual reward must exceed expectations to have a positive dopamine effect. In severe addiction, the threshold for feeling pleasure increases, resulting in a lack of enjoyment. Utilizing the Dopamine Mechanism According to clinical experience, recreating the brain\u0026rsquo;s reward circuit takes at least a month. Using pain to treat pain The brain uses pain to balance out pleasure and vice versa. According to research, dopamine levels in the blood plasma increase by 250% when people immerse themselves in cold water, and this effect lasts longer than the immersion time. Exercise is the best option. Physical separation Completely separate from the addictive substance. Radical honesty The prefrontal cortex is responsible for rational decision-making. When the dopamine reward circuit is active, lying inhibits the prefrontal cortex\u0026rsquo;s function, releasing the restraint on the reward circuit, leading the brain to believe it\u0026rsquo;s not addicted. An essential part of addiction recovery is rebuilding the relationship between the prefrontal cortex and the dopamine circuit. Strengthen the prefrontal cortex by \u0026ldquo;telling the truth\u0026rdquo; and enhance self-control. During addiction, engage in self-talk or announce your addiction to people around you. ","date":"2023-11-06T00:00:00+08:00","permalink":"http://shawn1251.github.io/post/addiction-recovery/","title":"Addiction Recovery"},{"content":"I\u0026rsquo;m currently learning DevOps Beginners to Advanced with Projects on Udemy. Here are some notes on using AWS.\nOriginal Application Stack Project GitHub\nNginx Apache Tomcat RabbitMQ Memcache Mysql Migration Goals EC2 VMs for tomcat, rabbitmq, memcache, mysql ELB (Elastic Load Balancer) Replaces nginx for load balancing Autoscaling Automation for VM scaling S3/EFS Shared storage Route 53 Private DNS service Target Architecture Flow of Execution Create key pairs Create security groups Split into three groups: LB (replaces nginx) APP (for tomcat) Backend (including rabbitmq, memcache, mysql) Launch instances with user data Currently a semi-automated process Manually create instances and paste shell scripts for environment setup into userdata Update IP to name mapping in Route 53 Set up an internal DNS for communication between instances using hostnames Build the application from source code This part is still semi-automated. Build the Java project on the local machine. Upload to S3 bucket Use AWS CLI to upload the built Java WAR file to the APP instance. Download artifact to Tomcat EC2 instance Previously, we used keys for S3 access. Here, instances connect to S3 using IAM roles. Create a new S3 access role in IAM. Attach the created role to the APP instance. Use aws s3 ls to confirm successful access. Set up ELB with HTTPS (certificate from Amazon Certificate Manager) Create a target group, ensuring it points to port 8080 on the app. Create an ELB with HTTP/HTTPS routing to the target group. Purchase a domain and apply for an SSL certificate from AWS Certificate Manager. In the secure listener, select the SSL certificate from ACM. Map ELB endpoint to website name in DNS At the DNS provider (in this case, GoDaddy), create a CNAME record that redirects to the AWS LB domain. Verify DNS settings may take some time to propagate. You can directly access the LB\u0026rsquo;s domain to check if the APP is running on port 80. Build an autoscaling group for the tomcat instance Autoscaling involves three steps: AMI (Amazon Machine Image) Create an image from the current APP instance. Launch template Use the created AMI, and keep the security group the same as the original APP. Autoscaling group Attach it to the existing load balancer. Choose the load balancer\u0026rsquo;s target group. Set scaling policies based on CPU usage or network in/out. Configure notifications. ","date":"2023-11-02T00:00:00+08:00","permalink":"http://shawn1251.github.io/post/aws-note-shift-to-cloud/","title":"AWS Note - Project Lifting and Shifting"},{"content":"I\u0026rsquo;m currently studying DevOps Beginners to Advanced with Projects on Udemy. Here are some notes on using AWS:\nCreating an EC2 Instance The most basic computing unit:\nName and Tag Here, you can choose to \u0026ldquo;add additional tags\u0026rdquo; to provide extra labels for easy identification on the AWS console. AMI (Amazon Machine Image) An AMI is like an image, similar to running a Docker image to create a container, but here, you create an EC2 instance. Instance Type For the free tier, I\u0026rsquo;ve only used t2.micro. In real scenarios, you can choose different resource levels based on your requirements. Key Pair AWS uses SSH keys for remote access. Choose the key pair for this instance. You can reuse a key pair across different instances for better key pair management. Network Settings Configure inbound and outbound rules. Typically, you\u0026rsquo;d open inbound for SSH and add \u0026ldquo;my IP\u0026rdquo; as the source. For web services, you\u0026rsquo;d add HTTP with a source of \u0026ldquo;anywhere.\u0026rdquo; Configure Storage AWS offers various storage types, such as SSD, HDD, and specialized types based on I/O. Advanced Here, I used the \u0026ldquo;User Data\u0026rdquo; field. You can write shell scripts in this field to install software or complete specific configurations during instance launch. Elastic Block Store (EBS) Storage options:\nVolume Type You can choose storage types like SSD, HDD, or specialized types based on I/O. You can also select the region for volume creation. AWS allows dynamic attachment of volumes to instances. Use fdisk -l to check the volume\u0026rsquo;s name. Use fdisk /dev/xvdf to create partitions. The path might vary based on the previous command\u0026rsquo;s output. m for help n new partition p primary partition number: default First sector: default Last sector: default w write table to disk Create partitions, format them using mkfs.ext4, and check with lsblk. Mount the partition using mount /dev/xvdf1 {target path}. To make it auto-mount, modify /etc/fstab. Snapshot Important data, like a database, is often stored on a separate volume. You can use EBS snapshots to back up a volume and later restore it by creating a new volume from the snapshot. Load Balancing An example with two instances running the same HTTP server:\nCreate a Target Group Configure health checks to ensure instance health. For a web server, set up periodic HTTP requests to a specific path. Add instances to the target group. Create a Load Balancer For example, use an Application Load Balancer. Configure security groups for inbound HTTP traffic. Set up listeners \u0026amp; routing to forward traffic to the target group. Adjust the security group of the target group to allow access from the load balancer\u0026rsquo;s security group. CloudWatch Create alarms, such as monitoring CPU resources:\nGo to \u0026ldquo;All Alarms\u0026rdquo; and create a new alarm. Select metrics, e.g., EC2, per-instance metrics. Choose the instance ID and select CPUUtilization. Set the threshold (e.g., 60%) and configure notification details for email or groups. Amazon Elastic File System (EFS) Similar to NFS on Linux, suitable for shared storage among multiple instances:\nCreate a security group for EFS. Create an EFS file system with default performance settings or adjust as needed. Configure network settings with the security group for all availability zones. Create an access point. Mount EFS from an EC2 instance using the amazon-efs-utils. sudo yum install -y amazon-efs-utils. official doc Update /etc/fstab Add {file-system-id}:/ {efs-mount-point} efs _netdev,noresvport,tls,accesspoint={access-point-id} 0 0 official doc execute mount -fav. If you see {mount-point}: successfully mounted, you\u0026rsquo;re done. ","date":"2023-10-31T00:00:00+08:00","permalink":"http://shawn1251.github.io/post/aws-note/","title":"AWS Note"},{"content":"For Linux users who are familiar with commands like cp, mv, and ls, here are some commands I found useful but took some time to master:\ncat Most often, cat is used to display file contents, such as cat {your file}. However, it can also be used to concatenate two files and create a new file.\nTo concatenate two files: cat {file1} {file2} \u0026gt; {merged file} To create a new file and write to it: cat \u0026gt; {your file} It will accept your input and write it to the file. Some automation scripts use this command to create files, like: 1 2 3 cat \u0026gt; testFile \u0026lt;\u0026lt; EOF {your content} EOF grep 1 grep -R SELINUX /etc/* -i: Ignore case. -R: Recursively search in subdirectories. -v: Invert match, output lines that don\u0026rsquo;t contain the keyword. cut This command is useful for quickly extracting specific content from files with a fixed format, such as /etc/passwd. In this file, each line is separated by colons (\u0026quot;:\u0026quot;).\n1 2 root:x:0:0:root:/root:/bin/bash vagrant:x:1000:1000::/home/vagrant:/bin/bash Using cut on this file:\n1 cut -d: -f1 /etc/passwd -d specifies the delimiter, and we use \u0026ldquo;:\u0026rdquo; to indicate that the delimiter is a colon. -f1 indicates that we want to extract the first field after splitting, which is the username. The output will be:\n1 2 root vagrant awk When the separator is more complex or variable, you can use awk. For the example mentioned above, you can use awk to achieve the same result:\n1 awk -F\u0026#39;:\u0026#39; \u0026#39;{print $1}\u0026#39; /etc/passwd -F specifies the field separator. {print $1} specifies to print the first field after splitting. sed sed is used for text substitution. It operates on streams and doesn\u0026rsquo;t overwrite the original file. For example:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 echo \u0026#34;this is a book.\u0026#34; \u0026gt; test # Create a sample text sed \u0026#39;s/book/dog/g\u0026#39; test \u0026gt; this is a dog. # It replaces \u0026#34;book\u0026#34; with \u0026#34;dog\u0026#34; in the text. # \u0026#39;s\u0026#39; stands for search. # \u0026#39;g\u0026#39; stands for global. # You can replace \u0026#39;test\u0026#39; with \u0026#39;*\u0026#39; to change multiple files. cat test \u0026gt; this is a book. # The original file remains unchanged. # To overwrite, you can add -i sed -i \u0026#39;s/book/dog/g\u0026#39; test cat test \u0026gt; this is a dog. Redirection By default, the output of Linux commands is displayed on the screen, but you can redirect the output to a file. Here are some key points:\n\u0026gt; will overwrite the target, while \u0026gt;\u0026gt; appends. 1 is stdout, and 2 is stderr. You can use \u0026amp; to redirect all output. 1 2 3 4 5 6 7 8 9 # When the target is stdout, you don\u0026#39;t need to specify 1. ls \u0026gt;\u0026gt; tmpfile # \u0026#39;lss\u0026#39; is a non-existent command that will produce an error. You can redirect its stderr output. lss 2\u0026gt;\u0026gt; tmpfile # The \u0026#39;\u0026amp;\u0026#39; symbol redirects both stdout and stderr. ls \u0026amp;\u0026gt;\u0026gt; tmpfile lss \u0026amp;\u0026gt;\u0026gt; tmpfile Pipe Use the pipe | to pass the output of one command as input to another.\n1 2 3 4 5 # Count the lines by passing the output of \u0026#39;ls\u0026#39; to \u0026#39;wc\u0026#39;. ls | wc -l # Extract the \u0026#39;Mem\u0026#39; column from the output of \u0026#39;free\u0026#39;. free | grep -i Mem ","date":"2023-10-30T00:00:00+08:00","permalink":"http://shawn1251.github.io/post/shell-cmd-filter/","title":"Commonly Used Shell Commands for Filtering"},{"content":"Vagrant is a command line tool that makes it easy to automate the setup and launching of virtual machines (VMs). It\u0026rsquo;s not a hypervisor itself but operates as a layer on top of existing hypervisors, allowing users to quickly create VMs on those hypervisors. Vagrant doesn\u0026rsquo;t require an operating system image; the image (referred to as a \u0026ldquo;box\u0026rdquo;) specified in the Vagrantfile is fetched from Vagrant Cloud. You define the necessary parameters in the Vagrantfile, and then you can start the VM with the vagrant up command.\nCommon Commands vagrant init {box name} - Initialize a new Vagrant environment with the specified box. vagrant up - Start the VM. vagrant ssh - Log in to the VM via SSH. vagrant halt - Stop the VM. vagrant destroy - Remove the VM. Process Create a folder. Create a Vagrantfile. Run vagrant up to start the VM. Use vagrant ssh to access the VM. Stop or delete the VM with vagrant halt or vagrant destroy. Example You can find VM images (boxes) on Vagrant Cloud: https://app.vagrantup.com/boxes/search. Initialize a new Vagrant environment with a specific box using vagrant init {box name} and start it with vagrant up. You can check the status of your VMs with vagrant global-status.\n1 2 3 vagrant init {box name} vagrant up vagrant global-status Provision of Vagrantfile Provisioning allows you to run commands on the VM before its first boot, such as installing specific software. You can refer to the official Vagrantfile documentation for more details. Here\u0026rsquo;s an example of provisioning to install Apache2 during VM setup:\n1 2 3 4 5 6 # Example provisioning to install Apache2 during VM setup config.vm.provision \u0026#34;shell\u0026#34;, inline: \u0026lt;\u0026lt;-SHELL apt-get update apt-get install -y apache2 SHELL ","date":"2023-10-28T00:00:00+08:00","permalink":"http://shawn1251.github.io/post/vagrant-intro/","title":"vagrant note"},{"content":"Chocolatey is a software installation tool for Windows, similar to \u0026lsquo;brew\u0026rsquo; on macOS. It makes installing software much more convenient.\nInstallation 1 2 3 4 5 6 7 Get-ExecutionPolicy # If it\u0026#39;s \u0026#39;restricted,\u0026#39; run PowerShell as an administrator and enter the following commands: Set-ExecutionPolicy AllSigned # Enter Y or A to confirm the permission change. Set-ExecutionPolicy Bypass -Scope Process -Force; iex ((New-Object System.Net.WebClient).DownloadString(\u0026#39;https://chocolatey.org/install.ps1\u0026#39;)) # Finally, run `choco` to confirm a successful installation. choco Usage You can visit https://community.chocolatey.org/packages to search for the software you want. For example, if you\u0026rsquo;re looking for VirtualBox, you\u0026rsquo;ll find the command:\n1 choco install virtualbox Running this command will automatically install the software!\n","date":"2023-10-24T06:42:46+08:00","permalink":"http://shawn1251.github.io/post/install-chocolatey/","title":"Install chocolatey"},{"content":"This article is here to document the process of building a blog using Hugo and publishing it on GitHub Pages. GitHub provides a free personal website service called GitHub Pages. You can upload your web content to a designated format repository to make it live.\nPreparations GitHub account Install Git Your target website Setup Click on \u0026ldquo;repository,\u0026rdquo; then \u0026ldquo;New.\u0026rdquo; In the \u0026ldquo;repository name\u0026rdquo; field, enter \u0026ldquo;{your account name}.github.io.\u0026rdquo; Click \u0026ldquo;create repository.\u0026rdquo; Upload Next, we\u0026rsquo;ll push the local website to GitHub. If you don\u0026rsquo;t have a website and just want to test, you can simply create an index.html for testing.\n1 2 3 4 5 6 7 8 9 10 11 # Initialize git for the current website git init # Add to the stage and commit git add . git commit -m \u0026#34;first commit\u0026#34; # Create the main branch git branch -M main # Add the remote repository and name it origin git remote add origin https://github.com/{your account}/{your account}.github.io.git # Push the current project to GitHub git push -u origin main View If everything is fine, you can visit https://{your account}.github.io to see the web page you just pushed!\nUsing Hugo: Building the Site and Uploading Continuing from the previous article, \u0026ldquo;Creating the First Post with Hugo\u0026rdquo;, we can use GitHub Pages to publish our results. Remember to change the baseURL in your config.\n1 2 3 4 5 6 7 8 9 10 11 # Build hugo # Navigate to the static website folder cd public # As explained above git init git add . git commit -m \u0026#34;first commit\u0026#34; git branch -M main git remote add origin https://github.com/{your account}/{your account}.github.io.git git push -u origin main ","date":"2023-10-21T06:42:46+08:00","permalink":"http://shawn1251.github.io/post/setting-your-first-githubpage/","title":"Setting GitHub page"},{"content":"I had a sudden inspiration to organize some of my past notes, and when looking for a platform, I took a friend\u0026rsquo;s advice and chose Hugo with GitHub Pages. Here, I\u0026rsquo;ll document the process.\nHugo Let me briefly introduce Hugo. Hugo is a static website generator developed in Golang. Static websites don\u0026rsquo;t rely on a backend, they\u0026rsquo;re fast, and you don\u0026rsquo;t need to set up a database, making them ideal for showcasing websites. In the past, many people used CMS, like WordPress, to create personal websites. However, for simpler needs, using static websites is recommended. Similar tools include Hexo and Jekyll.\nSince Hugo is developed in Golang, you only need to install the pre-compiled Hugo executable when using it, without the need for other languages like Ruby or JavaScript. You can start by browsing some pre-built Hugo template to get an idea of what your future project could look like.\nHere, we\u0026rsquo;ll follow the official guide: https://gohugo.io/getting-started/quick-start/\nInstalling Hugo Choose the appropriate installation method based on your operating system. I\u0026rsquo;m using Ubuntu, and assuming you already have Git installed, you can use the following commands:\n1 2 3 4 # First, install the Sass package sudo snap install dart-sass # Install Hugo sudo snap install hugo After installation, you can check the version:\n1 hugo --version Trying Your First Project 1 2 3 4 5 6 7 8 9 10 # Create a new project hugo new site quickstart cd quickstart git init # Add the \u0026#39;ananke\u0026#39; theme as a Git submodule for easier updates git submodule add https://github.com/theNewDynamic/gohugo-theme-ananke.git themes/ananke # Specify \u0026#39;ananke\u0026#39; as the theme for the current project echo \u0026#34;theme = \u0026#39;ananke\u0026#39;\u0026#34; \u0026gt;\u0026gt; hugo.toml # Run a web server to see the results hugo server Adding Content After following the above steps, you should see a simple black-and-white homepage. Now, you can add your own content using Hugo\u0026rsquo;s built-in commands:\n1 2 # Create a post named \u0026#39;my-first-post\u0026#39; hugo new content posts/my-first-post.md This will create an .md file under content/posts/. It will contain the following metadata, which is necessary for Hugo\u0026rsquo;s markdown:\n1 2 3 4 5 +++ title = \u0026#39;My First Post\u0026#39; date = 2023-10-20T21:37:17+08:00 draft = true +++ Unlike the content in the blank markdown, this one has the above metadata which is necessary. Let\u0026rsquo;s add some extra content using markdown. markdown instruction\n1 2 3 4 5 6 7 8 +++ title = \u0026#39;My First Post\u0026#39; date = 2023-10-20T21:37:17+08:00 draft = false +++ # hello world hello Be sure to change draft to false if you want your content to appear on the homepage. Otherwise, you need to use hugo server -D to display draft content.\nPublishing Simply run the hugo command to begin building based on your content. The results will be in the public folder. If you also have Python 3, you can run the built-in HTTP server for a simple test:\n1 2 cd public python3 -m http.server It will run on port 8000 by default. You can open your browser and go to localhost:8000 to see the static site.\nQuestions How can I customize the template? Usually, template projects have documentation for customization. For example, this blog uses stack. The issue I encountered with this template was adding a few icons that were not present in the theme. To customize it, I had to fork the original repository into my own repository and then make the necessary customizations.\nI found a template I like, but I don\u0026rsquo;t know how to get started. Typically, template projects come with a basic example site that you can refer to in order to understand how to use the template. In the case of stack, it has an \u0026rsquo;exampleSite\u0026rsquo; folder that contains content and config.yaml files. You can copy these files to your project directory to see how to get started.\n","date":"2023-10-20T00:00:00+08:00","permalink":"http://shawn1251.github.io/post/first-post/","title":"First Post with Hugo"}]