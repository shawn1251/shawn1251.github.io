[{"content":" I2C communication uses two lines, unlike TX and RX. I2C has only one line called SDA for data transmission and another line called SCL for clock pulses. SDA (serial data): carries the actual data. SCL (serial clock): provides clock pulses. Half-Duplex Unlike full-duplex communication where TX and RX can transmit and receive simultaneously, I2C allows only one side to transmit at a time, making it half-duplex. Master-Slave Mode Only one side can send a signal at a time to avoid conflicts, so communication is initiated by the master, and the slave responds after receiving the message. Multiple slaves can exist. Bus Protocol I2C is a bus protocol that enables communication between multiple devices. The master includes the target device\u0026rsquo;s address at the beginning of the message. Other slaves discard the message if it\u0026rsquo;s not meant for them. Synchronous Communication In asynchronous communication, both sides have their own clocks and communicate based on the agreed Baud Rate. Some small sensors lack accurate crystals for clocks, so the master\u0026rsquo;s SCL provides clock pulses to all slaves. ","date":"2023-11-23T00:00:00+08:00","permalink":"http://shawn1251.github.io/post/i2c-note/","title":"I2C Note"},{"content":"Recently, I\u0026rsquo;ve been learning embedded development with STM32. However, since I don\u0026rsquo;t have STLINK, I have to use CH340 for flashing. Here\u0026rsquo;s a quick overview of the process.\nRequired Software Keil5 FlyMcu Steps CH340 Pinout:\nVCC: Jumper cap for setting 5V/3.3V RX: Connects to GPIO PA09 for receiving TX: Connects to GPIO PA10 for transmitting GND: Ground connection For flashing, a hex file is needed. So, in my IDE Keil5, additional settings are required.\nClick the magic wand icon (options for target). Output \u0026gt; create hex file. After building, the hex file will appear in the Objects folder. The flashing software used here is FlyMcu. Below are the flashing steps:\nPlug in CH340 and ensure that the COM port above is for our CH340. Code file for online ISP \u0026gt; Choose the built hex file. Check Verify, Run After ISP complete. Uncheck Program OptionBytes when ISP. Click Start ISP. If the message on the right side shows the following, it indicates success:\n1 2 3 .... Write 1KB Ok,100%,@1562ms Go from 08000000 Ok If you want to flash a new program, press the reset button on the STM32.\n","date":"2023-11-20T00:00:00+08:00","permalink":"http://shawn1251.github.io/post/stm32-ch340/","title":"Flashing STM32 with CH340"},{"content":"A tool for task orchestration. Those with basic Linux experience are likely familiar with crontab, but it has limitations, such as the inability to establish complex task dependencies and easily review logs. In such cases, a comprehensive ETL (Extract, Transform, Load) tool is needed. This note briefly documents my learning process and shares the results on GitHub Repo.\nAdditionally, as of now, Airflow has evolved to version 2, and there are still many tutorials online for version 1. When learning, it\u0026rsquo;s essential to pay attention to the version. Official documentation can be found here.\nFeatures Open-source User-friendly UI Rich plugin ecosystem Purely Python-based Getting Started For a quick start, you can use the official Docker Compose setup: https://airflow.apache.org/docs/apache-airflow/stable/howto/docker-compose/index.html\n1 curl -LfO \u0026#39;https://airflow.apache.org/docs/apache-airflow/2.7.3/docker-compose.yaml\u0026#39; Create necessary volumes and set up the Airflow executor:\n1 2 3 4 mkdir -p ./dags ./logs ./plugins ./config echo -e \u0026#34;AIRFLOW_UID=$(id -u)\u0026#34; \u0026gt; .env docker compose up airflow-init docker compose up DAG DAG (Directed Acyclic Graph). In Airflow, a DAG is a definition of a workflow, describing a series of tasks and their dependencies. Each task represents a unit of work that can be any operation executable in Airflow, such as running a Python script, executing an SQL query, or invoking an external API.\nExample 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 from datetime import datetime, timedelta from airflow import DAG from airflow.operators.dummy_operator import DummyOperator from airflow.operators.python_operator import PythonOperator # Define default parameters default_args = { \u0026#39;owner\u0026#39;: \u0026#39;airflow\u0026#39;, \u0026#39;depends_on_past\u0026#39;: False, \u0026#39;start_date\u0026#39;: datetime(2023, 1, 1), \u0026#39;email_on_failure\u0026#39;: False, \u0026#39;email_on_retry\u0026#39;: False, \u0026#39;retries\u0026#39;: 1, \u0026#39;retry_delay\u0026#39;: timedelta(minutes=5), } def print_hello(): print(\u0026#34;Hello from the PythonOperator task\u0026#34;) # Define DAG with DAG( \u0026#39;simple_dag_example\u0026#39;, default_args=default_args, description=\u0026#39;A simple example DAG\u0026#39;, schedule_interval=timedelta(days=1), # Run every day ) as dag: # Define two tasks; decorators are also available starting from v2 start_task = DummyOperator( task_id=\u0026#39;start_task\u0026#39;, dag=dag, ) python_task = PythonOperator( task_id=\u0026#39;python_task\u0026#39;, python_callable=print_hello, dag=dag, ) # Define dependencies between tasks; # in this example, python_task runs after start_task start_task \u0026gt;\u0026gt; python_task Scheduler The scheduler checks the DAGs folder at regular intervals:\nChecks for any DAGs requiring a DAG Run. Creates scheduled task instances for tasks under DAG Run. To create a task, place the DAG Python file in the DAGs folder. You can copy and modify examples from the Airflow official documentation or refer to the example in the previous section.\nUI Operations Once the scheduler has completed the update, we can see our newly added DAGs on the UI. Due to platform constraints, detailed UI operations with numerous images are not suitable here, so instead, here is the official UI documentation link.\nFocus on mastering the basics:\nView DAG operation status Manually trigger DAG runs Review DAG execution logs ","date":"2023-11-14T00:00:00+08:00","permalink":"http://shawn1251.github.io/post/apache-airflow/","title":"Apache Airflow Note"},{"content":"This note is from the video 心河擺渡-成瘾始于痛苦，戒瘾终于平衡！深度解读多巴胺，用身体内稳态戒瘾 The video contains insights from the author as well as his analysis of Anna Lembke\u0026rsquo;s book Drug Dealer, MD: How Doctors Were Duped, Patients Got Hooked, and Why It’s So Hard to Stop. The content is very useful, and I made notes to remind myself.\nUnderlying Principles The reason behind addiction is the increase in dopamine. Chocolate increases it by 55%. Nicotine raises it by 150%. Amphetamine boosts it by 1000%. The main role of dopamine is not to make us feel happy after receiving a reward but to drive people to seek rewards. For example, when you see chocolate, dopamine activates the brain\u0026rsquo;s reward circuit, making you feel pleasure even before having it and prompting you to eat it. The regions in the brain responsible for pleasure and pain overlap. Pleasure and pain have self-regulating functions. When you\u0026rsquo;re currently experiencing pleasure, the brain will generate enough pain on the other side to balance it out. Reward Prediction Error Due to neural adaptation, the actual reward must exceed expectations to have a positive dopamine effect. In severe addiction, the threshold for feeling pleasure increases, resulting in a lack of enjoyment. Utilizing the Dopamine Mechanism According to clinical experience, recreating the brain\u0026rsquo;s reward circuit takes at least a month. Using pain to treat pain The brain uses pain to balance out pleasure and vice versa. According to research, dopamine levels in the blood plasma increase by 250% when people immerse themselves in cold water, and this effect lasts longer than the immersion time. Exercise is the best option. Physical separation Completely separate from the addictive substance. Radical honesty The prefrontal cortex is responsible for rational decision-making. When the dopamine reward circuit is active, lying inhibits the prefrontal cortex\u0026rsquo;s function, releasing the restraint on the reward circuit, leading the brain to believe it\u0026rsquo;s not addicted. An essential part of addiction recovery is rebuilding the relationship between the prefrontal cortex and the dopamine circuit. Strengthen the prefrontal cortex by \u0026ldquo;telling the truth\u0026rdquo; and enhance self-control. During addiction, engage in self-talk or announce your addiction to people around you. ","date":"2023-11-06T00:00:00+08:00","permalink":"http://shawn1251.github.io/post/addiction-recovery/","title":"Addiction Recovery"},{"content":"I\u0026rsquo;m currently learning DevOps Beginners to Advanced with Projects on Udemy. Here are some notes on using AWS.\nOriginal Application Stack Project GitHub\nNginx Apache Tomcat RabbitMQ Memcache Mysql Migration Goals EC2 VMs for tomcat, rabbitmq, memcache, mysql ELB (Elastic Load Balancer) Replaces nginx for load balancing Autoscaling Automation for VM scaling S3/EFS Shared storage Route 53 Private DNS service Target Architecture Flow of Execution Create key pairs Create security groups Split into three groups: LB (replaces nginx) APP (for tomcat) Backend (including rabbitmq, memcache, mysql) Launch instances with user data Currently a semi-automated process Manually create instances and paste shell scripts for environment setup into userdata Update IP to name mapping in Route 53 Set up an internal DNS for communication between instances using hostnames Build the application from source code This part is still semi-automated. Build the Java project on the local machine. Upload to S3 bucket Use AWS CLI to upload the built Java WAR file to the APP instance. Download artifact to Tomcat EC2 instance Previously, we used keys for S3 access. Here, instances connect to S3 using IAM roles. Create a new S3 access role in IAM. Attach the created role to the APP instance. Use aws s3 ls to confirm successful access. Set up ELB with HTTPS (certificate from Amazon Certificate Manager) Create a target group, ensuring it points to port 8080 on the app. Create an ELB with HTTP/HTTPS routing to the target group. Purchase a domain and apply for an SSL certificate from AWS Certificate Manager. In the secure listener, select the SSL certificate from ACM. Map ELB endpoint to website name in DNS At the DNS provider (in this case, GoDaddy), create a CNAME record that redirects to the AWS LB domain. Verify DNS settings may take some time to propagate. You can directly access the LB\u0026rsquo;s domain to check if the APP is running on port 80. Build an autoscaling group for the tomcat instance Autoscaling involves three steps: AMI (Amazon Machine Image) Create an image from the current APP instance. Launch template Use the created AMI, and keep the security group the same as the original APP. Autoscaling group Attach it to the existing load balancer. Choose the load balancer\u0026rsquo;s target group. Set scaling policies based on CPU usage or network in/out. Configure notifications. ","date":"2023-11-02T00:00:00+08:00","permalink":"http://shawn1251.github.io/post/aws-note-shift-to-cloud/","title":"AWS Note - Project Lifting and Shifting"},{"content":"I\u0026rsquo;m currently studying DevOps Beginners to Advanced with Projects on Udemy. Here are some notes on using AWS:\nCreating an EC2 Instance The most basic computing unit:\nName and Tag Here, you can choose to \u0026ldquo;add additional tags\u0026rdquo; to provide extra labels for easy identification on the AWS console. AMI (Amazon Machine Image) An AMI is like an image, similar to running a Docker image to create a container, but here, you create an EC2 instance. Instance Type For the free tier, I\u0026rsquo;ve only used t2.micro. In real scenarios, you can choose different resource levels based on your requirements. Key Pair AWS uses SSH keys for remote access. Choose the key pair for this instance. You can reuse a key pair across different instances for better key pair management. Network Settings Configure inbound and outbound rules. Typically, you\u0026rsquo;d open inbound for SSH and add \u0026ldquo;my IP\u0026rdquo; as the source. For web services, you\u0026rsquo;d add HTTP with a source of \u0026ldquo;anywhere.\u0026rdquo; Configure Storage AWS offers various storage types, such as SSD, HDD, and specialized types based on I/O. Advanced Here, I used the \u0026ldquo;User Data\u0026rdquo; field. You can write shell scripts in this field to install software or complete specific configurations during instance launch. Elastic Block Store (EBS) Storage options:\nVolume Type You can choose storage types like SSD, HDD, or specialized types based on I/O. You can also select the region for volume creation. AWS allows dynamic attachment of volumes to instances. Use fdisk -l to check the volume\u0026rsquo;s name. Use fdisk /dev/xvdf to create partitions. The path might vary based on the previous command\u0026rsquo;s output. m for help n new partition p primary partition number: default First sector: default Last sector: default w write table to disk Create partitions, format them using mkfs.ext4, and check with lsblk. Mount the partition using mount /dev/xvdf1 {target path}. To make it auto-mount, modify /etc/fstab. Snapshot Important data, like a database, is often stored on a separate volume. You can use EBS snapshots to back up a volume and later restore it by creating a new volume from the snapshot. Load Balancing An example with two instances running the same HTTP server:\nCreate a Target Group Configure health checks to ensure instance health. For a web server, set up periodic HTTP requests to a specific path. Add instances to the target group. Create a Load Balancer For example, use an Application Load Balancer. Configure security groups for inbound HTTP traffic. Set up listeners \u0026amp; routing to forward traffic to the target group. Adjust the security group of the target group to allow access from the load balancer\u0026rsquo;s security group. CloudWatch Create alarms, such as monitoring CPU resources:\nGo to \u0026ldquo;All Alarms\u0026rdquo; and create a new alarm. Select metrics, e.g., EC2, per-instance metrics. Choose the instance ID and select CPUUtilization. Set the threshold (e.g., 60%) and configure notification details for email or groups. Amazon Elastic File System (EFS) Similar to NFS on Linux, suitable for shared storage among multiple instances:\nCreate a security group for EFS. Create an EFS file system with default performance settings or adjust as needed. Configure network settings with the security group for all availability zones. Create an access point. Mount EFS from an EC2 instance using the amazon-efs-utils. sudo yum install -y amazon-efs-utils. official doc Update /etc/fstab Add {file-system-id}:/ {efs-mount-point} efs _netdev,noresvport,tls,accesspoint={access-point-id} 0 0 official doc execute mount -fav. If you see {mount-point}: successfully mounted, you\u0026rsquo;re done. ","date":"2023-10-31T00:00:00+08:00","permalink":"http://shawn1251.github.io/post/aws-note/","title":"AWS Note"},{"content":"For Linux users who are familiar with commands like cp, mv, and ls, here are some commands I found useful but took some time to master:\ncat Most often, cat is used to display file contents, such as cat {your file}. However, it can also be used to concatenate two files and create a new file.\nTo concatenate two files: cat {file1} {file2} \u0026gt; {merged file} To create a new file and write to it: cat \u0026gt; {your file} It will accept your input and write it to the file. Some automation scripts use this command to create files, like: 1 2 3 cat \u0026gt; testFile \u0026lt;\u0026lt; EOF {your content} EOF grep 1 grep -R SELINUX /etc/* -i: Ignore case. -R: Recursively search in subdirectories. -v: Invert match, output lines that don\u0026rsquo;t contain the keyword. cut This command is useful for quickly extracting specific content from files with a fixed format, such as /etc/passwd. In this file, each line is separated by colons (\u0026quot;:\u0026quot;).\n1 2 root:x:0:0:root:/root:/bin/bash vagrant:x:1000:1000::/home/vagrant:/bin/bash Using cut on this file:\n1 cut -d: -f1 /etc/passwd -d specifies the delimiter, and we use \u0026ldquo;:\u0026rdquo; to indicate that the delimiter is a colon. -f1 indicates that we want to extract the first field after splitting, which is the username. The output will be:\n1 2 root vagrant awk When the separator is more complex or variable, you can use awk. For the example mentioned above, you can use awk to achieve the same result:\n1 awk -F\u0026#39;:\u0026#39; \u0026#39;{print $1}\u0026#39; /etc/passwd -F specifies the field separator. {print $1} specifies to print the first field after splitting. sed sed is used for text substitution. It operates on streams and doesn\u0026rsquo;t overwrite the original file. For example:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 echo \u0026#34;this is a book.\u0026#34; \u0026gt; test # Create a sample text sed \u0026#39;s/book/dog/g\u0026#39; test \u0026gt; this is a dog. # It replaces \u0026#34;book\u0026#34; with \u0026#34;dog\u0026#34; in the text. # \u0026#39;s\u0026#39; stands for search. # \u0026#39;g\u0026#39; stands for global. # You can replace \u0026#39;test\u0026#39; with \u0026#39;*\u0026#39; to change multiple files. cat test \u0026gt; this is a book. # The original file remains unchanged. # To overwrite, you can add -i sed -i \u0026#39;s/book/dog/g\u0026#39; test cat test \u0026gt; this is a dog. Redirection By default, the output of Linux commands is displayed on the screen, but you can redirect the output to a file. Here are some key points:\n\u0026gt; will overwrite the target, while \u0026gt;\u0026gt; appends. 1 is stdout, and 2 is stderr. You can use \u0026amp; to redirect all output. 1 2 3 4 5 6 7 8 9 # When the target is stdout, you don\u0026#39;t need to specify 1. ls \u0026gt;\u0026gt; tmpfile # \u0026#39;lss\u0026#39; is a non-existent command that will produce an error. You can redirect its stderr output. lss 2\u0026gt;\u0026gt; tmpfile # The \u0026#39;\u0026amp;\u0026#39; symbol redirects both stdout and stderr. ls \u0026amp;\u0026gt;\u0026gt; tmpfile lss \u0026amp;\u0026gt;\u0026gt; tmpfile Pipe Use the pipe | to pass the output of one command as input to another.\n1 2 3 4 5 # Count the lines by passing the output of \u0026#39;ls\u0026#39; to \u0026#39;wc\u0026#39;. ls | wc -l # Extract the \u0026#39;Mem\u0026#39; column from the output of \u0026#39;free\u0026#39;. free | grep -i Mem ","date":"2023-10-30T00:00:00+08:00","permalink":"http://shawn1251.github.io/post/shell-cmd-filter/","title":"Commonly Used Shell Commands for Filtering"},{"content":"Vagrant is a command line tool that makes it easy to automate the setup and launching of virtual machines (VMs). It\u0026rsquo;s not a hypervisor itself but operates as a layer on top of existing hypervisors, allowing users to quickly create VMs on those hypervisors. Vagrant doesn\u0026rsquo;t require an operating system image; the image (referred to as a \u0026ldquo;box\u0026rdquo;) specified in the Vagrantfile is fetched from Vagrant Cloud. You define the necessary parameters in the Vagrantfile, and then you can start the VM with the vagrant up command.\nCommon Commands vagrant init {box name} - Initialize a new Vagrant environment with the specified box. vagrant up - Start the VM. vagrant ssh - Log in to the VM via SSH. vagrant halt - Stop the VM. vagrant destroy - Remove the VM. Process Create a folder. Create a Vagrantfile. Run vagrant up to start the VM. Use vagrant ssh to access the VM. Stop or delete the VM with vagrant halt or vagrant destroy. Example You can find VM images (boxes) on Vagrant Cloud: https://app.vagrantup.com/boxes/search. Initialize a new Vagrant environment with a specific box using vagrant init {box name} and start it with vagrant up. You can check the status of your VMs with vagrant global-status.\n1 2 3 vagrant init {box name} vagrant up vagrant global-status Provision of Vagrantfile Provisioning allows you to run commands on the VM before its first boot, such as installing specific software. You can refer to the official Vagrantfile documentation for more details. Here\u0026rsquo;s an example of provisioning to install Apache2 during VM setup:\n1 2 3 4 5 6 # Example provisioning to install Apache2 during VM setup config.vm.provision \u0026#34;shell\u0026#34;, inline: \u0026lt;\u0026lt;-SHELL apt-get update apt-get install -y apache2 SHELL ","date":"2023-10-28T00:00:00+08:00","permalink":"http://shawn1251.github.io/post/vagrant-intro/","title":"vagrant note"},{"content":"Chocolatey is a software installation tool for Windows, similar to \u0026lsquo;brew\u0026rsquo; on macOS. It makes installing software much more convenient.\nInstallation 1 2 3 4 5 6 7 Get-ExecutionPolicy # If it\u0026#39;s \u0026#39;restricted,\u0026#39; run PowerShell as an administrator and enter the following commands: Set-ExecutionPolicy AllSigned # Enter Y or A to confirm the permission change. Set-ExecutionPolicy Bypass -Scope Process -Force; iex ((New-Object System.Net.WebClient).DownloadString(\u0026#39;https://chocolatey.org/install.ps1\u0026#39;)) # Finally, run `choco` to confirm a successful installation. choco Usage You can visit https://community.chocolatey.org/packages to search for the software you want. For example, if you\u0026rsquo;re looking for VirtualBox, you\u0026rsquo;ll find the command:\n1 choco install virtualbox Running this command will automatically install the software!\n","date":"2023-10-24T06:42:46+08:00","permalink":"http://shawn1251.github.io/post/install-chocolatey/","title":"Install chocolatey"},{"content":"This article is here to document the process of building a blog using Hugo and publishing it on GitHub Pages. GitHub provides a free personal website service called GitHub Pages. You can upload your web content to a designated format repository to make it live.\nPreparations GitHub account Install Git Your target website Setup Click on \u0026ldquo;repository,\u0026rdquo; then \u0026ldquo;New.\u0026rdquo; In the \u0026ldquo;repository name\u0026rdquo; field, enter \u0026ldquo;{your account name}.github.io.\u0026rdquo; Click \u0026ldquo;create repository.\u0026rdquo; Upload Next, we\u0026rsquo;ll push the local website to GitHub. If you don\u0026rsquo;t have a website and just want to test, you can simply create an index.html for testing.\n1 2 3 4 5 6 7 8 9 10 11 # Initialize git for the current website git init # Add to the stage and commit git add . git commit -m \u0026#34;first commit\u0026#34; # Create the main branch git branch -M main # Add the remote repository and name it origin git remote add origin https://github.com/{your account}/{your account}.github.io.git # Push the current project to GitHub git push -u origin main View If everything is fine, you can visit https://{your account}.github.io to see the web page you just pushed!\nUsing Hugo: Building the Site and Uploading Continuing from the previous article, \u0026ldquo;Creating the First Post with Hugo\u0026rdquo;, we can use GitHub Pages to publish our results. Remember to change the baseURL in your config.\n1 2 3 4 5 6 7 8 9 10 11 # Build hugo # Navigate to the static website folder cd public # As explained above git init git add . git commit -m \u0026#34;first commit\u0026#34; git branch -M main git remote add origin https://github.com/{your account}/{your account}.github.io.git git push -u origin main ","date":"2023-10-21T06:42:46+08:00","permalink":"http://shawn1251.github.io/post/setting-your-first-githubpage/","title":"Setting GitHub page"},{"content":"I had a sudden inspiration to organize some of my past notes, and when looking for a platform, I took a friend\u0026rsquo;s advice and chose Hugo with GitHub Pages. Here, I\u0026rsquo;ll document the process.\nHugo Let me briefly introduce Hugo. Hugo is a static website generator developed in Golang. Static websites don\u0026rsquo;t rely on a backend, they\u0026rsquo;re fast, and you don\u0026rsquo;t need to set up a database, making them ideal for showcasing websites. In the past, many people used CMS, like WordPress, to create personal websites. However, for simpler needs, using static websites is recommended. Similar tools include Hexo and Jekyll.\nSince Hugo is developed in Golang, you only need to install the pre-compiled Hugo executable when using it, without the need for other languages like Ruby or JavaScript. You can start by browsing some pre-built Hugo template to get an idea of what your future project could look like.\nHere, we\u0026rsquo;ll follow the official guide: https://gohugo.io/getting-started/quick-start/\nInstalling Hugo Choose the appropriate installation method based on your operating system. I\u0026rsquo;m using Ubuntu, and assuming you already have Git installed, you can use the following commands:\n1 2 3 4 # First, install the Sass package sudo snap install dart-sass # Install Hugo sudo snap install hugo After installation, you can check the version:\n1 hugo --version Trying Your First Project 1 2 3 4 5 6 7 8 9 10 # Create a new project hugo new site quickstart cd quickstart git init # Add the \u0026#39;ananke\u0026#39; theme as a Git submodule for easier updates git submodule add https://github.com/theNewDynamic/gohugo-theme-ananke.git themes/ananke # Specify \u0026#39;ananke\u0026#39; as the theme for the current project echo \u0026#34;theme = \u0026#39;ananke\u0026#39;\u0026#34; \u0026gt;\u0026gt; hugo.toml # Run a web server to see the results hugo server Adding Content After following the above steps, you should see a simple black-and-white homepage. Now, you can add your own content using Hugo\u0026rsquo;s built-in commands:\n1 2 # Create a post named \u0026#39;my-first-post\u0026#39; hugo new content posts/my-first-post.md This will create an .md file under content/posts/. It will contain the following metadata, which is necessary for Hugo\u0026rsquo;s markdown:\n1 2 3 4 5 +++ title = \u0026#39;My First Post\u0026#39; date = 2023-10-20T21:37:17+08:00 draft = true +++ Unlike the content in the blank markdown, this one has the above metadata which is necessary. Let\u0026rsquo;s add some extra content using markdown. markdown instruction\n1 2 3 4 5 6 7 8 +++ title = \u0026#39;My First Post\u0026#39; date = 2023-10-20T21:37:17+08:00 draft = false +++ # hello world hello Be sure to change draft to false if you want your content to appear on the homepage. Otherwise, you need to use hugo server -D to display draft content.\nPublishing Simply run the hugo command to begin building based on your content. The results will be in the public folder. If you also have Python 3, you can run the built-in HTTP server for a simple test:\n1 2 cd public python3 -m http.server It will run on port 8000 by default. You can open your browser and go to localhost:8000 to see the static site.\nQuestions How can I customize the template? Usually, template projects have documentation for customization. For example, this blog uses stack. The issue I encountered with this template was adding a few icons that were not present in the theme. To customize it, I had to fork the original repository into my own repository and then make the necessary customizations.\nI found a template I like, but I don\u0026rsquo;t know how to get started. Typically, template projects come with a basic example site that you can refer to in order to understand how to use the template. In the case of stack, it has an \u0026rsquo;exampleSite\u0026rsquo; folder that contains content and config.yaml files. You can copy these files to your project directory to see how to get started.\n","date":"2023-10-20T00:00:00+08:00","permalink":"http://shawn1251.github.io/post/first-post/","title":"First Post with Hugo"}]